{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB6 — Biological Context: Age, Neuropathology & Irisin\n",
    "\n",
    "Age-stratified MES-GR associations, neuropathological burden analysis (Braak/CERAD), irisin-pathway scoring, GR x age interaction models, and threshold sensitivity analyses.\n",
    "\n",
    "**Paper:** Zafar SA, Qin W. *Thymus-Derived Myeloid Education Signatures Predict Microglial Tolerance Positioning and Are Modulated by Glucocorticoid Stress-Axis Activity.* Neuroimmunomodulation (2026).\n",
    "\n",
    "> **Note:** Update the path variables in section 0 to match your local directory structure before running. Raw data can be obtained from the public repositories listed in Supplementary Table S1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os, re, time, math, json, gc, glob, warnings, traceback\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({\n",
    "    \"font.family\": \"Arial\",\n",
    "    \"font.size\": 8,\n",
    "    \"axes.titlesize\": 9,\n",
    "    \"axes.labelsize\": 8,\n",
    "    \"xtick.labelsize\": 7,\n",
    "    \"ytick.labelsize\": 7,\n",
    "    \"legend.fontsize\": 7,\n",
    "    \"figure.dpi\": 150,\n",
    "    \"savefig.dpi\": 1200,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "    \"savefig.pad_inches\": 0.05,\n",
    "    \"axes.linewidth\": 0.8,\n",
    "    \"xtick.major.width\": 0.6,\n",
    "    \"ytick.major.width\": 0.6,\n",
    "    \"xtick.major.size\": 3,\n",
    "    \"ytick.major.size\": 3,\n",
    "    \"pdf.fonttype\": 42,       # editable text in PDF\n",
    "    \"ps.fonttype\": 42,\n",
    "})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set_style(\"ticks\")\n",
    "    HAS_SNS = True\n",
    "except ImportError:\n",
    "    HAS_SNS = False\n",
    "    print(\"[WARN] seaborn not installed; figures will use matplotlib only.\")\n",
    "\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "from scipy import stats as scipy_stats\n",
    "\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.stats.multitest import multipletests\n",
    "    HAS_SM = True\n",
    "except ImportError:\n",
    "    HAS_SM = False\n",
    "    print(\"[WARN] statsmodels not installed; partial correlations & OLS unavailable.\")\n",
    "\n",
    "# PATHS \n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "PROC_DIR  = Path(\".\") / \"data\" / \"processed\" / \"aim2_microglia\"  # <-- SET PATH\n",
    "MANUS_DIR = Path(\".\") / \"outputs\" / \"manuscript\"  # <-- SET PATH\n",
    "\n",
    "FIG_DIR = MANUS_DIR / \"Figures\"\n",
    "TAB_DIR = MANUS_DIR / \"Tables\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TAB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SCORED_GLOB = str(PROC_DIR / \"*__microglia_scored.h5ad\")\n",
    "\n",
    "DPI = 1200\n",
    "N_BOOT = 2000        # bootstrap iterations\n",
    "N_PERM = 5000        # permutation test iterations\n",
    "ALPHA  = 0.05        # significance threshold\n",
    "MIN_DONORS_PER_GROUP = 8\n",
    "\n",
    "# Run controls\n",
    "\n",
    "RUN_PART_A = True\n",
    "RUN_PART_B = True\n",
    "RUN_PART_C = True\n",
    "RUN_PART_D = False   # optional\n",
    "RUN_PART_E = False   # optional\n",
    "RUN_PART_F = True    # cross-cohort validation \n",
    "RUN_PART_G = True    # sensitivity analyses \n",
    "\n",
    "# Column conventions from NB5\n",
    "\n",
    "MES_COLS = [\n",
    "    \"MES01_score\", \"MES02_score\", \"MES03_score\", \"MES04_score\",\n",
    "    \"MES05_score\", \"MES06_score\", \"MES07_score\", \"MES08_score\",\n",
    "]\n",
    "GR_COL = \"GR_composite\"\n",
    "\n",
    "TOL_CANDS = [\n",
    "    \"tolerance_positioning\", \"tolerance\", \"Tolerance\", \"tolerance_score\",\n",
    "    \"tolerance_pos\", \"positioning\", \"Tol_positioning\",\n",
    "]\n",
    "\n",
    "# Gene sets\n",
    "\n",
    "IRISIN_GENES   = [\"FNDC5\", \"PPARGC1A\", \"PPRC1\", \"NRF1\", \"TFAM\"]\n",
    "IRISIN_ALIASES = {\"PGC1A\": \"PPARGC1A\"}\n",
    "\n",
    "NT_SIGS = {\n",
    "    \"dopamine\":        [\"TH\",\"DDC\",\"SLC6A3\",\"DRD1\",\"DRD2\",\"DRD3\",\"DRD4\",\"DRD5\"],\n",
    "    \"serotonin\":       [\"TPH1\",\"TPH2\",\"SLC6A4\",\"HTR1A\",\"HTR1B\",\"HTR2A\",\"HTR2C\"],\n",
    "    \"acetylcholine\":   [\"CHAT\",\"ACHE\",\"SLC18A3\",\"CHRNA7\",\"CHRNB2\"],\n",
    "    \"norepinephrine\":  [\"DBH\",\"SLC6A2\",\"ADRA1A\",\"ADRA2A\",\"ADRB1\",\"ADRB2\"],\n",
    "}\n",
    "\n",
    "EXERCISE_MODULE = [\n",
    "    \"PPARGC1A\",\"PPRC1\",\"NRF1\",\"TFAM\",\n",
    "    \"SOD1\",\"SOD2\",\"CAT\",\"GPX1\",\n",
    "    \"VEGFA\",\"VEGFB\",\n",
    "    \"BDNF\",\"IGF1\",\n",
    "]\n",
    "\n",
    "# Color palettes\n",
    "\n",
    "PALETTE_STATUS = {\"Control\": \"#4393C3\", \"AD\": \"#D6604D\",\n",
    "                  \"LowPath\": \"#4393C3\", \"HighPath\": \"#D6604D\",\n",
    "                  \"Unknown\": \"#999999\"}\n",
    "PALETTE_AGE    = {\"<65\": \"#66C2A5\", \"65-79\": \"#FC8D62\", \">=80\": \"#8DA0CB\", \"NA\": \"#CCCCCC\"}\n",
    "PALETTE_MES    = sns.color_palette(\"husl\", 8) if HAS_SNS else plt.cm.tab10(np.linspace(0, 1, 8))\n",
    "\n",
    "# Utilities\n",
    "\n",
    "def _now():\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def log(msg: str):\n",
    "    print(f\"[{_now()}] {msg}\", flush=True)\n",
    "\n",
    "def save_fig(path: Path, fig=None):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if fig is not None:\n",
    "        fig.savefig(path, dpi=DPI, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.savefig(path, dpi=DPI, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    log(f\"SAVED FIG {path}\")\n",
    "\n",
    "def save_xlsx(df: pd.DataFrame, path: Path, sheet_name=\"Sheet1\"):\n",
    "    if df is None or df.empty:\n",
    "        log(f\"SKIP TABLE (empty) {path}\")\n",
    "        return\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with pd.ExcelWriter(path, engine=\"openpyxl\") as w:\n",
    "        df.to_excel(w, index=False, sheet_name=sheet_name)\n",
    "    log(f\"SAVED TABLE {path}\")\n",
    "\n",
    "def save_xlsx_multi(dfs: Dict[str, pd.DataFrame], path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with pd.ExcelWriter(path, engine=\"openpyxl\") as w:\n",
    "        for name, df in dfs.items():\n",
    "            if df is not None and not df.empty:\n",
    "                df.to_excel(w, index=False, sheet_name=name[:31])\n",
    "    log(f\"SAVED TABLE (multi-sheet) {path}\")\n",
    "\n",
    "def safe_numeric(x) -> np.ndarray:\n",
    "    return pd.to_numeric(pd.Series(x), errors=\"coerce\").to_numpy()\n",
    "\n",
    "def _align_finite(x, y, min_n=8):\n",
    "    \"\"\"Return aligned finite arrays + mask.\"\"\"\n",
    "    x = safe_numeric(x); y = safe_numeric(y)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    if m.sum() < min_n:\n",
    "        return None, None, 0\n",
    "    return x[m], y[m], int(m.sum())\n",
    "\n",
    "# STATISTICAL TOOLKIT \n",
    "\n",
    "def corr_with_pvalue(x, y, method=\"spearman\", min_n=8):\n",
    "    \"\"\"\n",
    "    Returns dict: r, p, n, ci_lo, ci_hi (bootstrap 95% CI).\n",
    "    \"\"\"\n",
    "    xa, ya, n = _align_finite(x, y, min_n)\n",
    "    out = {\"r\": np.nan, \"p\": np.nan, \"n\": n, \"ci_lo\": np.nan, \"ci_hi\": np.nan, \"method\": method}\n",
    "    if xa is None:\n",
    "        return out\n",
    "\n",
    "    if method == \"spearman\":\n",
    "        r, p = scipy_stats.spearmanr(xa, ya)\n",
    "    elif method == \"pearson\":\n",
    "        r, p = scipy_stats.pearsonr(xa, ya)\n",
    "    elif method == \"kendall\":\n",
    "        r, p = scipy_stats.kendalltau(xa, ya)\n",
    "        r = r  # tau\n",
    "    else:\n",
    "        r, p = scipy_stats.spearmanr(xa, ya)\n",
    "\n",
    "    out[\"r\"] = float(r); out[\"p\"] = float(p); out[\"n\"] = n\n",
    "\n",
    "    # Bootstrap CI\n",
    "    rng = np.random.RandomState(42)\n",
    "    boots = np.full(N_BOOT, np.nan)\n",
    "    for i in range(N_BOOT):\n",
    "        idx = rng.randint(0, n, n)\n",
    "        if method == \"spearman\":\n",
    "            boots[i] = scipy_stats.spearmanr(xa[idx], ya[idx])[0]\n",
    "        elif method == \"pearson\":\n",
    "            boots[i] = scipy_stats.pearsonr(xa[idx], ya[idx])[0]\n",
    "        elif method == \"kendall\":\n",
    "            boots[i] = scipy_stats.kendalltau(xa[idx], ya[idx])[0]\n",
    "    finite_boots = boots[np.isfinite(boots)]\n",
    "    if len(finite_boots) > 10:\n",
    "        out[\"ci_lo\"] = float(np.percentile(finite_boots, 2.5))\n",
    "        out[\"ci_hi\"] = float(np.percentile(finite_boots, 97.5))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def partial_corr(df: pd.DataFrame, x: str, y: str, covars: List[str],\n",
    "                 method=\"spearman\", min_n=10) -> dict:\n",
    "    \"\"\"\n",
    "    Partial correlation controlling for covariates via OLS residuals.\n",
    "    Falls back to raw correlation if statsmodels missing or covars empty.\n",
    "    \"\"\"\n",
    "    cols = [x, y] + covars\n",
    "    d = df[cols].dropna()\n",
    "    if d.shape[0] < min_n or not HAS_SM or len(covars) == 0:\n",
    "        return corr_with_pvalue(df[x], df[y], method=method, min_n=min_n)\n",
    "\n",
    "    C = sm.add_constant(d[covars].values)\n",
    "    resid_x = sm.OLS(d[x].values, C).fit().resid\n",
    "    resid_y = sm.OLS(d[y].values, C).fit().resid\n",
    "\n",
    "    out = corr_with_pvalue(resid_x, resid_y, method=method, min_n=min_n)\n",
    "    out[\"partial\"] = True\n",
    "    out[\"covariates\"] = \",\".join(covars)\n",
    "    return out\n",
    "\n",
    "\n",
    "def cohen_d_with_ci(x, y, n_boot=N_BOOT):\n",
    "    \"\"\"\n",
    "    Cohen's d = (mean(y)-mean(x))/pooled_sd with bootstrap 95% CI.\n",
    "    Also returns Mann-Whitney U test p-value.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, float); y = np.asarray(y, float)\n",
    "    x = x[np.isfinite(x)]; y = y[np.isfinite(y)]\n",
    "    out = {\"d\": np.nan, \"ci_lo\": np.nan, \"ci_hi\": np.nan,\n",
    "           \"mw_U\": np.nan, \"mw_p\": np.nan,\n",
    "           \"mean_x\": np.nan, \"mean_y\": np.nan, \"sd_x\": np.nan, \"sd_y\": np.nan,\n",
    "           \"n_x\": len(x), \"n_y\": len(y)}\n",
    "\n",
    "    if len(x) < 3 or len(y) < 3:\n",
    "        return out\n",
    "\n",
    "    out[\"mean_x\"] = float(np.mean(x)); out[\"mean_y\"] = float(np.mean(y))\n",
    "    out[\"sd_x\"] = float(np.std(x, ddof=1)); out[\"sd_y\"] = float(np.std(y, ddof=1))\n",
    "\n",
    "    vx = np.var(x, ddof=1); vy = np.var(y, ddof=1)\n",
    "    sp2 = ((len(x)-1)*vx + (len(y)-1)*vy) / max((len(x)+len(y)-2), 1)\n",
    "    if sp2 <= 0:\n",
    "        return out\n",
    "    out[\"d\"] = float((np.mean(y) - np.mean(x)) / np.sqrt(sp2))\n",
    "\n",
    "    # Mann-Whitney\n",
    "    try:\n",
    "        U, p = scipy_stats.mannwhitneyu(x, y, alternative=\"two-sided\")\n",
    "        out[\"mw_U\"] = float(U); out[\"mw_p\"] = float(p)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Bootstrap CI on d\n",
    "    rng = np.random.RandomState(42)\n",
    "    boots = np.full(n_boot, np.nan)\n",
    "    for i in range(n_boot):\n",
    "        bx = x[rng.randint(0, len(x), len(x))]\n",
    "        by = y[rng.randint(0, len(y), len(y))]\n",
    "        bvx = np.var(bx, ddof=1); bvy = np.var(by, ddof=1)\n",
    "        bsp2 = ((len(bx)-1)*bvx + (len(by)-1)*bvy) / max((len(bx)+len(by)-2), 1)\n",
    "        if bsp2 > 0:\n",
    "            boots[i] = (np.mean(by) - np.mean(bx)) / np.sqrt(bsp2)\n",
    "    fb = boots[np.isfinite(boots)]\n",
    "    if len(fb) > 10:\n",
    "        out[\"ci_lo\"] = float(np.percentile(fb, 2.5))\n",
    "        out[\"ci_hi\"] = float(np.percentile(fb, 97.5))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def permutation_test_corr(x, y, method=\"spearman\", n_perm=N_PERM, min_n=8):\n",
    "    \"\"\"Permutation p-value for correlation.\"\"\"\n",
    "    xa, ya, n = _align_finite(x, y, min_n)\n",
    "    if xa is None:\n",
    "        return np.nan\n",
    "\n",
    "    if method == \"spearman\":\n",
    "        obs_r = scipy_stats.spearmanr(xa, ya)[0]\n",
    "    else:\n",
    "        obs_r = scipy_stats.pearsonr(xa, ya)[0]\n",
    "\n",
    "    rng = np.random.RandomState(42)\n",
    "    count = 0\n",
    "    for _ in range(n_perm):\n",
    "        perm_y = rng.permutation(ya)\n",
    "        if method == \"spearman\":\n",
    "            pr = scipy_stats.spearmanr(xa, perm_y)[0]\n",
    "        else:\n",
    "            pr = scipy_stats.pearsonr(xa, perm_y)[0]\n",
    "        if abs(pr) >= abs(obs_r):\n",
    "            count += 1\n",
    "    return float((count + 1) / (n_perm + 1))\n",
    "\n",
    "\n",
    "def bh_fdr(pvals) -> np.ndarray:\n",
    "    \"\"\"Benjamini-Hochberg FDR. Returns q-values. NaNs preserved.\"\"\"\n",
    "    p = np.asarray(pvals, float)\n",
    "    q = np.full_like(p, np.nan)\n",
    "    m = np.isfinite(p)\n",
    "    if m.sum() == 0:\n",
    "        return q\n",
    "    if HAS_SM:\n",
    "        _, qv, _, _ = multipletests(p[m], method=\"fdr_bh\")\n",
    "        q[m] = qv\n",
    "    else:\n",
    "        pv = p[m]; n = pv.size\n",
    "        order = np.argsort(pv)\n",
    "        ranked = pv[order]\n",
    "        qv = ranked * n / (np.arange(n) + 1.0)\n",
    "        qv = np.minimum.accumulate(qv[::-1])[::-1]\n",
    "        q[m] = qv[np.argsort(order)]\n",
    "    return q\n",
    "\n",
    "\n",
    "def fit_interaction_ols(df: pd.DataFrame, y: str, x: str, z: str,\n",
    "                        covars: Optional[List[str]] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    OLS: y ~ x + z + x*z [+ covars]. Returns betas, p-values, R², n.\n",
    "    \"\"\"\n",
    "    covars = covars or []\n",
    "    out = {\"beta_x\": np.nan, \"beta_z\": np.nan, \"beta_xz\": np.nan,\n",
    "           \"p_x\": np.nan, \"p_z\": np.nan, \"p_xz\": np.nan,\n",
    "           \"R2\": np.nan, \"R2_adj\": np.nan, \"n\": 0, \"model\": \"failed\"}\n",
    "\n",
    "    cols = [y, x, z] + covars\n",
    "    d = df[cols].dropna()\n",
    "    out[\"n\"] = int(d.shape[0])\n",
    "    if out[\"n\"] < max(10, len(cols) + 5):\n",
    "        return out\n",
    "\n",
    "    if not HAS_SM:\n",
    "        # Fallback: numpy lstsq (no p-values)\n",
    "        xz = d[x].values * d[z].values\n",
    "        Xm = np.column_stack([np.ones(out[\"n\"]), d[x].values, d[z].values, xz]\n",
    "                             + [d[c].values for c in covars])\n",
    "        try:\n",
    "            b = np.linalg.lstsq(Xm, d[y].values, rcond=None)[0]\n",
    "            out[\"beta_x\"] = float(b[1]); out[\"beta_z\"] = float(b[2]); out[\"beta_xz\"] = float(b[3])\n",
    "            out[\"model\"] = \"numpy_lstsq\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        return out\n",
    "\n",
    "    Xdf = pd.DataFrame({x: d[x].values, z: d[z].values, \"xz\": d[x].values * d[z].values})\n",
    "    for c in covars:\n",
    "        Xdf[c] = d[c].values\n",
    "    Xdf = sm.add_constant(Xdf, has_constant=\"add\")\n",
    "\n",
    "    try:\n",
    "        model = sm.OLS(d[y].values, Xdf).fit()\n",
    "        out[\"beta_x\"]  = float(model.params.get(x, np.nan))\n",
    "        out[\"beta_z\"]  = float(model.params.get(z, np.nan))\n",
    "        out[\"beta_xz\"] = float(model.params.get(\"xz\", np.nan))\n",
    "        out[\"p_x\"]  = float(model.pvalues.get(x, np.nan))\n",
    "        out[\"p_z\"]  = float(model.pvalues.get(z, np.nan))\n",
    "        out[\"p_xz\"] = float(model.pvalues.get(\"xz\", np.nan))\n",
    "        out[\"R2\"]     = float(model.rsquared)\n",
    "        out[\"R2_adj\"] = float(model.rsquared_adj)\n",
    "        out[\"model\"]  = \"OLS_statsmodels\"\n",
    "    except Exception as e:\n",
    "        out[\"model\"] = f\"failed: {e}\"\n",
    "    return out\n",
    "\n",
    "\n",
    "def sig_stars(p):\n",
    "    \"\"\"Return significance stars for annotation.\"\"\"\n",
    "    if pd.isna(p) or not np.isfinite(p):\n",
    "        return \"ns\"\n",
    "    if p < 0.001:\n",
    "        return \"***\"\n",
    "    if p < 0.01:\n",
    "        return \"**\"\n",
    "    if p < 0.05:\n",
    "        return \"*\"\n",
    "    return \"ns\"\n",
    "\n",
    "# Column detection helpers \n",
    "\n",
    "def pick_first_existing(cols, candidates):\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def find_col_by_keywords(obs_cols, keywords_any, keywords_not=None):\n",
    "    keywords_not = keywords_not or []\n",
    "    for c in obs_cols:\n",
    "        s = str(c).lower()\n",
    "        if any(k in s for k in keywords_any) and not any(k in s for k in keywords_not):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def detect_donor_col(adata):\n",
    "    cols = list(map(str, adata.obs.columns))\n",
    "    for cand in [\"donor_id\",\"Donor ID\",\"donor\",\"DonorID\",\"patient_id\",\"PatientID\",\"subject_id\",\"individual\"]:\n",
    "        if cand in cols:\n",
    "            return cand\n",
    "    return find_col_by_keywords(cols, [\"donor\"])\n",
    "\n",
    "def detect_age_col(adata):\n",
    "    cols = list(map(str, adata.obs.columns))\n",
    "    for cand in [\"Age\",\"age\",\"Age at Death\",\"age_at_death\",\"age_at_death_years\",\"AgeAtDeath\",\"age_years\"]:\n",
    "        if cand in cols:\n",
    "            return cand\n",
    "    return find_col_by_keywords(cols, [\"age\"], keywords_not=[\"stage\",\"assay\"])\n",
    "\n",
    "def detect_diagnosis_col(adata):\n",
    "    cols = list(map(str, adata.obs.columns))\n",
    "    for cand in [\"Diagnosis\",\"diagnosis\",\"dx\",\"Dx\",\"disease\",\"Disease\",\"clinical_diagnosis\"]:\n",
    "        if cand in cols:\n",
    "            return cand\n",
    "    return find_col_by_keywords(cols, [\"diagnos\",\"dement\",\"alzheimer\",\"adnc\",\"case\",\"control\"])\n",
    "\n",
    "def detect_severity_cols(adata):\n",
    "    cols = list(map(str, adata.obs.columns))\n",
    "    out = {\n",
    "        \"braak\": pick_first_existing(cols, [\"Braak\",\"braak\",\"braak_stage\",\"Braak stage\"]),\n",
    "        \"cerad\": pick_first_existing(cols, [\"CERAD\",\"cerad\",\"CERAD score\",\"cerad_score\"]),\n",
    "        \"adnc\":  pick_first_existing(cols, [\"ADNC\",\"adnc\",\"ADNC_level\",\"adnc_level\"]),\n",
    "    }\n",
    "    if out[\"braak\"] is None: out[\"braak\"] = find_col_by_keywords(cols, [\"braak\"])\n",
    "    if out[\"cerad\"] is None: out[\"cerad\"] = find_col_by_keywords(cols, [\"cerad\"])\n",
    "    if out[\"adnc\"]  is None: out[\"adnc\"]  = find_col_by_keywords(cols, [\"adnc\"])\n",
    "    return out\n",
    "\n",
    "def detect_tolerance_col(adata):\n",
    "    cols = list(map(str, adata.obs.columns))\n",
    "    c = pick_first_existing(cols, TOL_CANDS)\n",
    "    if c is not None:\n",
    "        return c\n",
    "    return find_col_by_keywords(cols, [\"toler\",\"position\"], keywords_not=[\"composition\"])\n",
    "\n",
    "def detect_sex_col(adata):\n",
    "    cols = list(map(str, adata.obs.columns))\n",
    "    for cand in [\"Sex\",\"sex\",\"gender\",\"Gender\"]:\n",
    "        if cand in cols:\n",
    "            return cand\n",
    "    return find_col_by_keywords(cols, [\"sex\",\"gender\"])\n",
    "\n",
    "def detect_pmi_col(adata):\n",
    "    cols = list(map(str, adata.obs.columns))\n",
    "    for cand in [\"PMI\",\"pmi\",\"post_mortem_interval\",\"PostMortemInterval\"]:\n",
    "        if cand in cols:\n",
    "            return cand\n",
    "    return find_col_by_keywords(cols, [\"pmi\",\"post.?mortem\"])\n",
    "\n",
    "def detect_batch_col(adata):\n",
    "    cols = list(map(str, adata.obs.columns))\n",
    "    for cand in [\"batch\",\"Batch\",\"library_prep_batch\",\"sequencing_batch\"]:\n",
    "        if cand in cols:\n",
    "            return cand\n",
    "    return find_col_by_keywords(cols, [\"batch\"], keywords_not=[\"size\"])\n",
    "\n",
    "# Braak / CERAD parsing (same robust approach)\n",
    "\n",
    "_ROMAN = {\"0\":0, \"I\":1, \"II\":2, \"III\":3, \"IV\":4, \"V\":5, \"VI\":6}\n",
    "_CERAD = {\"ABSENT\":0, \"NONE\":0, \"SPARSE\":1, \"MODERATE\":2, \"FREQUENT\":3}\n",
    "\n",
    "def parse_braak(v):\n",
    "    if pd.isna(v): return np.nan\n",
    "    s = str(v).upper()\n",
    "    m = re.findall(r\"(VI|IV|V|III|II|I|0)\", s)\n",
    "    if not m: return np.nan\n",
    "    nums = [_ROMAN.get(x, np.nan) for x in m]\n",
    "    nums = [x for x in nums if np.isfinite(x)]\n",
    "    return float(np.max(nums)) if nums else np.nan\n",
    "\n",
    "def parse_cerad(v):\n",
    "    if pd.isna(v): return np.nan\n",
    "    s = str(v).strip().upper()\n",
    "    vn = pd.to_numeric(s, errors=\"coerce\")\n",
    "    if np.isfinite(vn): return float(vn)\n",
    "    for k, val in _CERAD.items():\n",
    "        if k in s: return float(val)\n",
    "    return np.nan\n",
    "\n",
    "# Scoring helpers\n",
    "\n",
    "def canonicalize_gene(g):\n",
    "    return IRISIN_ALIASES.get(str(g).strip(), str(g).strip())\n",
    "\n",
    "def score_geneset_simple(adata, genes, score_name):\n",
    "    genes = [canonicalize_gene(g) for g in genes]\n",
    "    genes_present = [g for g in genes if g in adata.var_names]\n",
    "    if len(genes_present) < max(2, min(5, len(genes)//2)):\n",
    "        adata.obs[score_name] = np.nan\n",
    "        log(f\"  score_geneset: {score_name} SKIPPED (present={len(genes_present)}/{len(genes)})\")\n",
    "        return genes_present\n",
    "    sc.tl.score_genes(adata, gene_list=genes_present, score_name=score_name, use_raw=False)\n",
    "    log(f\"  score_geneset: {score_name} OK ({len(genes_present)} genes)\")\n",
    "    return genes_present\n",
    "\n",
    "def score_geneset_zscore(adata, genes, score_name):\n",
    "    \"\"\"Alternative: mean of Z-scored expression. Reports alongside scanpy for robustness.\"\"\"\n",
    "    genes = [canonicalize_gene(g) for g in genes]\n",
    "    genes_present = [g for g in genes if g in adata.var_names]\n",
    "    if len(genes_present) < 2:\n",
    "        adata.obs[score_name] = np.nan\n",
    "        return\n",
    "    idx = [list(adata.var_names).index(g) for g in genes_present]\n",
    "    if sp.issparse(adata.X):\n",
    "        mat = np.asarray(adata.X[:, idx].todense())\n",
    "    else:\n",
    "        mat = np.asarray(adata.X[:, idx])\n",
    "    # Z-score per gene across cells\n",
    "    mu = np.nanmean(mat, axis=0, keepdims=True)\n",
    "    sd = np.nanstd(mat, axis=0, keepdims=True)\n",
    "    sd[sd < 1e-10] = 1.0\n",
    "    z = (mat - mu) / sd\n",
    "    adata.obs[score_name] = np.nanmean(z, axis=1)\n",
    "    log(f\"  score_geneset_zscore: {score_name} OK ({len(genes_present)} genes)\")\n",
    "\n",
    "# Donor aggregation\n",
    "\n",
    "def donor_aggregate(adata, donor_col, cols_to_mean, cols_to_keep_first=None):\n",
    "    cols_to_keep_first = cols_to_keep_first or []\n",
    "    obs = adata.obs.copy()\n",
    "    obs[donor_col] = obs[donor_col].astype(str)\n",
    "    mean_cols = [c for c in cols_to_mean if c in obs.columns]\n",
    "    dfm = obs.groupby(donor_col)[mean_cols].mean(numeric_only=True)\n",
    "    # Also compute n_cells per donor\n",
    "    n_cells = obs.groupby(donor_col).size().rename(\"n_cells\")\n",
    "    out = dfm.join(n_cells).reset_index().rename(columns={donor_col: \"donor_id\"})\n",
    "    for c in cols_to_keep_first:\n",
    "        if c in obs.columns:\n",
    "            tmp = obs.groupby(donor_col)[c].first().reset_index().rename(columns={donor_col: \"donor_id\"})\n",
    "            out = out.merge(tmp, on=\"donor_id\", how=\"left\")\n",
    "    return out\n",
    "\n",
    "# Status assignment (Clinical or Neuropathological)\n",
    "\n",
    "def assign_age_group(df, age_col):\n",
    "    age = pd.to_numeric(df[age_col], errors=\"coerce\")\n",
    "    out = pd.Series(\"NA\", index=df.index, dtype=\"object\")\n",
    "    out[age < 65] = \"<65\"\n",
    "    out[(age >= 65) & (age < 80)] = \"65-79\"\n",
    "    out[age >= 80] = \">=80\"\n",
    "    out[~np.isfinite(age)] = \"NA\"\n",
    "    return pd.Categorical(out, categories=[\"<65\",\"65-79\",\">=80\",\"NA\"])\n",
    "\n",
    "def assign_status(df, dx_col, sev_cols, prefer_clinical=True,\n",
    "                  braak_thresh=4, cerad_thresh=2):\n",
    "    \"\"\"\n",
    "    Assign status with configurable thresholds for sensitivity analysis.\n",
    "    Default: LowPath = Braak<=3 & CERAD<=1; HighPath = Braak>=4 | CERAD>=2.\n",
    "    \"\"\"\n",
    "    # Clinical if available\n",
    "    if prefer_clinical and dx_col and dx_col in df.columns:\n",
    "        out = pd.Series(\"Unknown\", index=df.index, dtype=\"object\")\n",
    "        s = df[dx_col].astype(str).str.lower()\n",
    "        out[s.str.contains(r\"control|no dementia|normal|non[- ]dement\", na=False)] = \"Control\"\n",
    "        out[s.str.contains(r\"alzheimer|dement|ad\\b\", na=False)] = \"AD\"\n",
    "        return pd.Categorical(out, categories=[\"Control\",\"AD\",\"Unknown\"]), \"Clinical\"\n",
    "\n",
    "    # Neuropathology strata\n",
    "    braak_col = sev_cols.get(\"braak\")\n",
    "    cerad_col = sev_cols.get(\"cerad\")\n",
    "\n",
    "    b = df[braak_col].map(parse_braak).astype(float) if braak_col and braak_col in df.columns else pd.Series(np.nan, index=df.index, dtype=float)\n",
    "    c = df[cerad_col].map(parse_cerad).astype(float) if cerad_col and cerad_col in df.columns else pd.Series(np.nan, index=df.index, dtype=float)\n",
    "\n",
    "    b_vals = b.to_numpy(dtype=float)\n",
    "    c_vals = c.to_numpy(dtype=float)\n",
    "\n",
    "    low  = np.isfinite(b_vals) & np.isfinite(c_vals) & (b_vals < braak_thresh) & (c_vals < cerad_thresh)\n",
    "    high = (np.isfinite(b_vals) & (b_vals >= braak_thresh)) | (np.isfinite(c_vals) & (c_vals >= cerad_thresh))\n",
    "\n",
    "    out = pd.Series(\"Unknown\", index=df.index, dtype=\"object\")\n",
    "    out[low]  = \"LowPath\"\n",
    "    out[high] = \"HighPath\"\n",
    "\n",
    "    return pd.Categorical(out, categories=[\"LowPath\",\"HighPath\",\"Unknown\"]), \"Neuropathology\"\n",
    "\n",
    "# Build covariate list\n",
    "\n",
    "def build_covariate_list(df, sex_col, pmi_col, batch_col):\n",
    "    \"\"\"Return list of usable covariate column names (numeric-encoded).\"\"\"\n",
    "    covars = []\n",
    "\n",
    "    if sex_col and sex_col in df.columns:\n",
    "        s = df[sex_col].astype(str).str.lower()\n",
    "        df[\"_cov_sex_num\"] = np.where(s.str.startswith(\"m\"), 0.0,\n",
    "                             np.where(s.str.startswith(\"f\"), 1.0, np.nan))\n",
    "        if df[\"_cov_sex_num\"].notna().sum() > 10:\n",
    "            covars.append(\"_cov_sex_num\")\n",
    "\n",
    "    if pmi_col and pmi_col in df.columns:\n",
    "        df[\"_cov_pmi\"] = pd.to_numeric(df[pmi_col], errors=\"coerce\")\n",
    "        if df[\"_cov_pmi\"].notna().sum() > 10:\n",
    "            covars.append(\"_cov_pmi\")\n",
    "\n",
    "    if batch_col and batch_col in df.columns:\n",
    "        u = df[batch_col].dropna().unique()\n",
    "        if 1 < len(u) < 20:\n",
    "            df[\"_cov_batch_num\"] = pd.Categorical(df[batch_col]).codes.astype(float)\n",
    "            df.loc[df[batch_col].isna(), \"_cov_batch_num\"] = np.nan\n",
    "            if df[\"_cov_batch_num\"].notna().sum() > 10:\n",
    "                covars.append(\"_cov_batch_num\")\n",
    "\n",
    "    return covars\n",
    "\n",
    "# Build donor-level table\n",
    "\n",
    "def make_donor_df(adata, cohort_name=\"SEA-AD\",\n",
    "                  braak_thresh=4, cerad_thresh=2):\n",
    "    \"\"\"Build donor-level DataFrame from a scored AnnData.\"\"\"\n",
    "    d_col = detect_donor_col(adata)\n",
    "    a_col = detect_age_col(adata)\n",
    "    dx    = detect_diagnosis_col(adata)\n",
    "    sev   = detect_severity_cols(adata)\n",
    "    tol   = detect_tolerance_col(adata)\n",
    "    sx    = detect_sex_col(adata)\n",
    "    pmi   = detect_pmi_col(adata)\n",
    "    bat   = detect_batch_col(adata)\n",
    "\n",
    "    meta = {\"cohort\": cohort_name,\n",
    "            \"donor_col\": d_col, \"age_col\": a_col, \"dx_col\": dx,\n",
    "            \"tol_col\": tol, \"sex_col\": sx, \"pmi_col\": pmi, \"batch_col\": bat,\n",
    "            **{f\"sev_{k}\": v for k, v in sev.items()}}\n",
    "\n",
    "    # Columns to aggregate\n",
    "    mean_cols = [c for c in MES_COLS + [GR_COL, \"IrisinScore\", \"IrisinScore_Z\"]\n",
    "                 if c in adata.obs.columns]\n",
    "    if tol and tol in adata.obs.columns:\n",
    "        mean_cols.append(tol)\n",
    "    for k in NT_SIGS:\n",
    "        if f\"NT_{k}\" in adata.obs.columns:\n",
    "            mean_cols.append(f\"NT_{k}\")\n",
    "    if \"ExerciseModuleScore\" in adata.obs.columns:\n",
    "        mean_cols.append(\"ExerciseModuleScore\")\n",
    "\n",
    "    keep_first = []\n",
    "    for c in [a_col, dx, sev.get(\"braak\"), sev.get(\"cerad\"), sev.get(\"adnc\"), sx, pmi, bat]:\n",
    "        if c and c in adata.obs.columns:\n",
    "            keep_first.append(c)\n",
    "\n",
    "    if d_col and d_col in adata.obs.columns:\n",
    "        ddf = donor_aggregate(adata, d_col, mean_cols, keep_first)\n",
    "    else:\n",
    "        ddf = adata.obs.copy().reset_index().rename(columns={\"index\": \"donor_id\"})\n",
    "        ddf[\"n_cells\"] = 1\n",
    "\n",
    "    # Age\n",
    "    if a_col and a_col in ddf.columns:\n",
    "        ddf[\"age_group\"] = assign_age_group(ddf, a_col)\n",
    "        ddf[\"age_years\"] = pd.to_numeric(ddf[a_col], errors=\"coerce\")\n",
    "    else:\n",
    "        ddf[\"age_group\"] = pd.Categorical([\"NA\"]*len(ddf), categories=[\"<65\",\"65-79\",\">=80\",\"NA\"])\n",
    "        ddf[\"age_years\"] = np.nan\n",
    "\n",
    "    # Status\n",
    "    status, label = assign_status(ddf, dx_col=dx, sev_cols=sev,\n",
    "                                  prefer_clinical=True,\n",
    "                                  braak_thresh=braak_thresh,\n",
    "                                  cerad_thresh=cerad_thresh)\n",
    "    ddf[\"status\"] = status\n",
    "    ddf[\"status_label\"] = label\n",
    "\n",
    "    # Numeric neuropath\n",
    "    if sev.get(\"braak\") and sev[\"braak\"] in ddf.columns:\n",
    "        ddf[\"Braak_num\"] = ddf[sev[\"braak\"]].map(parse_braak)\n",
    "    else:\n",
    "        ddf[\"Braak_num\"] = np.nan\n",
    "    if sev.get(\"cerad\") and sev[\"cerad\"] in ddf.columns:\n",
    "        ddf[\"CERAD_num\"] = ddf[sev[\"cerad\"]].map(parse_cerad)\n",
    "    else:\n",
    "        ddf[\"CERAD_num\"] = np.nan\n",
    "\n",
    "    # Covariates\n",
    "    covars = build_covariate_list(ddf, sx, pmi, bat)\n",
    "    meta[\"covariates\"] = covars\n",
    "\n",
    "    ddf[\"cohort\"] = cohort_name\n",
    "    return ddf, meta\n",
    "\n",
    "# Load all cohorts\n",
    "\n",
    "def load_scored_cohorts():\n",
    "    files = sorted(glob.glob(SCORED_GLOB))\n",
    "    log(f\"Found scored cohorts: {[Path(x).name for x in files]}\")\n",
    "    cohorts = {}\n",
    "    for f in files:\n",
    "        a = sc.read_h5ad(f)\n",
    "        if not a.obs_names.is_unique: a.obs_names_make_unique()\n",
    "        if not a.var_names.is_unique: a.var_names_make_unique()\n",
    "        ds = Path(f).name.replace(\"__microglia_scored.h5ad\", \"\")\n",
    "        cohorts[ds] = a\n",
    "    log(f\"Loaded cohorts: {list(cohorts.keys())}\")\n",
    "    return cohorts\n",
    "\n",
    "log(\"=\" * 60)\n",
    "log(\"NB6 START\")\n",
    "log(\"=\" * 60)\n",
    "\n",
    "cohorts = load_scored_cohorts()\n",
    "\n",
    "if \"SEA-AD\" not in cohorts:\n",
    "    raise RuntimeError(\"SEA-AD cohort not found. Check PROC_DIR / SCORED_GLOB.\")\n",
    "\n",
    "# Score gene modules on ALL cohorts before donor aggregation\n",
    "\n",
    "for cname, adata in cohorts.items():\n",
    "    log(f\"Scoring modules on {cname} (n={adata.n_obs})\")\n",
    "    score_geneset_simple(adata, IRISIN_GENES, \"IrisinScore\")\n",
    "    score_geneset_zscore(adata, IRISIN_GENES, \"IrisinScore_Z\")  # robustness\n",
    "    if RUN_PART_D:\n",
    "        for k, g in NT_SIGS.items():\n",
    "            score_geneset_simple(adata, g, f\"NT_{k}\")\n",
    "    if RUN_PART_E:\n",
    "        score_geneset_simple(adata, EXERCISE_MODULE, \"ExerciseModuleScore\")\n",
    "\n",
    "# Extract FNDC5 expression on ALL cohorts\n",
    "\n",
    "for cname, adata in cohorts.items():\n",
    "    if \"FNDC5\" in adata.var_names:\n",
    "        idx = int(np.where(adata.var_names == \"FNDC5\")[0][0])\n",
    "        if sp.issparse(adata.X):\n",
    "            f = np.asarray(adata.X[:, idx].todense()).ravel()\n",
    "        else:\n",
    "            f = np.asarray(adata.X[:, idx]).ravel()\n",
    "        adata.obs[\"FNDC5_expr_X\"] = f\n",
    "        log(f\"  {cname}: FNDC5 mean={np.nanmean(f):.4f}, frac>0={np.nanmean(f>0):.4f}\")\n",
    "    else:\n",
    "        adata.obs[\"FNDC5_expr_X\"] = np.nan\n",
    "        log(f\"  {cname}: FNDC5 not found\")\n",
    "\n",
    "# Primary: SEA-AD donor table\n",
    "\n",
    "sea = cohorts[\"SEA-AD\"]\n",
    "sea_d, sea_meta = make_donor_df(sea, \"SEA-AD\")\n",
    "covars = sea_meta[\"covariates\"]\n",
    "tol_col = sea_meta[\"tol_col\"]\n",
    "\n",
    "log(f\"SEA-AD donor table: {sea_d.shape[0]} donors\")\n",
    "log(f\"Status: {sea_d['status_label'].iloc[0] if len(sea_d) else 'NA'}\")\n",
    "log(f\"Status counts:\\n{sea_d['status'].value_counts(dropna=False)}\")\n",
    "log(f\"Age group counts:\\n{sea_d['age_group'].value_counts(dropna=False)}\")\n",
    "log(f\"Covariates available: {covars}\")\n",
    "\n",
    "# Add FNDC5 donor mean\n",
    "if sea_meta[\"donor_col\"] and sea_meta[\"donor_col\"] in sea.obs.columns:\n",
    "    tmp = donor_aggregate(sea, sea_meta[\"donor_col\"], [\"FNDC5_expr_X\"])\n",
    "    tmp = tmp.rename(columns={\"FNDC5_expr_X\": \"FNDC5_donor_mean\"})\n",
    "    sea_d = sea_d.merge(tmp[[\"donor_id\",\"FNDC5_donor_mean\"]], on=\"donor_id\", how=\"left\")\n",
    "else:\n",
    "    sea_d[\"FNDC5_donor_mean\"] = np.nan\n",
    "\n",
    "# Scoring robustness check\n",
    "r_scoring = corr_with_pvalue(sea_d[\"IrisinScore\"], sea_d.get(\"IrisinScore_Z\", pd.Series(dtype=float)),\n",
    "                             method=\"spearman\")\n",
    "log(f\"IrisinScore vs IrisinScore_Z (robustness): r={r_scoring['r']:.3f}, p={r_scoring['p']:.2e}\")\n",
    "\n",
    "# PART A: AGE STRATIFICATION (SEA-AD)\n",
    "\n",
    "def partA_age(sea_d, covars):\n",
    "    log(\"=\" * 50)\n",
    "    log(\"PART A: Age Stratification\")\n",
    "\n",
    "    age_groups_all = [\"<65\", \"65-79\", \">=80\"]\n",
    "    age_groups = [ag for ag in age_groups_all\n",
    "                  if (sea_d[\"age_group\"].astype(str)==ag).sum() >= MIN_DONORS_PER_GROUP]\n",
    "\n",
    "    if len(age_groups) == 0:\n",
    "        log(\"[A] No age groups with sufficient donors; skipping.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # A1: Stratified correlations with p-values + CIs\n",
    "    rows = []\n",
    "    for ag in age_groups:\n",
    "        sub = sea_d[sea_d[\"age_group\"].astype(str)==ag].copy()\n",
    "        for mes in [c for c in MES_COLS if c in sub.columns]:\n",
    "            # GR vs MES\n",
    "            if GR_COL in sub.columns:\n",
    "                raw = corr_with_pvalue(sub[GR_COL], sub[mes], method=\"spearman\")\n",
    "                pcr = partial_corr(sub, GR_COL, mes, covars, method=\"spearman\")\n",
    "                rows.append({\n",
    "                    \"age_group\": ag, \"target\": \"GR\", \"MES\": mes.replace(\"_score\",\"\"),\n",
    "                    \"r_spearman\": raw[\"r\"], \"p_spearman\": raw[\"p\"],\n",
    "                    \"ci_lo\": raw[\"ci_lo\"], \"ci_hi\": raw[\"ci_hi\"],\n",
    "                    \"r_partial\": pcr[\"r\"], \"p_partial\": pcr[\"p\"],\n",
    "                    \"N\": raw[\"n\"]\n",
    "                })\n",
    "            # Tolerance vs MES\n",
    "            if tol_col and tol_col in sub.columns:\n",
    "                raw = corr_with_pvalue(sub[tol_col], sub[mes], method=\"spearman\")\n",
    "                pcr = partial_corr(sub, tol_col, mes, covars, method=\"spearman\")\n",
    "                rows.append({\n",
    "                    \"age_group\": ag, \"target\": \"tolerance\", \"MES\": mes.replace(\"_score\",\"\"),\n",
    "                    \"r_spearman\": raw[\"r\"], \"p_spearman\": raw[\"p\"],\n",
    "                    \"ci_lo\": raw[\"ci_lo\"], \"ci_hi\": raw[\"ci_hi\"],\n",
    "                    \"r_partial\": pcr[\"r\"], \"p_partial\": pcr[\"p\"],\n",
    "                    \"N\": raw[\"n\"]\n",
    "                })\n",
    "\n",
    "    df_corr = pd.DataFrame(rows)\n",
    "    if len(df_corr):\n",
    "        df_corr[\"q_BH\"] = bh_fdr(df_corr[\"p_spearman\"].values)\n",
    "        df_corr[\"q_partial_BH\"] = bh_fdr(df_corr[\"p_partial\"].values)\n",
    "\n",
    "    # A2: Interaction tests MES ~ GR + age + GR*age [+ covars]\n",
    "    inter_rows = []\n",
    "    if \"age_years\" in sea_d.columns and GR_COL in sea_d.columns:\n",
    "        for mes in [c for c in MES_COLS if c in sea_d.columns]:\n",
    "            out = fit_interaction_ols(sea_d, y=mes, x=GR_COL, z=\"age_years\", covars=covars)\n",
    "            inter_rows.append({\"MES\": mes.replace(\"_score\",\"\"), **out})\n",
    "    df_inter = pd.DataFrame(inter_rows)\n",
    "    if len(df_inter) and \"p_xz\" in df_inter.columns:\n",
    "        df_inter[\"q_xz_BH\"] = bh_fdr(df_inter[\"p_xz\"].values)\n",
    "\n",
    "    # Figure 6A: Heatmap\n",
    "    mes_names = [m for m in MES_COLS if m in sea_d.columns]\n",
    "    ags_ok, mat = [], []\n",
    "    for ag in age_groups:\n",
    "        sub = sea_d[sea_d[\"age_group\"].astype(str)==ag]\n",
    "        if sub.shape[0] == 0:\n",
    "            continue\n",
    "        ags_ok.append(f\"{ag}\\n(n={sub.shape[0]})\")\n",
    "        mat.append([float(np.nanmean(pd.to_numeric(sub[m], errors=\"coerce\"))) for m in mes_names])\n",
    "    mat = np.array(mat, float)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.0, 2.2))\n",
    "    if HAS_SNS:\n",
    "        sns.heatmap(mat, ax=ax, annot=True, fmt=\".3f\", cmap=\"RdBu_r\",\n",
    "                    center=0, linewidths=0.5, linecolor=\"white\",\n",
    "                    xticklabels=[m.replace(\"_score\",\"\") for m in mes_names],\n",
    "                    yticklabels=ags_ok, cbar_kws={\"label\": \"Mean MES score\", \"shrink\": 0.8})\n",
    "    else:\n",
    "        im = ax.imshow(mat, aspect=\"auto\", cmap=\"RdBu_r\")\n",
    "        ax.set_yticks(np.arange(len(ags_ok))); ax.set_yticklabels(ags_ok)\n",
    "        ax.set_xticks(np.arange(len(mes_names)))\n",
    "        ax.set_xticklabels([m.replace(\"_score\",\"\") for m in mes_names], rotation=45, ha=\"right\")\n",
    "        plt.colorbar(im, ax=ax, label=\"Mean MES score\", shrink=0.8)\n",
    "    ax.set_title(\"SEA-AD: Age-stratified MES means (donor-level)\")\n",
    "    save_fig(FIG_DIR / \"Main_Fig6A_AgeStrat_MES_Means.png\", fig)\n",
    "\n",
    "    return df_corr, df_inter\n",
    "\n",
    "\n",
    "# PART B: NEUROPATHOLOGY / CLINICAL PROGRESSION\n",
    "\n",
    "def partB_status(sea_d, covars):\n",
    "    log(\"=\" * 50)\n",
    "    log(\"PART B: Status Progression\")\n",
    "\n",
    "    if \"status\" not in sea_d.columns:\n",
    "        log(\"[B] No status column; skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    label = str(sea_d[\"status_label\"].iloc[0]) if len(sea_d) else \"NA\"\n",
    "\n",
    "    if label == \"Clinical\":\n",
    "        g1, g2 = \"Control\", \"AD\"\n",
    "        ylab = \"Cohen's d (AD − Control)\"\n",
    "    else:\n",
    "        g1, g2 = \"LowPath\", \"HighPath\"\n",
    "        ylab = \"Cohen's d (HighPath − LowPath)\"\n",
    "\n",
    "    sub = sea_d[sea_d[\"status\"].astype(str).isin([g1, g2])].copy()\n",
    "    n1 = int((sub[\"status\"].astype(str)==g1).sum())\n",
    "    n2 = int((sub[\"status\"].astype(str)==g2).sum())\n",
    "    if n1 < MIN_DONORS_PER_GROUP or n2 < MIN_DONORS_PER_GROUP:\n",
    "        log(f\"[B] Too few donors ({g1}={n1}, {g2}={n2}); skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Features to test\n",
    "    features = [c for c in MES_COLS if c in sub.columns]\n",
    "    extra = []\n",
    "    if tol_col and tol_col in sub.columns: extra.append(tol_col)\n",
    "    if GR_COL in sub.columns: extra.append(GR_COL)\n",
    "    if \"IrisinScore\" in sub.columns: extra.append(\"IrisinScore\")\n",
    "    if \"ExerciseModuleScore\" in sub.columns: extra.append(\"ExerciseModuleScore\")\n",
    "    for k in NT_SIGS:\n",
    "        c = f\"NT_{k}\"\n",
    "        if c in sub.columns: extra.append(c)\n",
    "    features += extra\n",
    "\n",
    "    rows = []\n",
    "    for feat in features:\n",
    "        a = pd.to_numeric(sub.loc[sub[\"status\"].astype(str)==g1, feat], errors=\"coerce\").to_numpy()\n",
    "        b = pd.to_numeric(sub.loc[sub[\"status\"].astype(str)==g2, feat], errors=\"coerce\").to_numpy()\n",
    "        res = cohen_d_with_ci(a, b)\n",
    "        rows.append({\n",
    "            \"feature\": feat.replace(\"_score\",\"\"),\n",
    "            \"d\": res[\"d\"], \"d_ci_lo\": res[\"ci_lo\"], \"d_ci_hi\": res[\"ci_hi\"],\n",
    "            \"mw_U\": res[\"mw_U\"], \"mw_p\": res[\"mw_p\"],\n",
    "            \"mean_g1\": res[\"mean_x\"], \"mean_g2\": res[\"mean_y\"],\n",
    "            \"sd_g1\": res[\"sd_x\"], \"sd_g2\": res[\"sd_y\"],\n",
    "            \"n_g1\": res[\"n_x\"], \"n_g2\": res[\"n_y\"],\n",
    "            \"group1\": g1, \"group2\": g2\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if len(df):\n",
    "        df[\"mw_q_BH\"] = bh_fdr(df[\"mw_p\"].values)\n",
    "    df = df.sort_values(\"d\", ascending=False)\n",
    "\n",
    "    # Figure 6B: Cohen's d with CIs and significance\n",
    "    fig, ax = plt.subplots(figsize=(9.0, 3.5))\n",
    "    x_pos = np.arange(len(df))\n",
    "    colors = [PALETTE_STATUS.get(g2, \"#D6604D\") if d > 0 else PALETTE_STATUS.get(g1, \"#4393C3\")\n",
    "              for d in df[\"d\"].values]\n",
    "\n",
    "    bars = ax.bar(x_pos, df[\"d\"].values, color=colors, edgecolor=\"black\", linewidth=0.5, alpha=0.85)\n",
    "\n",
    "    # Error bars from bootstrap CI\n",
    "    yerr_lo = df[\"d\"].values - df[\"d_ci_lo\"].values\n",
    "    yerr_hi = df[\"d_ci_hi\"].values - df[\"d\"].values\n",
    "    ax.errorbar(x_pos, df[\"d\"].values,\n",
    "                yerr=[yerr_lo, yerr_hi],\n",
    "                fmt=\"none\", ecolor=\"black\", elinewidth=0.8, capsize=2.5, capthick=0.8)\n",
    "\n",
    "    # Significance stars\n",
    "    for i, (_, row) in enumerate(df.iterrows()):\n",
    "        star = sig_stars(row.get(\"mw_q_BH\", row.get(\"mw_p\")))\n",
    "        if star != \"ns\":\n",
    "            y_off = row[\"d_ci_hi\"] + 0.03 if row[\"d\"] > 0 else row[\"d_ci_lo\"] - 0.06\n",
    "            ax.text(i, y_off, star, ha=\"center\", va=\"bottom\" if row[\"d\"]>0 else \"top\",\n",
    "                    fontsize=7, fontweight=\"bold\")\n",
    "\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(df[\"feature\"].values, rotation=55, ha=\"right\")\n",
    "    ax.axhline(0, color=\"black\", linewidth=0.8)\n",
    "    ax.set_ylabel(ylab)\n",
    "    ax.set_title(f\"SEA-AD: {g2} vs {g1} (n={n1} vs {n2}) | bars=Cohen's d, whiskers=95% CI\")\n",
    "    if HAS_SNS: sns.despine(ax=ax)\n",
    "    save_fig(FIG_DIR / f\"Main_Fig6B_{'AD' if label=='Clinical' else 'Pathology'}_Effects_CohenD.png\", fig)\n",
    "\n",
    "    tab_name = \"Supplementary_Table6_AD_Differential.xlsx\" if label==\"Clinical\" else \"Supplementary_Table6_Pathology_Differential.xlsx\"\n",
    "    save_xlsx(df, TAB_DIR / tab_name)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# PART C: FNDC5 / IRISIN DEEP DIVE\n",
    "\n",
    "def partC_irisin(sea, sea_d, covars):\n",
    "    log(\"=\" * 50)\n",
    "    log(\"PART C: FNDC5 / Irisin Deep Dive\")\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # C1: IrisinScore vs MES/tolerance by age group with stats\n",
    "    if \"age_group\" in sea_d.columns:\n",
    "        for ag in [\"<65\", \"65-79\", \">=80\"]:\n",
    "            sub = sea_d[sea_d[\"age_group\"].astype(str)==ag]\n",
    "            if sub.shape[0] < MIN_DONORS_PER_GROUP:\n",
    "                continue\n",
    "            for mes in [c for c in MES_COLS if c in sub.columns]:\n",
    "                raw = corr_with_pvalue(sub[\"IrisinScore\"], sub[mes], method=\"spearman\")\n",
    "                rows.append({\n",
    "                    \"stratum\": \"age_group\", \"group\": ag, \"target\": mes.replace(\"_score\",\"\"),\n",
    "                    \"assoc\": \"Irisin×MES\",\n",
    "                    \"r\": raw[\"r\"], \"p\": raw[\"p\"],\n",
    "                    \"ci_lo\": raw[\"ci_lo\"], \"ci_hi\": raw[\"ci_hi\"],\n",
    "                    \"N\": raw[\"n\"]\n",
    "                })\n",
    "            if tol_col and tol_col in sub.columns:\n",
    "                raw = corr_with_pvalue(sub[\"IrisinScore\"], sub[tol_col], method=\"spearman\")\n",
    "                rows.append({\n",
    "                    \"stratum\": \"age_group\", \"group\": ag, \"target\": tol_col,\n",
    "                    \"assoc\": \"Irisin×tolerance\",\n",
    "                    \"r\": raw[\"r\"], \"p\": raw[\"p\"],\n",
    "                    \"ci_lo\": raw[\"ci_lo\"], \"ci_hi\": raw[\"ci_hi\"],\n",
    "                    \"N\": raw[\"n\"]\n",
    "                })\n",
    "\n",
    "    # C2: Overall correlations\n",
    "    for target_name, target_col in [(\"GR\", GR_COL), (\"tolerance\", tol_col)]:\n",
    "        if target_col and target_col in sea_d.columns:\n",
    "            raw = corr_with_pvalue(sea_d[\"IrisinScore\"], sea_d[target_col], method=\"spearman\")\n",
    "            pcr = partial_corr(sea_d, \"IrisinScore\", target_col, covars, method=\"spearman\")\n",
    "            rows.append({\n",
    "                \"stratum\": \"all\", \"group\": \"all\", \"target\": target_name,\n",
    "                \"assoc\": f\"Irisin×{target_name}\",\n",
    "                \"r\": raw[\"r\"], \"p\": raw[\"p\"],\n",
    "                \"ci_lo\": raw[\"ci_lo\"], \"ci_hi\": raw[\"ci_hi\"],\n",
    "                \"r_partial\": pcr[\"r\"], \"p_partial\": pcr[\"p\"],\n",
    "                \"N\": raw[\"n\"]\n",
    "            })\n",
    "\n",
    "    # C3: FNDC5_donor_mean vs IrisinScore\n",
    "    raw = corr_with_pvalue(sea_d[\"FNDC5_donor_mean\"], sea_d[\"IrisinScore\"], method=\"spearman\")\n",
    "    rows.append({\n",
    "        \"stratum\": \"all\", \"group\": \"all\", \"target\": \"FNDC5_donor_mean\",\n",
    "        \"assoc\": \"FNDC5_expr×IrisinScore\",\n",
    "        \"r\": raw[\"r\"], \"p\": raw[\"p\"],\n",
    "        \"ci_lo\": raw[\"ci_lo\"], \"ci_hi\": raw[\"ci_hi\"],\n",
    "        \"N\": raw[\"n\"]\n",
    "    })\n",
    "\n",
    "    # C4: Permutation test for key irisin-tolerance link\n",
    "    if tol_col and tol_col in sea_d.columns:\n",
    "        perm_p = permutation_test_corr(sea_d[\"IrisinScore\"], sea_d[tol_col],\n",
    "                                       method=\"spearman\", n_perm=N_PERM)\n",
    "        rows.append({\n",
    "            \"stratum\": \"all\", \"group\": \"all\", \"target\": \"tolerance_permutation\",\n",
    "            \"assoc\": \"Irisin×tolerance (permutation)\",\n",
    "            \"r\": np.nan, \"p\": perm_p,\n",
    "            \"ci_lo\": np.nan, \"ci_hi\": np.nan,\n",
    "            \"N\": int(sea_d.shape[0])\n",
    "        })\n",
    "        log(f\"  Irisin×tolerance permutation p = {perm_p:.4f}\")\n",
    "\n",
    "    df_ir = pd.DataFrame(rows)\n",
    "    if len(df_ir) and \"p\" in df_ir.columns:\n",
    "        df_ir[\"q_BH\"] = bh_fdr(df_ir[\"p\"].values)\n",
    "\n",
    "    # Figure 6C: IrisinScore vs tolerance by status\n",
    "    label = str(sea_d[\"status_label\"].iloc[0]) if len(sea_d) else \"NA\"\n",
    "    g1 = \"Control\" if label==\"Clinical\" else \"LowPath\"\n",
    "    g2 = \"AD\" if label==\"Clinical\" else \"HighPath\"\n",
    "    has_groups = sea_d[\"status\"].astype(str).isin([g1, g2]).any()\n",
    "\n",
    "    if tol_col and tol_col in sea_d.columns and has_groups:\n",
    "        sub = sea_d[sea_d[\"status\"].astype(str).isin([g1, g2])].copy()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8.5, 3.5), sharey=True)\n",
    "\n",
    "        for ax, grp, color in zip(axes, [g1, g2],\n",
    "                                  [PALETTE_STATUS[g1], PALETTE_STATUS[g2]]):\n",
    "            ss = sub[sub[\"status\"].astype(str)==grp]\n",
    "            x = pd.to_numeric(ss[\"IrisinScore\"], errors=\"coerce\")\n",
    "            y = pd.to_numeric(ss[tol_col], errors=\"coerce\")\n",
    "            ax.scatter(x, y, s=22, alpha=0.7, color=color, edgecolors=\"black\", linewidth=0.3)\n",
    "\n",
    "            # Regression line\n",
    "            m = np.isfinite(x) & np.isfinite(y)\n",
    "            if m.sum() > 5:\n",
    "                z = np.polyfit(x[m], y[m], 1)\n",
    "                xline = np.linspace(np.nanmin(x[m]), np.nanmax(x[m]), 100)\n",
    "                ax.plot(xline, np.polyval(z, xline), color=\"black\", linewidth=1.0, linestyle=\"--\")\n",
    "\n",
    "            raw = corr_with_pvalue(x, y, method=\"spearman\")\n",
    "            star = sig_stars(raw[\"p\"])\n",
    "            ax.set_title(f\"{grp} (n={ss.shape[0]})\\nρ={raw['r']:.2f} [{raw['ci_lo']:.2f}, {raw['ci_hi']:.2f}] {star}\",\n",
    "                        fontsize=8)\n",
    "            ax.set_xlabel(\"IrisinScore\")\n",
    "            ax.axhline(0, color=\"grey\", linewidth=0.5, linestyle=\":\")\n",
    "            if HAS_SNS: sns.despine(ax=ax)\n",
    "\n",
    "        axes[0].set_ylabel(tol_col)\n",
    "        fig.suptitle(\"SEA-AD: IrisinScore vs Tolerance (donor-level)\", fontsize=9, y=1.02)\n",
    "        fig.tight_layout()\n",
    "        save_fig(FIG_DIR / f\"Main_Fig6C_Irisin_vs_Tolerance_{g1}_vs_{g2}.png\", fig)\n",
    "\n",
    "    elif tol_col and tol_col in sea_d.columns:\n",
    "        # Single panel\n",
    "        fig, ax = plt.subplots(figsize=(5.5, 4.5))\n",
    "        x = pd.to_numeric(sea_d[\"IrisinScore\"], errors=\"coerce\")\n",
    "        y = pd.to_numeric(sea_d[tol_col], errors=\"coerce\")\n",
    "        ax.scatter(x, y, s=30, alpha=0.7, color=\"#4393C3\", edgecolors=\"black\", linewidth=0.3)\n",
    "        m = np.isfinite(x) & np.isfinite(y)\n",
    "        if m.sum() > 5:\n",
    "            z = np.polyfit(x[m], y[m], 1)\n",
    "            xline = np.linspace(np.nanmin(x[m]), np.nanmax(x[m]), 100)\n",
    "            ax.plot(xline, np.polyval(z, xline), color=\"black\", linewidth=1.0, linestyle=\"--\")\n",
    "        raw = corr_with_pvalue(x, y, method=\"spearman\")\n",
    "        star = sig_stars(raw[\"p\"])\n",
    "        ax.set_title(f\"All donors (n={raw['n']})\\nρ={raw['r']:.2f} [{raw['ci_lo']:.2f}, {raw['ci_hi']:.2f}] {star}\")\n",
    "        ax.set_xlabel(\"IrisinScore\"); ax.set_ylabel(tol_col)\n",
    "        if HAS_SNS: sns.despine(ax=ax)\n",
    "        save_fig(FIG_DIR / \"Main_Fig6C_Irisin_vs_Tolerance_All.png\", fig)\n",
    "\n",
    "    # Save donor table\n",
    "    sea_d.to_csv(TAB_DIR / \"NB6_SEA_AD_DonorTable.csv\", index=False)\n",
    "    log(f\"SAVED {TAB_DIR / 'NB6_SEA_AD_DonorTable.csv'}\")\n",
    "\n",
    "    return df_ir\n",
    "\n",
    "\n",
    "# PART D: NEUROTRANSMITTER SIGNATURES \n",
    "\n",
    "def partD_neurotransmitters(sea_d, covars):\n",
    "    log(\"=\" * 50)\n",
    "    log(\"PART D: Neurotransmitter Signatures\")\n",
    "\n",
    "    nt_cols = [f\"NT_{k}\" for k in NT_SIGS if f\"NT_{k}\" in sea_d.columns]\n",
    "    if not nt_cols:\n",
    "        log(\"[D] No NT columns; skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    for nt in nt_cols:\n",
    "        for mes in [c for c in MES_COLS if c in sea_d.columns]:\n",
    "            raw = corr_with_pvalue(sea_d[nt], sea_d[mes], method=\"spearman\")\n",
    "            rows.append({\"NT\": nt, \"MES\": mes.replace(\"_score\",\"\"),\n",
    "                         \"r\": raw[\"r\"], \"p\": raw[\"p\"],\n",
    "                         \"ci_lo\": raw[\"ci_lo\"], \"ci_hi\": raw[\"ci_hi\"],\n",
    "                         \"N\": raw[\"n\"]})\n",
    "    df = pd.DataFrame(rows)\n",
    "    if len(df):\n",
    "        df[\"q_BH\"] = bh_fdr(df[\"p\"].values)\n",
    "\n",
    "    # Heatmap with significance\n",
    "    piv_r = df.pivot_table(index=\"NT\", columns=\"MES\", values=\"r\", aggfunc=\"mean\")\n",
    "    piv_q = df.pivot_table(index=\"NT\", columns=\"MES\", values=\"q_BH\", aggfunc=\"mean\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8.0, 2.8))\n",
    "    if HAS_SNS:\n",
    "        sns.heatmap(piv_r, ax=ax, annot=True, fmt=\".2f\", cmap=\"RdBu_r\", center=0,\n",
    "                    linewidths=0.5, linecolor=\"white\",\n",
    "                    cbar_kws={\"label\": \"Spearman ρ\", \"shrink\": 0.8})\n",
    "        # Add significance markers\n",
    "        for i, nt in enumerate(piv_r.index):\n",
    "            for j, mes in enumerate(piv_r.columns):\n",
    "                q = piv_q.loc[nt, mes] if nt in piv_q.index and mes in piv_q.columns else np.nan\n",
    "                s = sig_stars(q)\n",
    "                if s != \"ns\":\n",
    "                    ax.text(j+0.5, i+0.82, s, ha=\"center\", va=\"center\", fontsize=6, color=\"black\")\n",
    "    else:\n",
    "        im = ax.imshow(piv_r.values, aspect=\"auto\", cmap=\"RdBu_r\")\n",
    "        ax.set_yticks(range(piv_r.shape[0])); ax.set_yticklabels(piv_r.index)\n",
    "        ax.set_xticks(range(piv_r.shape[1])); ax.set_xticklabels(piv_r.columns, rotation=45, ha=\"right\")\n",
    "        plt.colorbar(im, ax=ax, label=\"Spearman ρ\", shrink=0.8)\n",
    "    ax.set_title(\"SEA-AD: Neurotransmitter signatures vs MES (donor-level)\")\n",
    "    save_fig(FIG_DIR / \"Supp_Fig6D_NT_Sigs.png\", fig)\n",
    "\n",
    "    return df\n",
    "\n",
    "# PART E: EXERCISE MODULE \n",
    "\n",
    "def partE_exercise(sea_d, covars):\n",
    "    log(\"=\" * 50)\n",
    "    log(\"PART E: Exercise Module\")\n",
    "\n",
    "    if \"ExerciseModuleScore\" not in sea_d.columns:\n",
    "        log(\"[E] ExerciseModuleScore missing; skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    for mes in [c for c in MES_COLS if c in sea_d.columns]:\n",
    "        raw = corr_with_pvalue(sea_d[\"ExerciseModuleScore\"], sea_d[mes], method=\"spearman\")\n",
    "        pcr = partial_corr(sea_d, \"ExerciseModuleScore\", mes, covars, method=\"spearman\")\n",
    "        rows.append({\"MES\": mes.replace(\"_score\",\"\"),\n",
    "                     \"r\": raw[\"r\"], \"p\": raw[\"p\"],\n",
    "                     \"ci_lo\": raw[\"ci_lo\"], \"ci_hi\": raw[\"ci_hi\"],\n",
    "                     \"r_partial\": pcr[\"r\"], \"p_partial\": pcr[\"p\"],\n",
    "                     \"N\": raw[\"n\"]})\n",
    "    df = pd.DataFrame(rows)\n",
    "    if len(df):\n",
    "        df[\"q_BH\"] = bh_fdr(df[\"p\"].values)\n",
    "    df = df.sort_values(\"r\", ascending=False)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.0, 3.0))\n",
    "    colors = [\"#66C2A5\" if r > 0 else \"#FC8D62\" for r in df[\"r\"].values]\n",
    "    ax.bar(df[\"MES\"], df[\"r\"].values, color=colors, edgecolor=\"black\", linewidth=0.5)\n",
    "    yerr_lo = df[\"r\"].values - df[\"ci_lo\"].values\n",
    "    yerr_hi = df[\"ci_hi\"].values - df[\"r\"].values\n",
    "    ax.errorbar(np.arange(len(df)), df[\"r\"].values,\n",
    "                yerr=[yerr_lo, yerr_hi],\n",
    "                fmt=\"none\", ecolor=\"black\", elinewidth=0.8, capsize=2.5)\n",
    "    for i, (_, row) in enumerate(df.iterrows()):\n",
    "        s = sig_stars(row.get(\"q_BH\", row[\"p\"]))\n",
    "        if s != \"ns\":\n",
    "            y = row[\"ci_hi\"] + 0.02 if row[\"r\"] > 0 else row[\"ci_lo\"] - 0.03\n",
    "            ax.text(i, y, s, ha=\"center\", va=\"bottom\" if row[\"r\"]>0 else \"top\", fontsize=7, fontweight=\"bold\")\n",
    "    ax.axhline(0, color=\"black\", linewidth=0.8)\n",
    "    ax.set_ylabel(\"Spearman ρ\"); ax.set_title(\"SEA-AD: Exercise module × MES (donor-level)\")\n",
    "    ax.set_xticklabels(df[\"MES\"], rotation=45, ha=\"right\")\n",
    "    if HAS_SNS: sns.despine(ax=ax)\n",
    "    save_fig(FIG_DIR / \"Supp_Fig6E_Exercise_Module.png\", fig)\n",
    "\n",
    "    return df\n",
    "\n",
    "# PART F: CROSS-COHORT VALIDATION\n",
    "\n",
    "def partF_cross_cohort(cohorts, covars_sea):\n",
    "    log(\"=\" * 50)\n",
    "    log(\"PART F: Cross-Cohort Validation\")\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for cname, adata in cohorts.items():\n",
    "        log(f\"  Processing {cname} ...\")\n",
    "        ddf, meta = make_donor_df(adata, cname)\n",
    "        local_covars = meta[\"covariates\"]\n",
    "        local_tol = meta[\"tol_col\"]\n",
    "        label = str(ddf[\"status_label\"].iloc[0]) if len(ddf) else \"NA\"\n",
    "\n",
    "        if label == \"Clinical\":\n",
    "            g1, g2 = \"Control\", \"AD\"\n",
    "        else:\n",
    "            g1, g2 = \"LowPath\", \"HighPath\"\n",
    "\n",
    "        n1 = (ddf[\"status\"].astype(str)==g1).sum()\n",
    "        n2 = (ddf[\"status\"].astype(str)==g2).sum()\n",
    "\n",
    "        # Effect sizes for MES + key features\n",
    "        for feat in [c for c in MES_COLS if c in ddf.columns] + \\\n",
    "                     ([GR_COL] if GR_COL in ddf.columns else []) + \\\n",
    "                     ([\"IrisinScore\"] if \"IrisinScore\" in ddf.columns else []):\n",
    "\n",
    "            if n1 >= MIN_DONORS_PER_GROUP and n2 >= MIN_DONORS_PER_GROUP:\n",
    "                a = pd.to_numeric(ddf.loc[ddf[\"status\"].astype(str)==g1, feat], errors=\"coerce\").to_numpy()\n",
    "                b = pd.to_numeric(ddf.loc[ddf[\"status\"].astype(str)==g2, feat], errors=\"coerce\").to_numpy()\n",
    "                res = cohen_d_with_ci(a, b)\n",
    "            else:\n",
    "                res = {\"d\": np.nan, \"ci_lo\": np.nan, \"ci_hi\": np.nan,\n",
    "                       \"mw_p\": np.nan, \"n_x\": int(n1), \"n_y\": int(n2)}\n",
    "\n",
    "            # Irisin-tolerance correlation\n",
    "            ir_tol_r = np.nan\n",
    "            if local_tol and local_tol in ddf.columns and \"IrisinScore\" in ddf.columns:\n",
    "                ir_corr = corr_with_pvalue(ddf[\"IrisinScore\"], ddf[local_tol], method=\"spearman\")\n",
    "                ir_tol_r = ir_corr[\"r\"]\n",
    "\n",
    "            all_rows.append({\n",
    "                \"cohort\": cname, \"feature\": feat.replace(\"_score\",\"\"),\n",
    "                \"status_type\": label, \"g1\": g1, \"g2\": g2,\n",
    "                \"d\": res[\"d\"], \"d_ci_lo\": res[\"ci_lo\"], \"d_ci_hi\": res[\"ci_hi\"],\n",
    "                \"mw_p\": res.get(\"mw_p\", np.nan),\n",
    "                \"n_g1\": res.get(\"n_x\", int(n1)), \"n_g2\": res.get(\"n_y\", int(n2)),\n",
    "                \"n_donors\": int(len(ddf)),\n",
    "                \"irisin_tol_r\": ir_tol_r\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    if len(df):\n",
    "        df[\"mw_q_BH\"] = bh_fdr(df[\"mw_p\"].values)\n",
    "\n",
    "    # Forest plot: Cohen's d across cohorts for GR_composite\n",
    "    gr_df = df[df[\"feature\"]==GR_COL.replace(\"_score\",\"\")].copy()\n",
    "    if len(gr_df) > 1:\n",
    "        gr_df = gr_df.sort_values(\"d\")\n",
    "        fig, ax = plt.subplots(figsize=(6.0, max(2.5, 0.4*len(gr_df))))\n",
    "        y_pos = np.arange(len(gr_df))\n",
    "\n",
    "        for i, (_, row) in enumerate(gr_df.iterrows()):\n",
    "            color = \"#D6604D\" if row[\"d\"] > 0 else \"#4393C3\"\n",
    "            ax.errorbar(row[\"d\"], i,\n",
    "                       xerr=[[row[\"d\"]-row[\"d_ci_lo\"]], [row[\"d_ci_hi\"]-row[\"d\"]]],\n",
    "                       fmt=\"o\", color=color, ecolor=\"black\", elinewidth=0.8,\n",
    "                       capsize=3, markersize=6)\n",
    "            star = sig_stars(row.get(\"mw_q_BH\", row[\"mw_p\"]))\n",
    "            ax.text(row[\"d_ci_hi\"]+0.05, i, f'{star}  n={row[\"n_g1\"]}+{row[\"n_g2\"]}',\n",
    "                   va=\"center\", fontsize=7)\n",
    "\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(gr_df[\"cohort\"].values)\n",
    "        ax.axvline(0, color=\"black\", linewidth=0.8, linestyle=\"--\")\n",
    "        ax.set_xlabel(\"Cohen's d (High − Low pathology)\")\n",
    "        ax.set_title(\"Cross-cohort: GR composite effect sizes\")\n",
    "        if HAS_SNS: sns.despine(ax=ax)\n",
    "        save_fig(FIG_DIR / \"Supp_Fig6F_CrossCohort_ForestPlot.png\", fig)\n",
    "\n",
    "    # Save\n",
    "    save_xlsx(df, TAB_DIR / \"Supplementary_Table6_CrossCohort.xlsx\")\n",
    "    df.to_csv(TAB_DIR / \"NB6_CrossCohort_Summary.csv\", index=False)\n",
    "    log(f\"SAVED {TAB_DIR / 'NB6_CrossCohort_Summary.csv'}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# PART G: SENSITIVITY ANALYSES\n",
    "\n",
    "def partG_sensitivity(sea, sea_d_orig, covars):\n",
    "    log(\"=\" * 50)\n",
    "    log(\"PART G: Sensitivity Analyses\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # G1: Different Braak/CERAD thresholds\n",
    "    threshold_schemes = [\n",
    "        {\"name\": \"Braak≥3/CERAD≥1 (liberal)\",  \"braak\": 3, \"cerad\": 1},\n",
    "        {\"name\": \"Braak≥4/CERAD≥2 (default)\",   \"braak\": 4, \"cerad\": 2},\n",
    "        {\"name\": \"Braak≥5/CERAD≥2 (strict)\",    \"braak\": 5, \"cerad\": 2},\n",
    "        {\"name\": \"Braak≥5/CERAD≥3 (very strict)\",\"braak\": 5, \"cerad\": 3},\n",
    "    ]\n",
    "\n",
    "    thresh_rows = []\n",
    "    for scheme in threshold_schemes:\n",
    "        ddf, meta = make_donor_df(sea, \"SEA-AD\",\n",
    "                                  braak_thresh=scheme[\"braak\"],\n",
    "                                  cerad_thresh=scheme[\"cerad\"])\n",
    "        label = str(ddf[\"status_label\"].iloc[0]) if len(ddf) else \"NA\"\n",
    "        g1 = \"Control\" if label==\"Clinical\" else \"LowPath\"\n",
    "        g2 = \"AD\" if label==\"Clinical\" else \"HighPath\"\n",
    "\n",
    "        n1 = (ddf[\"status\"].astype(str)==g1).sum()\n",
    "        n2 = (ddf[\"status\"].astype(str)==g2).sum()\n",
    "\n",
    "        for feat in [c for c in MES_COLS if c in ddf.columns] + \\\n",
    "                     ([GR_COL] if GR_COL in ddf.columns else []):\n",
    "            if n1 >= MIN_DONORS_PER_GROUP and n2 >= MIN_DONORS_PER_GROUP:\n",
    "                a = pd.to_numeric(ddf.loc[ddf[\"status\"].astype(str)==g1, feat], errors=\"coerce\").to_numpy()\n",
    "                b = pd.to_numeric(ddf.loc[ddf[\"status\"].astype(str)==g2, feat], errors=\"coerce\").to_numpy()\n",
    "                res = cohen_d_with_ci(a, b, n_boot=500)  # fewer boots for speed\n",
    "            else:\n",
    "                res = {\"d\": np.nan, \"ci_lo\": np.nan, \"ci_hi\": np.nan, \"mw_p\": np.nan}\n",
    "\n",
    "            thresh_rows.append({\n",
    "                \"scheme\": scheme[\"name\"],\n",
    "                \"braak_thresh\": scheme[\"braak\"], \"cerad_thresh\": scheme[\"cerad\"],\n",
    "                \"feature\": feat.replace(\"_score\",\"\"),\n",
    "                \"d\": res[\"d\"], \"d_ci_lo\": res[\"ci_lo\"], \"d_ci_hi\": res[\"ci_hi\"],\n",
    "                \"mw_p\": res.get(\"mw_p\", np.nan),\n",
    "                \"n_low\": int(n1), \"n_high\": int(n2)\n",
    "            })\n",
    "\n",
    "    df_thresh = pd.DataFrame(thresh_rows)\n",
    "    if len(df_thresh):\n",
    "        df_thresh[\"mw_q_BH\"] = bh_fdr(df_thresh[\"mw_p\"].values)\n",
    "    results[\"thresholds\"] = df_thresh\n",
    "\n",
    "    # G2: Leave-one-out donor stability\n",
    "    loo_rows = []\n",
    "    if GR_COL in sea_d_orig.columns and tol_col and tol_col in sea_d_orig.columns:\n",
    "        base_r = corr_with_pvalue(sea_d_orig[GR_COL], sea_d_orig[tol_col], method=\"spearman\")[\"r\"]\n",
    "        for i in range(len(sea_d_orig)):\n",
    "            sub = sea_d_orig.drop(sea_d_orig.index[i])\n",
    "            r_loo = corr_with_pvalue(sub[GR_COL], sub[tol_col], method=\"spearman\")[\"r\"]\n",
    "            loo_rows.append({\n",
    "                \"dropped_donor\": sea_d_orig.iloc[i].get(\"donor_id\", i),\n",
    "                \"r_spearman_loo\": r_loo,\n",
    "                \"delta_r\": r_loo - base_r\n",
    "            })\n",
    "        df_loo = pd.DataFrame(loo_rows)\n",
    "        results[\"loo_GR_tol\"] = df_loo\n",
    "\n",
    "        log(f\"  LOO GR×tolerance: base r={base_r:.3f}, \"\n",
    "            f\"range=[{df_loo['r_spearman_loo'].min():.3f}, {df_loo['r_spearman_loo'].max():.3f}]\")\n",
    "\n",
    "        # LOO plot\n",
    "        fig, ax = plt.subplots(figsize=(6.0, 3.0))\n",
    "        ax.hist(df_loo[\"r_spearman_loo\"], bins=20, color=\"#4393C3\", edgecolor=\"black\", linewidth=0.5, alpha=0.8)\n",
    "        ax.axvline(base_r, color=\"red\", linewidth=1.2, linestyle=\"--\", label=f\"Full sample ρ={base_r:.3f}\")\n",
    "        ax.set_xlabel(\"Spearman ρ (LOO)\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_title(\"Leave-one-out stability: GR × Tolerance\")\n",
    "        ax.legend(fontsize=7)\n",
    "        if HAS_SNS: sns.despine(ax=ax)\n",
    "        save_fig(FIG_DIR / \"Supp_Fig6G_LOO_Stability.png\", fig)\n",
    "    else:\n",
    "        results[\"loo_GR_tol\"] = pd.DataFrame()\n",
    "\n",
    "    # G3: Scoring robustness (scanpy vs Z-score)\n",
    "    rob_rows = []\n",
    "    if \"IrisinScore\" in sea_d_orig.columns and \"IrisinScore_Z\" in sea_d_orig.columns:\n",
    "        for mes in [c for c in MES_COLS if c in sea_d_orig.columns]:\n",
    "            r1 = corr_with_pvalue(sea_d_orig[\"IrisinScore\"], sea_d_orig[mes], method=\"spearman\")\n",
    "            r2 = corr_with_pvalue(sea_d_orig[\"IrisinScore_Z\"], sea_d_orig[mes], method=\"spearman\")\n",
    "            rob_rows.append({\n",
    "                \"MES\": mes.replace(\"_score\",\"\"),\n",
    "                \"r_scanpy\": r1[\"r\"], \"p_scanpy\": r1[\"p\"],\n",
    "                \"r_zscore\": r2[\"r\"], \"p_zscore\": r2[\"p\"],\n",
    "                \"delta_r\": abs(r1[\"r\"] - r2[\"r\"]) if np.isfinite(r1[\"r\"]) and np.isfinite(r2[\"r\"]) else np.nan\n",
    "            })\n",
    "    results[\"scoring_robustness\"] = pd.DataFrame(rob_rows)\n",
    "\n",
    "    # Save all sensitivity results\n",
    "    save_xlsx_multi({\n",
    "        \"Threshold_Sensitivity\": df_thresh,\n",
    "        \"LOO_Stability\": results.get(\"loo_GR_tol\", pd.DataFrame()),\n",
    "        \"Scoring_Robustness\": results.get(\"scoring_robustness\", pd.DataFrame()),\n",
    "    }, TAB_DIR / \"Supplementary_Table6_Sensitivity.xlsx\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# MAIN EXECUTION\n",
    "\n",
    "log(\"=\" * 60)\n",
    "log(\"EXECUTING ALL PARTS\")\n",
    "log(\"=\" * 60)\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "def push_summary(label, df):\n",
    "    sl = str(df[\"status_label\"].iloc[0]) if \"status_label\" in df.columns and len(df) else \"NA\"\n",
    "    if sl == \"Clinical\":\n",
    "        g1, g2 = \"Control\", \"AD\"\n",
    "    else:\n",
    "        g1, g2 = \"LowPath\", \"HighPath\"\n",
    "    n1 = int((df.get(\"status\", pd.Series(dtype=object)).astype(str)==g1).sum())\n",
    "    n2 = int((df.get(\"status\", pd.Series(dtype=object)).astype(str)==g2).sum())\n",
    "    summary_rows.append({\n",
    "        \"label\": label, \"N_donors\": int(df.shape[0]), \"status_label\": sl,\n",
    "        f\"N_{g1}\": n1, f\"N_{g2}\": n2,\n",
    "        \"covariates\": \",\".join(covars),\n",
    "        \"age_col\": sea_meta.get(\"age_col\"),\n",
    "        \"dx_col\": sea_meta.get(\"dx_col\"),\n",
    "        \"donor_col\": sea_meta.get(\"donor_col\"),\n",
    "        \"tol_col\": tol_col,\n",
    "        \"braak_col\": sea_meta.get(\"sev_braak\"),\n",
    "        \"cerad_col\": sea_meta.get(\"sev_cerad\"),\n",
    "    })\n",
    "\n",
    "push_summary(\"SEA-AD donor table\", sea_d)\n",
    "\n",
    "# Part A\n",
    "df_age_corr, df_age_inter = pd.DataFrame(), pd.DataFrame()\n",
    "if RUN_PART_A:\n",
    "    df_age_corr, df_age_inter = partA_age(sea_d, covars)\n",
    "    save_xlsx(df_age_corr, TAB_DIR / \"Supplementary_Table6_AgeStrat_Corr.xlsx\")\n",
    "    save_xlsx(df_age_inter, TAB_DIR / \"Supplementary_Table6_Age_GR_MES_Interaction.xlsx\")\n",
    "\n",
    "# Part B\n",
    "df_status = pd.DataFrame()\n",
    "if RUN_PART_B:\n",
    "    df_status = partB_status(sea_d, covars)\n",
    "\n",
    "# Part C\n",
    "df_irisin = pd.DataFrame()\n",
    "if RUN_PART_C:\n",
    "    df_irisin = partC_irisin(sea, sea_d, covars)\n",
    "    save_xlsx(df_irisin, TAB_DIR / \"Supplementary_Table6_Irisin.xlsx\")\n",
    "\n",
    "# Part D\n",
    "df_nt = pd.DataFrame()\n",
    "if RUN_PART_D:\n",
    "    df_nt = partD_neurotransmitters(sea_d, covars)\n",
    "    save_xlsx(df_nt, TAB_DIR / \"Supplementary_Table6_NT_Signatures.xlsx\")\n",
    "\n",
    "# Part E\n",
    "df_ex = pd.DataFrame()\n",
    "if RUN_PART_E:\n",
    "    df_ex = partE_exercise(sea_d, covars)\n",
    "    save_xlsx(df_ex, TAB_DIR / \"Supplementary_Table6_ExerciseModule.xlsx\")\n",
    "\n",
    "# Part F\n",
    "df_cross = pd.DataFrame()\n",
    "if RUN_PART_F:\n",
    "    df_cross = partF_cross_cohort(cohorts, covars)\n",
    "\n",
    "#  Part G\n",
    "sensitivity_results = {}\n",
    "if RUN_PART_G:\n",
    "    sensitivity_results = partG_sensitivity(sea, sea_d, covars)\n",
    "\n",
    "# Main summary table\n",
    "df_main6 = pd.DataFrame(summary_rows)\n",
    "save_xlsx(df_main6, TAB_DIR / \"Main_Table6_Age_Path_Summary.xlsx\")\n",
    "\n",
    "log(\"=\" * 60)\n",
    "log(\"NB6 COMPLETED\")\n",
    "log(\"=\" * 60)\n",
    "log(f\"Figures: {FIG_DIR}\")\n",
    "log(f\"Tables:  {TAB_DIR}\")\n",
    "log(\"Key outputs:\")\n",
    "log(\"  Main_Fig6A — Age-stratified MES heatmap\")\n",
    "log(\"  Main_Fig6B — Cohen's d with CIs + significance\")\n",
    "log(\"  Main_Fig6C — Irisin × tolerance by status\")\n",
    "log(\"  Supp_Fig6F — Cross-cohort forest plot\")\n",
    "log(\"  Supp_Fig6G — LOO stability\")\n",
    "log(\"  All tables include: p-values, CIs, BH-FDR q-values, partial correlations\")"
   ]
  }
 ]
}