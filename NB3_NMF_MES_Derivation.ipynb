{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB3 — Consensus NMF: Myeloid Education Signature (MES) Derivation (K=8)\n",
    "\n",
    "Consensus NMF training on Tabula Sapiens thymus (K=8), rank-sweep optimization, cross-cohort module matching (Hungarian algorithm), and functional axis enrichment for eight MES modules.\n",
    "\n",
    "**Paper:** Zafar SA, Qin W. *Thymus-Derived Myeloid Education Signatures Predict Microglial Tolerance Positioning and Are Modulated by Glucocorticoid Stress-Axis Activity.* Neuroimmunomodulation (2026).\n",
    "\n",
    "> **Note:** Update the path variables in section 0 to match your local directory structure before running. Raw data can be obtained from the public repositories listed in Supplementary Table S1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings, itertools\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import scipy.sparse as sp\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.cluster.hierarchy import linkage, cophenet\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sc.settings.verbosity = 2\n",
    "np.random.seed(42)\n",
    "\n",
    "# 0) Paths \n",
    "BASE_DIR  = Path(\".\")  # <-- SET TO YOUR PROJECT ROOT\n",
    "PROC_DIR  = BASE_DIR / \"Process Data\"\n",
    "AIM1_DIR  = PROC_DIR / \"aim1_thymus\"\n",
    "NEG_DIR   = PROC_DIR / \"negctrl\"\n",
    "MANUSCRIPT_DIR = BASE_DIR / \"outputs\" / \"manuscript\".exists()\n",
    "    else (BASE_DIR / \"Manuscript Data\")\n",
    ")\n",
    "FIG_DIR = MANUSCRIPT_DIR / \"Figures\"\n",
    "TAB_DIR = MANUSCRIPT_DIR / \"Tables\"\n",
    "for d in [AIM1_DIR, NEG_DIR, FIG_DIR, TAB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TS_QC    = AIM1_DIR / \"TS_Thymus_filtered__qc.h5ad\"\n",
    "LAV_QC   = AIM1_DIR / \"GSE144870_Lavaert__qc.h5ad\"\n",
    "LE_QC    = AIM1_DIR / \"GSE139042_Le__qc.h5ad\"\n",
    "BLOOD_QC = NEG_DIR  / \"TS_Blood_NegCtrl_Myeloid__qc.h5ad\"\n",
    "\n",
    "assert TS_QC.exists()  and LAV_QC.exists() and LE_QC.exists(), \\\n",
    "    \"NB2 thymus outputs missing. Re-run NB2 first.\"\n",
    "assert BLOOD_QC.exists(), \"NB2 negctrl output missing. Re-run NB2 first.\"\n",
    "\n",
    "# 1) Figure style\n",
    "plt.rcParams.update({\n",
    "    \"font.family\":       \"Arial\",\n",
    "    \"font.size\":         8,\n",
    "    \"axes.labelsize\":    8,\n",
    "    \"axes.titlesize\":    9,\n",
    "    \"xtick.labelsize\":   7,\n",
    "    \"ytick.labelsize\":   7,\n",
    "    \"legend.fontsize\":   7,\n",
    "    \"figure.titlesize\":  9,\n",
    "    \"axes.linewidth\":    0.8,\n",
    "})\n",
    "FIG_DPI = 1200\n",
    "\n",
    "# Colour palettes\n",
    "PALETTE_MES  = sns.color_palette(\"Set2\", 12)\n",
    "PALETTE_DUAL = [\"#3182bd\", \"#e6550d\"]    # thymus vs blood\n",
    "CMAP_RDBU    = plt.cm.RdBu_r\n",
    "CMAP_VIRIDIS = plt.cm.viridis\n",
    "CMAP_HEAT    = LinearSegmentedColormap.from_list(\n",
    "    \"custom_heat\", [\"#f7f7f7\", \"#fee08b\", \"#fc8d59\", \"#d73027\", \"#67001f\"]\n",
    ")\n",
    "\n",
    "def save_fig(fig, fname: str, kind: str = \"Main\"):\n",
    "    assert kind in (\"Main\", \"Supplementary\")\n",
    "    out = FIG_DIR / f\"{kind}_{fname}.png\"\n",
    "    fig.savefig(out, dpi=FIG_DPI, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"[SAVED FIG] {out}\")\n",
    "\n",
    "def save_excel(sheets: dict, fname: str, kind: str = \"Main\"):\n",
    "    assert kind in (\"Main\", \"Supplementary\")\n",
    "    out = TAB_DIR / f\"{kind}_{fname}.xlsx\"\n",
    "    with pd.ExcelWriter(out, engine=\"openpyxl\") as w:\n",
    "        for sn, df in sheets.items():\n",
    "            df.to_excel(w, index=False, sheet_name=str(sn)[:31])\n",
    "    print(f\"[SAVED TABLE] {out}\")\n",
    "\n",
    "\n",
    "def sanitize_for_write(adata: ad.AnnData) -> ad.AnnData:\n",
    "    \"\"\"Clean obs/var so h5ad write never fails on duplicate column / index.\"\"\"\n",
    "    for df_name in [\"obs\", \"var\"]:\n",
    "        df = getattr(adata, df_name)\n",
    "        if df.index.name is not None:\n",
    "            idx_name = df.index.name\n",
    "            if idx_name in df.columns:\n",
    "                if not pd.Series(df.index, index=df.index).equals(df[idx_name]):\n",
    "                    df.rename(columns={idx_name: f\"{idx_name}_col\"}, inplace=True)\n",
    "            df.index.name = None\n",
    "        df.columns = df.columns.astype(str)\n",
    "    adata.obs_names = adata.obs_names.astype(str)\n",
    "    adata.var_names = adata.var_names.astype(str)\n",
    "    return adata\n",
    "\n",
    "\n",
    "# 2) Load QC datasets\n",
    "print(\"\")\n",
    "print(\"NB3: Loading QC datasets\")\n",
    "print(\"\")\n",
    "ts    = sc.read_h5ad(TS_QC)\n",
    "lav   = sc.read_h5ad(LAV_QC)\n",
    "le    = sc.read_h5ad(LE_QC)\n",
    "blood = sc.read_h5ad(BLOOD_QC)\n",
    "\n",
    "def ensure_counts(a: ad.AnnData):\n",
    "    if \"counts\" not in a.layers:\n",
    "        a.layers[\"counts\"] = a.X.copy()\n",
    "    if not sp.issparse(a.layers[\"counts\"]):\n",
    "        a.layers[\"counts\"] = sp.csr_matrix(a.layers[\"counts\"])\n",
    "    return a\n",
    "\n",
    "ts    = ensure_counts(ts)\n",
    "lav   = ensure_counts(lav)\n",
    "le    = ensure_counts(le)\n",
    "blood = ensure_counts(blood)\n",
    "\n",
    "print(f\"  TS:          {ts.n_obs:>7,} cells × {ts.n_vars:>6,} genes\")\n",
    "print(f\"  Lavaert:     {lav.n_obs:>7,} cells × {lav.n_vars:>6,} genes\")\n",
    "print(f\"  Le:          {le.n_obs:>7,} cells × {le.n_vars:>6,} genes\")\n",
    "print(f\"  Blood NEGCTRL: {blood.n_obs:>7,} cells × {blood.n_vars:>6,} genes\")\n",
    "\n",
    "# 3) Axis priors\n",
    "AXIS = {\n",
    "    \"chemokine\": [\n",
    "        \"CXCL12\",\"CXCR4\",\"CCL19\",\"CCR7\",\"CCL21\",\"CXCL8\",\"CXCL10\",\n",
    "        \"CXCR3\",\"CCL5\",\"CCR5\",\"CXCL9\",\"CXCL11\",\"CCR2\",\"CCL2\",\n",
    "    ],\n",
    "    \"ecm_adhesion\": [\n",
    "        \"FN1\",\"ITGA5\",\"ITGB1\",\"ITGA4\",\"ITGB7\",\"LAMC1\",\"LAMA4\",\"LAMB1\",\n",
    "        \"COL1A1\",\"COL1A2\",\"COL3A1\",\"VCAN\",\"ICAM1\",\"VCAM1\",\"LGALS3\",\n",
    "    ],\n",
    "    \"guidance\": [\n",
    "        \"SEMA3A\",\"SEMA3C\",\"SEMA4D\",\"SEMA7A\",\"NRP1\",\"NRP2\",\"EPHA2\",\n",
    "        \"EPHA4\",\"EPHB2\",\"EFNA1\",\"EFNA5\",\"EFNB2\",\"SLIT2\",\"ROBO1\",\"ROBO2\",\n",
    "    ],\n",
    "    \"tolerance_assoc\": [\n",
    "        \"FOXP3\",\"IL2RA\",\"CTLA4\",\"IKZF2\",\"TNFRSF18\",\"LAG3\",\"TIGIT\",\n",
    "        \"ICOS\",\"TNFRSF4\",\"IL10\",\"TGFB1\",\"BATF\",\"IRF4\",\n",
    "    ],\n",
    "}\n",
    "AXIS = {k: [g.upper() for g in v] for k, v in AXIS.items()}\n",
    "\n",
    "# 4) TS training gene universe (NO LEAKAGE)\n",
    "print(\"\\n=== Preprocess TS (training only — no leakage) ===\")\n",
    "ts_train = ts.copy()\n",
    "ts_train.X = ts_train.layers[\"counts\"].copy()\n",
    "sc.pp.normalize_total(ts_train, target_sum=1e4)\n",
    "sc.pp.log1p(ts_train)\n",
    "sc.pp.highly_variable_genes(ts_train, n_top_genes=2500, flavor=\"seurat_v3\")\n",
    "\n",
    "hvg_ts       = ts_train.var_names[ts_train.var[\"highly_variable\"]].tolist()\n",
    "ts_var_upper = pd.Index([str(v).upper() for v in ts_train.var_names])\n",
    "axis_all     = {g for lst in AXIS.values() for g in lst}\n",
    "axis_present = [ts_train.var_names[i]\n",
    "                for i, u in enumerate(ts_var_upper) if u in axis_all]\n",
    "GENE_UNIVERSE = list(dict.fromkeys(hvg_ts + axis_present))\n",
    "GENE_UNI_UP   = [str(g).strip().upper() for g in GENE_UNIVERSE]\n",
    "\n",
    "print(f\"  TS HVG: {len(hvg_ts)} | Axis present: {len(axis_present)} \"\n",
    "      f\"| Training gene universe: {len(GENE_UNIVERSE)}\")\n",
    "\n",
    "# 5) Gene ID harmonisation + diagnostic\n",
    "def norm_sym(s: str) -> str:\n",
    "    return str(s).strip().upper()\n",
    "\n",
    "def build_symbol_index(adata: ad.AnnData) -> dict:\n",
    "    idx = {}\n",
    "    for v in adata.var_names:\n",
    "        idx[norm_sym(v)] = v\n",
    "    candidates = []\n",
    "    for c in adata.var.columns:\n",
    "        cn = c.lower()\n",
    "        if any(k in cn for k in [\"symbol\", \"gene\", \"feature\", \"name\"]):\n",
    "            candidates.append(c)\n",
    "    for c in candidates:\n",
    "        vals = adata.var[c].astype(str).values\n",
    "        for vname, sym in zip(adata.var_names, vals):\n",
    "            k = norm_sym(sym)\n",
    "            if k and (k not in idx):\n",
    "                idx[k] = vname\n",
    "    return idx\n",
    "\n",
    "def gene_overlap_report(genes_ref: list, adata: ad.AnnData, label: str) -> dict:\n",
    "    idx = build_symbol_index(adata)\n",
    "    present = sum(1 for g in genes_ref if norm_sym(g) in idx)\n",
    "    sample_var = list(adata.var_names[:5])\n",
    "    ensembl_like = sum(1 for x in sample_var if str(x).upper().startswith(\"ENSG\"))\n",
    "    return {\n",
    "        \"dataset\": label,\n",
    "        \"n_overlap\": int(present),\n",
    "        \"pct_overlap\": round(float(present / max(len(genes_ref), 1) * 100.0), 2),\n",
    "        \"varnames_look_ensembl\": int(ensembl_like),\n",
    "        \"var_columns_with_gene\": \", \".join(\n",
    "            [c for c in adata.var.columns\n",
    "             if any(k in c.lower() for k in [\"symbol\",\"gene\",\"feature\",\"name\"])][:8]\n",
    "        ),\n",
    "        \"varname_head\": \"; \".join([str(x) for x in sample_var]),\n",
    "    }\n",
    "\n",
    "df_diag = pd.DataFrame([\n",
    "    gene_overlap_report(GENE_UNIVERSE, lav,   \"Lavaert\"),\n",
    "    gene_overlap_report(GENE_UNIVERSE, le,    \"Le\"),\n",
    "    gene_overlap_report(GENE_UNIVERSE, blood, \"Blood_NEGCTRL\"),\n",
    "])\n",
    "print(\"\\n[DIAGNOSTIC] Gene overlap with TS training universe:\")\n",
    "print(df_diag.to_string(index=False))\n",
    "\n",
    "# 6) CORE NMF UTILITIES — consensus, cophenetic, projection\n",
    "\n",
    "def _X(a: ad.AnnData, genes: list):\n",
    "    X = a[:, genes].X\n",
    "    return X.tocsr() if sp.issparse(X) else sp.csr_matrix(X)\n",
    "\n",
    "\n",
    "def _subsample(n_obs: int, fit_n: int, rng: np.random.RandomState):\n",
    "    if n_obs > fit_n:\n",
    "        return rng.choice(n_obs, size=fit_n, replace=False)\n",
    "    return np.arange(n_obs)\n",
    "\n",
    "\n",
    "# single NMF fit\n",
    "def fit_nmf(X: sp.csr_matrix, k: int, seed: int = 42, max_iter: int = 800):\n",
    "    model = NMF(n_components=k, init=\"nndsvda\", random_state=seed, max_iter=max_iter)\n",
    "    W = model.fit_transform(X)\n",
    "    H = model.components_\n",
    "    return model, W, H, model.reconstruction_err_\n",
    "\n",
    "\n",
    "# Consensus NMF (multiple seeds → connectivity → cophenetic)\n",
    "def consensus_nmf(X: sp.csr_matrix, k: int, n_runs: int = 20,\n",
    "                  max_iter: int = 800, base_seed: int = 42):\n",
    "    \"\"\"\n",
    "    Run NMF `n_runs` times with different seeds.\n",
    "    Returns: best (W, H, model), consensus_matrix, cophenetic_corr, all_errors\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    connectivity_sum = np.zeros((n, n), dtype=np.float32)\n",
    "    best_err  = np.inf\n",
    "    best_run  = None\n",
    "    all_errors = []\n",
    "\n",
    "    for r in range(n_runs):\n",
    "        seed = base_seed + r\n",
    "        model, W, H, err = fit_nmf(X, k, seed=seed, max_iter=max_iter)\n",
    "        all_errors.append(err)\n",
    "        if err < best_err:\n",
    "            best_err = err\n",
    "            best_run = (model, W, H)\n",
    "        # Connectivity: cells assigned to same component ⇒ 1\n",
    "        labels = np.argmax(W, axis=1)\n",
    "        conn   = (labels[:, None] == labels[None, :]).astype(np.float32)\n",
    "        connectivity_sum += conn\n",
    "\n",
    "    C = connectivity_sum / n_runs            # consensus matrix\n",
    "    # Cophenetic correlation\n",
    "    dist = 1.0 - C\n",
    "    np.fill_diagonal(dist, 0.0)\n",
    "    dist = np.clip(dist, 0, None)\n",
    "    dist = (dist + dist.T) / 2.0            # ensure symmetry\n",
    "    try:\n",
    "        condensed = squareform(dist, checks=False)\n",
    "        Z = linkage(condensed, method=\"average\")\n",
    "        coph_corr, _ = cophenet(Z, condensed)\n",
    "    except Exception:\n",
    "        coph_corr = np.nan\n",
    "\n",
    "    return best_run, C, float(coph_corr), all_errors\n",
    "\n",
    "\n",
    "# Projection helper\n",
    "def project_with_ts_nmf(nmf_model, adata_counts: ad.AnnData,\n",
    "                        genes_ref: list) -> tuple:\n",
    "    idx_map = build_symbol_index(adata_counts)\n",
    "    present_mask = np.zeros(len(genes_ref), dtype=bool)\n",
    "    actual_vars  = []\n",
    "    for i, g in enumerate(genes_ref):\n",
    "        key = norm_sym(g)\n",
    "        if key in idx_map:\n",
    "            present_mask[i] = True\n",
    "            actual_vars.append(idx_map[key])\n",
    "        else:\n",
    "            actual_vars.append(None)\n",
    "\n",
    "    n_present = int(present_mask.sum())\n",
    "    n_missing = int((~present_mask).sum())\n",
    "    if n_present == 0:\n",
    "        return None, {\"n_present\": 0, \"n_missing\": n_missing, \"note\": \"ZERO OVERLAP\"}\n",
    "\n",
    "    present_vars = [v for v in actual_vars if v is not None]\n",
    "    tmp = adata_counts[:, present_vars].copy()\n",
    "    tmp.X = tmp.layers[\"counts\"].copy()\n",
    "    sc.pp.normalize_total(tmp, target_sum=1e4)\n",
    "    sc.pp.log1p(tmp)\n",
    "    Xp = tmp.X.tocsr() if sp.issparse(tmp.X) else sp.csr_matrix(tmp.X)\n",
    "\n",
    "    ref_positions = np.where(present_mask)[0].astype(np.int32)\n",
    "    Xcoo     = Xp.tocoo()\n",
    "    new_cols = ref_positions[Xcoo.col]\n",
    "    Xref     = sp.coo_matrix(\n",
    "        (Xcoo.data, (Xcoo.row, new_cols)),\n",
    "        shape=(tmp.n_obs, len(genes_ref))\n",
    "    ).tocsr()\n",
    "\n",
    "    # Ensure dtype matches NMF components (sklearn requires identical dtypes)\n",
    "    target_dtype = nmf_model.components_.dtype\n",
    "    if Xref.dtype != target_dtype:\n",
    "        Xref = Xref.astype(target_dtype)\n",
    "    W = nmf_model.transform(Xref)\n",
    "    return W, {\"n_present\": n_present, \"n_missing\": n_missing}\n",
    "\n",
    "\n",
    "# Component-level correlation + Hungarian matching\n",
    "def corr_components(H_a, H_b):\n",
    "    \"\"\"Row-wise Pearson between two H matrices (k × genes).\"\"\"\n",
    "    A = (H_a - H_a.mean(axis=1, keepdims=True)) / (H_a.std(axis=1, keepdims=True) + 1e-12)\n",
    "    B = (H_b - H_b.mean(axis=1, keepdims=True)) / (H_b.std(axis=1, keepdims=True) + 1e-12)\n",
    "    return (A @ B.T) / A.shape[1]\n",
    "\n",
    "def hungarian_match(C):\n",
    "    r, c = linear_sum_assignment(-C)\n",
    "    return r, c, C[r, c]\n",
    "\n",
    "\n",
    "# Refit NMF on external dataset\n",
    "def fit_nmf_on_dataset(ad_log: ad.AnnData, genes_actual: list,\n",
    "                       k: int, seed: int = 42, fit_n: int = 30000,\n",
    "                       max_iter: int = 800):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    idx = _subsample(ad_log.n_obs, fit_n, rng)\n",
    "    ad_fit = ad_log[idx, genes_actual].copy()\n",
    "    model = NMF(n_components=k, init=\"nndsvda\", random_state=seed,\n",
    "                max_iter=max_iter)\n",
    "    model.fit(_X(ad_fit, genes_actual))\n",
    "    return model.components_\n",
    "\n",
    "\n",
    "# 7) STATISTICAL UTILITIES\n",
    "\n",
    "def benjamini_hochberg(pvals: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Benjamini-Hochberg FDR correction.\"\"\"\n",
    "    n = len(pvals)\n",
    "    order = np.argsort(pvals)\n",
    "    ranked = np.empty_like(pvals)\n",
    "    ranked[order] = np.arange(1, n + 1)\n",
    "    adj = np.minimum(1.0, pvals * n / ranked)\n",
    "    # enforce monotonicity\n",
    "    for i in reversed(range(n - 1)):\n",
    "        adj[order[i]] = min(adj[order[i]], adj[order[i + 1]])\n",
    "    return adj\n",
    "\n",
    "\n",
    "def cohens_d(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Cohen's d effect size.\"\"\"\n",
    "    na, nb = len(a), len(b)\n",
    "    if na < 2 or nb < 2:\n",
    "        return 0.0\n",
    "    pooled = np.sqrt(((na - 1) * a.var(ddof=1) + (nb - 1) * b.var(ddof=1)) /\n",
    "                     (na + nb - 2))\n",
    "    return float((a.mean() - b.mean()) / (pooled + 1e-12))\n",
    "\n",
    "\n",
    "def bootstrap_ci(arr: np.ndarray, stat_fn=np.mean, n_boot: int = 2000,\n",
    "                 alpha: float = 0.05, seed: int = 42) -> tuple:\n",
    "    \"\"\"Bootstrap confidence interval for `stat_fn`.\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    boot_stats = np.array([\n",
    "        stat_fn(rng.choice(arr, size=len(arr), replace=True))\n",
    "        for _ in range(n_boot)\n",
    "    ])\n",
    "    lo = np.percentile(boot_stats, 100 * alpha / 2)\n",
    "    hi = np.percentile(boot_stats, 100 * (1 - alpha / 2))\n",
    "    return float(stat_fn(arr)), float(lo), float(hi)\n",
    "\n",
    "\n",
    "def permutation_test_corr(H_ref, H_tgt, n_perm: int = 500, seed: int = 42):\n",
    "    \"\"\"\n",
    "    Permutation null for mean matched Hungarian correlation.\n",
    "    Permutes gene columns of H_tgt to break gene-level correspondence.\n",
    "    Returns observed mean, null distribution, p-value.\n",
    "    \"\"\"\n",
    "    C_obs = corr_components(H_ref, H_tgt)\n",
    "    _, _, vals_obs = hungarian_match(C_obs)\n",
    "    obs_mean = float(np.mean(vals_obs))\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "    null_means = np.empty(n_perm)\n",
    "    n_genes = H_tgt.shape[1]\n",
    "    for p in range(n_perm):\n",
    "        perm = rng.permutation(n_genes)\n",
    "        C_p  = corr_components(H_ref, H_tgt[:, perm])\n",
    "        _, _, vals_p = hungarian_match(C_p)\n",
    "        null_means[p] = float(np.mean(vals_p))\n",
    "\n",
    "    p_val = float((np.sum(null_means >= obs_mean) + 1) / (n_perm + 1))\n",
    "    return obs_mean, null_means, p_val\n",
    "\n",
    "\n",
    "def hypergeom_enrichment(module_genes: list, gene_set: list,\n",
    "                         universe_size: int) -> dict:\n",
    "    \"\"\"One-sided hypergeometric test for overlap enrichment.\"\"\"\n",
    "    module_set = set(module_genes)\n",
    "    gs_set     = set(gene_set)\n",
    "    overlap    = module_set & gs_set\n",
    "    k = len(overlap)\n",
    "    M = universe_size\n",
    "    n = len(gs_set)\n",
    "    N = len(module_set)\n",
    "    pval = float(stats.hypergeom.sf(k - 1, M, n, N)) if k > 0 else 1.0\n",
    "    fold = (k / max(N, 1)) / (n / max(M, 1)) if n > 0 and M > 0 else 0.0\n",
    "    return {\n",
    "        \"overlap\": k,\n",
    "        \"module_size\": N,\n",
    "        \"gene_set_size\": n,\n",
    "        \"universe\": M,\n",
    "        \"fold_enrichment\": round(fold, 3),\n",
    "        \"pval_hypergeom\": pval,\n",
    "        \"overlap_genes\": \", \".join(sorted(overlap)),\n",
    "    }\n",
    "\n",
    "\n",
    "# 8) K-SWEEP WITH MULTI-CRITERIA MODEL SELECTION\n",
    "print(\"\")\n",
    "print(\"K-SWEEP: consensus NMF, cophenetic, reconstruction error, silhouette\")\n",
    "print(\"\")\n",
    "\n",
    "K_LIST       = [5, 8, 10, 12]\n",
    "N_CONSENSUS  = 20          # consensus runs per K\n",
    "FIT_N_TS     = 60000\n",
    "FIT_N_EXT    = 30000\n",
    "\n",
    "# Prepare TS matrix once\n",
    "rng_ks = np.random.RandomState(42)\n",
    "idx_ks = _subsample(ts_train.n_obs, FIT_N_TS, rng_ks)\n",
    "ts_fit = ts_train[idx_ks, GENE_UNIVERSE].copy()\n",
    "X_ts_fit = _X(ts_fit, GENE_UNIVERSE)\n",
    "\n",
    "# Pre-log external datasets (reused later)\n",
    "lav_log = lav.copy(); lav_log.X = lav_log.layers[\"counts\"].copy()\n",
    "sc.pp.normalize_total(lav_log, target_sum=1e4); sc.pp.log1p(lav_log)\n",
    "le_log = le.copy();  le_log.X = le_log.layers[\"counts\"].copy()\n",
    "sc.pp.normalize_total(le_log, target_sum=1e4);  sc.pp.log1p(le_log)\n",
    "\n",
    "lav_idx  = build_symbol_index(lav)\n",
    "le_idx   = build_symbol_index(le)\n",
    "genes_lav        = [g for g in GENE_UNIVERSE if norm_sym(g) in lav_idx]\n",
    "genes_le         = [g for g in GENE_UNIVERSE if norm_sym(g) in le_idx]\n",
    "genes_lav_actual = [lav_idx[norm_sym(g)] for g in genes_lav]\n",
    "genes_le_actual  = [le_idx[norm_sym(g)]  for g in genes_le]\n",
    "pos_ref = {norm_sym(g): i for i, g in enumerate(GENE_UNIVERSE)}\n",
    "\n",
    "sweep_rows = []\n",
    "consensus_results = {}   # store for K=8 reuse\n",
    "\n",
    "for K in K_LIST:\n",
    "    print(f\"\\n  K={K} — consensus NMF ({N_CONSENSUS} runs) …\")\n",
    "    (model_k, W_k, H_k), C_mat, coph, errors = consensus_nmf(\n",
    "        X_ts_fit, K, n_runs=N_CONSENSUS, base_seed=42\n",
    "    )\n",
    "\n",
    "    # Reconstruction error (mean across runs)\n",
    "    mean_err = float(np.mean(errors))\n",
    "    std_err  = float(np.std(errors))\n",
    "\n",
    "    # Silhouette on dominant module assignment\n",
    "    labels = np.argmax(W_k, axis=1)\n",
    "    n_labels = len(np.unique(labels))\n",
    "    if n_labels >= 2:\n",
    "        sil = float(silhouette_score(\n",
    "            X_ts_fit.toarray() if sp.issparse(X_ts_fit) else X_ts_fit,\n",
    "            labels, metric=\"cosine\", sample_size=min(10000, X_ts_fit.shape[0]),\n",
    "            random_state=42\n",
    "        ))\n",
    "    else:\n",
    "        sil = np.nan\n",
    "\n",
    "    # External stability vs Lavaert + Le (refit + Hungarian)\n",
    "    H_lavK = fit_nmf_on_dataset(lav_log, genes_lav_actual, K, seed=42)\n",
    "    H_leK  = fit_nmf_on_dataset(le_log,  genes_le_actual,  K, seed=42)\n",
    "    H_k_lav = H_k[:, [pos_ref[norm_sym(g)] for g in genes_lav]]\n",
    "    H_k_le  = H_k[:, [pos_ref[norm_sym(g)] for g in genes_le]]\n",
    "    C_lav_k = corr_components(H_k_lav, H_lavK)\n",
    "    C_le_k  = corr_components(H_k_le,  H_leK)\n",
    "    _, _, vals_lav_k = hungarian_match(C_lav_k)\n",
    "    _, _, vals_le_k  = hungarian_match(C_le_k)\n",
    "\n",
    "    sweep_rows.append({\n",
    "        \"K\": K,\n",
    "        \"cophenetic\": round(coph, 4),\n",
    "        \"silhouette_cosine\": round(sil, 4) if not np.isnan(sil) else np.nan,\n",
    "        \"recon_error_mean\": round(mean_err, 2),\n",
    "        \"recon_error_std\": round(std_err, 2),\n",
    "        \"ext_corr_Lavaert_mean\": round(float(np.mean(vals_lav_k)), 4),\n",
    "        \"ext_corr_Le_mean\": round(float(np.mean(vals_le_k)), 4),\n",
    "        \"ext_corr_Lavaert_min\": round(float(np.min(vals_lav_k)), 4),\n",
    "        \"ext_corr_Le_min\": round(float(np.min(vals_le_k)), 4),\n",
    "    })\n",
    "    consensus_results[K] = {\n",
    "        \"model\": model_k, \"W\": W_k, \"H\": H_k,\n",
    "        \"C_mat\": C_mat, \"coph\": coph,\n",
    "        \"C_lav\": C_lav_k, \"C_le\": C_le_k,\n",
    "        \"vals_lav\": vals_lav_k, \"vals_le\": vals_le_k,\n",
    "        \"H_lav_refit\": H_lavK, \"H_le_refit\": H_leK,\n",
    "    }\n",
    "    print(f\"    cophenetic={coph:.4f}  silhouette={sil:.4f}  \"\n",
    "          f\"ext_Lav={np.mean(vals_lav_k):.4f}  ext_Le={np.mean(vals_le_k):.4f}\")\n",
    "\n",
    "df_sweep = pd.DataFrame(sweep_rows)\n",
    "print(\"\\n[K-SWEEP SUMMARY]\")\n",
    "print(df_sweep.to_string(index=False))\n",
    "\n",
    "# 9) MAIN FIT — CONSENSUS NMF K=8 + WITHIN-TS BOOTSTRAP STABILITY\n",
    "K_MAIN   = 8\n",
    "N_SEEDS  = 10       # within-TS multi-seed stability\n",
    "mes_cols = [f\"MES{k+1:02d}\" for k in range(K_MAIN)]\n",
    "\n",
    "print(f\"\\n{'='*72}\")\n",
    "print(f\"MAIN FIT: Consensus NMF K={K_MAIN} on full TS training set\")\n",
    "print(\"\")\n",
    "\n",
    "# Full TS (not subsampled for final scores)\n",
    "X_ts_full = _X(ts_train, GENE_UNIVERSE)\n",
    "nmf_ts_best = consensus_results[K_MAIN][\"model\"]\n",
    "H_ts        = consensus_results[K_MAIN][\"H\"]\n",
    "\n",
    "# Re-transform full TS with the best model\n",
    "if X_ts_full.dtype != nmf_ts_best.components_.dtype:\n",
    "    X_ts_full = X_ts_full.astype(nmf_ts_best.components_.dtype)\n",
    "W_ts_full = nmf_ts_best.transform(X_ts_full)\n",
    "ts_scores = pd.DataFrame(W_ts_full, columns=mes_cols, index=ts_train.obs_names)\n",
    "\n",
    "# Within-TS multi-seed stability with bootstrap CI\n",
    "print(f\"\\n  Within-TS stability ({N_SEEDS} seeds) …\")\n",
    "stab_within_rows = []\n",
    "all_within_corrs = []\n",
    "\n",
    "for seed in range(N_SEEDS):\n",
    "    model_s, W_s, H_s, _ = fit_nmf(X_ts_fit, K_MAIN, seed=seed, max_iter=800)\n",
    "    C_s = corr_components(H_ts, H_s)\n",
    "    _, _, vals = hungarian_match(C_s)\n",
    "    all_within_corrs.extend(vals.tolist())\n",
    "    stab_within_rows.append({\n",
    "        \"seed\": seed,\n",
    "        \"mean_corr\": round(float(np.mean(vals)), 4),\n",
    "        \"median_corr\": round(float(np.median(vals)), 4),\n",
    "        \"min_corr\": round(float(np.min(vals)), 4),\n",
    "    })\n",
    "\n",
    "df_stab_within = pd.DataFrame(stab_within_rows)\n",
    "within_arr = np.array(all_within_corrs)\n",
    "within_mean, within_ci_lo, within_ci_hi = bootstrap_ci(within_arr)\n",
    "print(f\"    Within-TS mean matched corr = {within_mean:.4f} \"\n",
    "      f\"[{within_ci_lo:.4f}, {within_ci_hi:.4f}] 95% CI\")\n",
    "\n",
    "# 10) EXTERNAL PROJECTION + STABILITY WITH PERMUTATION TESTS\n",
    "print(f\"\\n{'='*72}\")\n",
    "print(\"EXTERNAL VALIDATION: projection + permutation null\")\n",
    "print(\"\")\n",
    "\n",
    "W_lav, info_lav   = project_with_ts_nmf(nmf_ts_best, lav, GENE_UNIVERSE)\n",
    "W_le,  info_le    = project_with_ts_nmf(nmf_ts_best, le,  GENE_UNIVERSE)\n",
    "\n",
    "# Retrieve stored refit results from K-sweep\n",
    "H_lav_refit = consensus_results[K_MAIN][\"H_lav_refit\"]\n",
    "H_le_refit  = consensus_results[K_MAIN][\"H_le_refit\"]\n",
    "C_lav       = consensus_results[K_MAIN][\"C_lav\"]\n",
    "C_le        = consensus_results[K_MAIN][\"C_le\"]\n",
    "vals_lav    = consensus_results[K_MAIN][\"vals_lav\"]\n",
    "vals_le     = consensus_results[K_MAIN][\"vals_le\"]\n",
    "\n",
    "H_ts_lav = H_ts[:, [pos_ref[norm_sym(g)] for g in genes_lav]]\n",
    "H_ts_le  = H_ts[:, [pos_ref[norm_sym(g)] for g in genes_le]]\n",
    "\n",
    "# Permutation tests (500 permutations)\n",
    "print(\"  Permutation test — TS vs Lavaert …\")\n",
    "obs_lav, null_lav, pval_lav = permutation_test_corr(H_ts_lav, H_lav_refit,\n",
    "                                                     n_perm=500, seed=42)\n",
    "print(f\"    Observed={obs_lav:.4f}  p={pval_lav:.4f}\")\n",
    "\n",
    "print(\"  Permutation test — TS vs Le …\")\n",
    "obs_le, null_le, pval_le = permutation_test_corr(H_ts_le, H_le_refit,\n",
    "                                                  n_perm=500, seed=42)\n",
    "print(f\"    Observed={obs_le:.4f}  p={pval_le:.4f}\")\n",
    "\n",
    "# Bootstrap CI on matched correlations\n",
    "lav_mean, lav_ci_lo, lav_ci_hi = bootstrap_ci(vals_lav)\n",
    "le_mean,  le_ci_lo,  le_ci_hi  = bootstrap_ci(vals_le)\n",
    "\n",
    "r_lav, c_lav, _ = hungarian_match(C_lav)\n",
    "r_le,  c_le,  _ = hungarian_match(C_le)\n",
    "\n",
    "df_stab8 = pd.DataFrame({\n",
    "    \"target_dataset\": ([\"Lavaert\"] * K_MAIN) + ([\"Le\"] * K_MAIN),\n",
    "    \"ref_module_TS\": [f\"MES{i+1:02d}\" for i in np.concatenate([r_lav, r_le])],\n",
    "    \"target_module_refit\": [f\"MES{i+1:02d}\" for i in np.concatenate([c_lav, c_le])],\n",
    "    \"corr\": np.concatenate([vals_lav, vals_le]).astype(float).round(4),\n",
    "})\n",
    "df_stab8_summary = pd.DataFrame([\n",
    "    {\"target\": \"Lavaert\", \"mean_corr\": round(lav_mean, 4),\n",
    "     \"CI95_lo\": round(lav_ci_lo, 4), \"CI95_hi\": round(lav_ci_hi, 4),\n",
    "     \"perm_pval\": pval_lav},\n",
    "    {\"target\": \"Le\", \"mean_corr\": round(le_mean, 4),\n",
    "     \"CI95_lo\": round(le_ci_lo, 4), \"CI95_hi\": round(le_ci_hi, 4),\n",
    "     \"perm_pval\": pval_le},\n",
    "])\n",
    "\n",
    "# 11) NEGCTRL — FORMAL STATISTICAL COMPARISON\n",
    "print(f\"\\n{'='*72}\")\n",
    "print(\"NEGATIVE CONTROL: formal statistical test per module\")\n",
    "print(\"\")\n",
    "\n",
    "W_blood, info_blood = project_with_ts_nmf(nmf_ts_best, blood, GENE_UNIVERSE)\n",
    "blood_scores = pd.DataFrame(W_blood, columns=mes_cols, index=blood.obs_names)\n",
    "\n",
    "negctrl_stat_rows = []\n",
    "for col in mes_cols:\n",
    "    t_vals = ts_scores[col].values\n",
    "    b_vals = blood_scores[col].values\n",
    "    U_stat, mwu_pval = stats.mannwhitneyu(t_vals, b_vals, alternative=\"greater\")\n",
    "    d = cohens_d(t_vals, b_vals)\n",
    "    negctrl_stat_rows.append({\n",
    "        \"module\": col,\n",
    "        \"thymus_mean\": round(float(t_vals.mean()), 5),\n",
    "        \"thymus_median\": round(float(np.median(t_vals)), 5),\n",
    "        \"blood_mean\": round(float(b_vals.mean()), 5),\n",
    "        \"blood_median\": round(float(np.median(b_vals)), 5),\n",
    "        \"mannwhitney_U\": float(U_stat),\n",
    "        \"pval_one_sided\": mwu_pval,\n",
    "        \"cohens_d\": round(d, 3),\n",
    "    })\n",
    "\n",
    "df_negctrl_stat = pd.DataFrame(negctrl_stat_rows)\n",
    "df_negctrl_stat[\"pval_BH\"] = benjamini_hochberg(\n",
    "    df_negctrl_stat[\"pval_one_sided\"].values\n",
    ")\n",
    "df_negctrl_stat[\"significant_BH005\"] = df_negctrl_stat[\"pval_BH\"] < 0.05\n",
    "print(df_negctrl_stat[[\"module\",\"thymus_mean\",\"blood_mean\",\"cohens_d\",\n",
    "                        \"pval_BH\",\"significant_BH005\"]].to_string(index=False))\n",
    "\n",
    "# Summary table for backward compat\n",
    "df_negctrl_summary = pd.concat([\n",
    "    pd.DataFrame({\n",
    "        \"dataset\": \"TS_thymus\", \"module\": mes_cols,\n",
    "        \"mean\": ts_scores.mean().values,\n",
    "        \"median\": ts_scores.median().values,\n",
    "        \"p95\": ts_scores.quantile(0.95).values,\n",
    "    }),\n",
    "    pd.DataFrame({\n",
    "        \"dataset\": \"Blood_negctrl\", \"module\": mes_cols,\n",
    "        \"mean\": blood_scores.mean().values,\n",
    "        \"median\": blood_scores.median().values,\n",
    "        \"p95\": blood_scores.quantile(0.95).values,\n",
    "    }),\n",
    "], ignore_index=True)\n",
    "\n",
    "# 12) THYMIC COMPARTMENT ENRICHMENT — WILCOXON + EFFECT SIZES\n",
    "print(f\"\\n{'='*72}\")\n",
    "print(\"THYMIC COMPARTMENT: differential enrichment per module\")\n",
    "print(\"\")\n",
    "\n",
    "def pick_best_compartment_col(obs: pd.DataFrame):\n",
    "    preferred = [\n",
    "        \"cell_type\",\"cell_type_label\",\"celltype\",\"annotation\",\n",
    "        \"annotation_fine\",\"annotation_coarse\",\"compartment\",\n",
    "        \"lineage\",\"subset\",\"cluster\",\"leiden\",\"louvain\",\n",
    "    ]\n",
    "    for c in preferred:\n",
    "        if c in obs.columns and 2 <= obs[c].nunique(dropna=True) <= 80:\n",
    "            return c\n",
    "    for c in obs.columns:\n",
    "        if (obs[c].dtype == \"object\" or str(obs[c].dtype).startswith(\"category\")):\n",
    "            if 2 <= obs[c].nunique(dropna=True) <= 60:\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "comp_col = pick_best_compartment_col(ts.obs)\n",
    "if comp_col is None:\n",
    "    raise RuntimeError(\"No suitable thymus compartment column in TS obs.\")\n",
    "\n",
    "ts_comp = ts_scores.copy()\n",
    "ts_comp[comp_col] = ts.obs.loc[ts_comp.index, comp_col].astype(str).values\n",
    "\n",
    "# Per-module per-compartment Wilcoxon rank-sum (one-vs-rest)\n",
    "enrichment_rows = []\n",
    "compartments = sorted(ts_comp[comp_col].unique())\n",
    "for mod in mes_cols:\n",
    "    for ct in compartments:\n",
    "        in_group  = ts_comp.loc[ts_comp[comp_col] == ct, mod].values\n",
    "        out_group = ts_comp.loc[ts_comp[comp_col] != ct, mod].values\n",
    "        if len(in_group) < 5 or len(out_group) < 5:\n",
    "            continue\n",
    "        U, pval = stats.mannwhitneyu(in_group, out_group, alternative=\"greater\")\n",
    "        d = cohens_d(in_group, out_group)\n",
    "        enrichment_rows.append({\n",
    "            \"module\": mod, \"compartment\": ct,\n",
    "            \"n_cells_in\": len(in_group),\n",
    "            \"mean_in\": round(float(in_group.mean()), 5),\n",
    "            \"mean_out\": round(float(out_group.mean()), 5),\n",
    "            \"cohens_d\": round(d, 3),\n",
    "            \"pval_wilcox\": pval,\n",
    "        })\n",
    "\n",
    "df_enrichment = pd.DataFrame(enrichment_rows)\n",
    "if len(df_enrichment):\n",
    "    df_enrichment[\"pval_BH\"] = benjamini_hochberg(\n",
    "        df_enrichment[\"pval_wilcox\"].values\n",
    "    )\n",
    "    df_enrichment[\"significant_BH005\"] = df_enrichment[\"pval_BH\"] < 0.05\n",
    "\n",
    "df_comp_ts = ts_comp.groupby(comp_col)[mes_cols].mean()\n",
    "\n",
    "# Compartment-level transfer\n",
    "def spearman_corr(a, b):\n",
    "    r, p = stats.spearmanr(a, b)\n",
    "    return float(r), float(p)\n",
    "\n",
    "def compartment_means_projected(W, adata_ref, col):\n",
    "    df = pd.DataFrame(W, columns=mes_cols, index=adata_ref.obs_names)\n",
    "    df[col] = adata_ref.obs[col].astype(str).values\n",
    "    return df.groupby(col)[mes_cols].mean()\n",
    "\n",
    "transfer_rows = []\n",
    "if comp_col in lav.obs.columns:\n",
    "    lav_means = compartment_means_projected(W_lav, lav, comp_col)\n",
    "    shared = sorted(set(df_comp_ts.index) & set(lav_means.index))\n",
    "    for c in shared:\n",
    "        r, p = spearman_corr(df_comp_ts.loc[c, mes_cols], lav_means.loc[c, mes_cols])\n",
    "        transfer_rows.append({\"target\": \"Lavaert\", \"compartment\": c,\n",
    "                              \"spearman_r\": round(r, 4), \"spearman_p\": p})\n",
    "\n",
    "if comp_col in le.obs.columns:\n",
    "    le_means = compartment_means_projected(W_le, le, comp_col)\n",
    "    shared = sorted(set(df_comp_ts.index) & set(le_means.index))\n",
    "    for c in shared:\n",
    "        r, p = spearman_corr(df_comp_ts.loc[c, mes_cols], le_means.loc[c, mes_cols])\n",
    "        transfer_rows.append({\"target\": \"Le\", \"compartment\": c,\n",
    "                              \"spearman_r\": round(r, 4), \"spearman_p\": p})\n",
    "\n",
    "df_transfer = pd.DataFrame(transfer_rows)\n",
    "if len(df_transfer):\n",
    "    df_transfer[\"pval_BH\"] = benjamini_hochberg(df_transfer[\"spearman_p\"].values)\n",
    "\n",
    "# 13) MODULE ANNOTATION — GENE TABLES + HYPERGEOMETRIC ENRICHMENT\n",
    "print(f\"\\n{'='*72}\")\n",
    "print(\"MODULE ANNOTATION: top genes + axis enrichment (hypergeometric)\")\n",
    "print(\"\")\n",
    "\n",
    "TOP_K = 20\n",
    "module_rows, top_rows = [], []\n",
    "for comp in range(K_MAIN):\n",
    "    w = pd.Series(H_ts[comp, :], index=GENE_UNI_UP)\n",
    "    # Axis enrichment via hypergeometric\n",
    "    top_genes_set = w.sort_values(ascending=False).head(100).index.tolist()\n",
    "    enr = {}\n",
    "    for ax_name, genes_ax in AXIS.items():\n",
    "        res = hypergeom_enrichment(top_genes_set, genes_ax, len(GENE_UNI_UP))\n",
    "        enr[ax_name] = res\n",
    "    best_axis = max(enr, key=lambda x: enr[x][\"fold_enrichment\"])\n",
    "    module_rows.append({\n",
    "        \"module\": f\"MES{comp+1:02d}\",\n",
    "        \"best_axis\": best_axis,\n",
    "        \"best_fold_enrichment\": enr[best_axis][\"fold_enrichment\"],\n",
    "        \"best_pval_hypergeom\": enr[best_axis][\"pval_hypergeom\"],\n",
    "        \"best_overlap_genes\": enr[best_axis][\"overlap_genes\"],\n",
    "        **{f\"fold_{k}\": v[\"fold_enrichment\"] for k, v in enr.items()},\n",
    "        **{f\"pval_{k}\": v[\"pval_hypergeom\"] for k, v in enr.items()},\n",
    "    })\n",
    "    # Top K genes\n",
    "    wtop = w.sort_values(ascending=False).head(TOP_K)\n",
    "    for r, (g, val) in enumerate(wtop.items(), start=1):\n",
    "        top_rows.append({\"module\": f\"MES{comp+1:02d}\", \"rank\": r,\n",
    "                         \"gene\": g, \"weight\": round(float(val), 6)})\n",
    "\n",
    "df_module = pd.DataFrame(module_rows)\n",
    "# BH correct the best p-values\n",
    "df_module[\"best_pval_BH\"] = benjamini_hochberg(\n",
    "    df_module[\"best_pval_hypergeom\"].values\n",
    ")\n",
    "\n",
    "df_top = pd.DataFrame(top_rows)\n",
    "df_weights = pd.DataFrame(\n",
    "    H_ts.T, index=GENE_UNI_UP, columns=mes_cols\n",
    ").reset_index().rename(columns={\"index\": \"gene\"})\n",
    "\n",
    "df_module[\"top_genes_10\"] = (\n",
    "    df_top.groupby(\"module\")[\"gene\"]\n",
    "    .apply(lambda x: \", \".join(list(x)[:10]))\n",
    "    .reindex(df_module[\"module\"]).values\n",
    ")\n",
    "\n",
    "# Full enrichment table (all axes × all modules)\n",
    "enrich_full_rows = []\n",
    "for comp in range(K_MAIN):\n",
    "    w = pd.Series(H_ts[comp, :], index=GENE_UNI_UP)\n",
    "    top100 = w.sort_values(ascending=False).head(100).index.tolist()\n",
    "    for ax_name, genes_ax in AXIS.items():\n",
    "        res = hypergeom_enrichment(top100, genes_ax, len(GENE_UNI_UP))\n",
    "        res[\"module\"] = f\"MES{comp+1:02d}\"\n",
    "        res[\"axis\"] = ax_name\n",
    "        enrich_full_rows.append(res)\n",
    "\n",
    "df_enrich_full = pd.DataFrame(enrich_full_rows)\n",
    "df_enrich_full[\"pval_BH\"] = benjamini_hochberg(\n",
    "    df_enrich_full[\"pval_hypergeom\"].values\n",
    ")\n",
    "\n",
    "# 14) PUBLICATION FIGURES\n",
    "print(f\"\\n{'='*72}\")\n",
    "print(\"FIGURES: publication-grade, multi-panel\")\n",
    "print(\"\")\n",
    "\n",
    "# UMAP (TS training only)\n",
    "print(\"  Computing UMAP (TS training) …\")\n",
    "N_EMB = 80000\n",
    "if ts_train.n_obs > N_EMB:\n",
    "    idx_emb = np.random.choice(ts_train.n_obs, size=N_EMB, replace=False)\n",
    "    ts_emb = ts_train[idx_emb].copy()\n",
    "    ts_emb_scores = ts_scores.loc[ts_emb.obs_names]\n",
    "else:\n",
    "    ts_emb = ts_train.copy()\n",
    "    ts_emb_scores = ts_scores.copy()\n",
    "\n",
    "ts_emb = ts_emb[:, hvg_ts].copy()\n",
    "sc.tl.pca(ts_emb, n_comps=50, svd_solver=\"arpack\")\n",
    "sc.pp.neighbors(ts_emb, n_neighbors=15, n_pcs=30)\n",
    "sc.tl.umap(ts_emb)\n",
    "ts_emb.obs[mes_cols] = ts_emb_scores.loc[ts_emb.obs_names, mes_cols].values\n",
    "ts_emb.obs[\"MES_dom\"] = np.array(mes_cols)[\n",
    "    np.argmax(ts_emb.obs[mes_cols].values, axis=1)\n",
    "]\n",
    "\n",
    "# MAIN FIG 1A — UMAP dominant module\n",
    "fig = plt.figure(figsize=(6.8, 5.2))\n",
    "ax = plt.gca()\n",
    "xy = ts_emb.obsm[\"X_umap\"]\n",
    "cats = ts_emb.obs[\"MES_dom\"].astype(\"category\")\n",
    "for idx_cat, cat in enumerate(sorted(cats.cat.categories)):\n",
    "    m = (cats == cat).values\n",
    "    ax.scatter(xy[m, 0], xy[m, 1], s=1.5, alpha=0.55, linewidths=0,\n",
    "               color=PALETTE_MES[idx_cat], label=cat, rasterized=True)\n",
    "ax.set_xlabel(\"UMAP1\"); ax.set_ylabel(\"UMAP2\")\n",
    "ax.set_title(\"Main Fig 1A Thymus MES dominant module per cell\")\n",
    "ax.legend(markerscale=5, bbox_to_anchor=(1.02, 1.0), loc=\"upper left\",\n",
    "          frameon=False, fontsize=6)\n",
    "save_fig(fig, \"Fig1A\", kind=\"Main\")\n",
    "\n",
    "# MAIN FIG 1B — Gene-weight heatmap (clustered)\n",
    "gene_union = sorted(df_top[\"gene\"].unique())\n",
    "wmap = {g: i for i, g in enumerate(GENE_UNI_UP)}\n",
    "mat = np.zeros((K_MAIN, len(gene_union)), dtype=float)\n",
    "for i in range(K_MAIN):\n",
    "    for j, g in enumerate(gene_union):\n",
    "        mat[i, j] = float(H_ts[i, wmap[g]]) if g in wmap else 0.0\n",
    "\n",
    "# Hierarchical clustering of genes\n",
    "if len(gene_union) > 2:\n",
    "    gene_link = linkage(mat.T, method=\"ward\", metric=\"euclidean\")\n",
    "    from scipy.cluster.hierarchy import leaves_list\n",
    "    gene_order = leaves_list(gene_link)\n",
    "else:\n",
    "    gene_order = np.arange(len(gene_union))\n",
    "\n",
    "mat_ordered = mat[:, gene_order]\n",
    "gene_labels_ordered = [gene_union[i] for i in gene_order]\n",
    "\n",
    "fig = plt.figure(figsize=(10.5, 3.8))\n",
    "ax = plt.gca()\n",
    "im = ax.imshow(mat_ordered, aspect=\"auto\", cmap=CMAP_HEAT)\n",
    "ax.set_yticks(range(K_MAIN))\n",
    "ax.set_yticklabels(mes_cols)\n",
    "ax.set_xticks(range(len(gene_labels_ordered)))\n",
    "ax.set_xticklabels(gene_labels_ordered, rotation=90, fontsize=2.5)\n",
    "ax.set_title(\"Main Fig 1B MES gene weight heatmap union of top genes\")\n",
    "cbar = plt.colorbar(im, ax=ax, fraction=0.02, pad=0.02)\n",
    "cbar.set_label(\"NMF weight\")\n",
    "plt.tight_layout()\n",
    "save_fig(fig, \"Fig1B\", kind=\"Main\")\n",
    "\n",
    "# MAIN FIG 1C — External stability heatmaps\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10.2, 3.4), constrained_layout=True)\n",
    "\n",
    "for ax, C_ext, tgt_label, perm_p in [\n",
    "    (axes[0], C_lav, \"Lavaert\", pval_lav),\n",
    "    (axes[1], C_le,  \"Le\",      pval_le),\n",
    "]:\n",
    "    im = ax.imshow(C_ext, aspect=\"equal\", cmap=CMAP_RDBU, vmin=-1, vmax=1)\n",
    "    ax.set_xticks(range(K_MAIN))\n",
    "    ax.set_xticklabels(mes_cols, rotation=45, ha=\"right\", fontsize=6)\n",
    "    ax.set_yticks(range(K_MAIN))\n",
    "    ax.set_yticklabels(mes_cols, fontsize=6)\n",
    "    ax.set_xlabel(f\"{tgt_label} refit modules\")\n",
    "    ax.set_ylabel(\"TS reference modules\")\n",
    "    for ri in range(K_MAIN):\n",
    "        for ci in range(K_MAIN):\n",
    "            v = C_ext[ri, ci]\n",
    "            col = \"white\" if abs(v) > 0.5 else \"black\"\n",
    "            ax.text(ci, ri, f\"{v:.2f}\", ha=\"center\", va=\"center\",\n",
    "                    fontsize=5, color=col)\n",
    "    ax.set_title(f\"Main Fig 1C TS vs {tgt_label} (perm p={perm_p:.3g})\")\n",
    "\n",
    "cbar = fig.colorbar(im, ax=axes.ravel().tolist(), fraction=0.02, pad=0.02)\n",
    "cbar.set_label(\"Pearson r\")\n",
    "save_fig(fig, \"Fig1C\", kind=\"Main\")\n",
    "\n",
    "# MAIN FIG 1D — Permutation null distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(9.5, 3.4), constrained_layout=True)\n",
    "\n",
    "for ax, null_dist, obs_val, perm_p, label in [\n",
    "    (axes[0], null_lav, obs_lav, pval_lav, \"Lavaert\"),\n",
    "    (axes[1], null_le,  obs_le,  pval_le,  \"Le\"),\n",
    "]:\n",
    "    ax.hist(null_dist, bins=40, color=\"#bdbdbd\", edgecolor=\"white\",\n",
    "            linewidth=0.5, density=True, label=\"Permutation null\")\n",
    "    ax.axvline(obs_val, color=\"#d7191c\", lw=2, ls=\"--\",\n",
    "               label=f\"Observed = {obs_val:.4f}\")\n",
    "    ax.set_xlabel(\"Mean matched correlation\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(f\"Main Fig 1D TS vs {label} (p = {perm_p:.3g})\")\n",
    "    ax.legend(frameon=False, fontsize=6)\n",
    "    ax.grid(alpha=0.15)\n",
    "\n",
    "save_fig(fig, \"Fig1D\", kind=\"Main\")\n",
    "\n",
    "# SUPPLEMENTARY FIG S3A — K-sweep multi-criteria\n",
    "fig_s3, axes_s3 = plt.subplots(2, 2, figsize=(10.0, 7.2), constrained_layout=True)\n",
    "\n",
    "# S3A-1: Cophenetic\n",
    "ax = axes_s3[0, 0]\n",
    "ax.plot(df_sweep[\"K\"], df_sweep[\"cophenetic\"], \"o-\", color=\"#2c7fb8\", lw=1.5)\n",
    "ax.set_xlabel(\"K\"); ax.set_ylabel(\"Cophenetic correlation\")\n",
    "ax.set_title(\"a  Cophenetic coefficient\", loc=\"left\")\n",
    "ax.set_xticks(K_LIST); ax.grid(alpha=0.2)\n",
    "\n",
    "# S3A-2: Silhouette\n",
    "ax = axes_s3[0, 1]\n",
    "ax.plot(df_sweep[\"K\"], df_sweep[\"silhouette_cosine\"], \"s-\", color=\"#d95f0e\", lw=1.5)\n",
    "ax.set_xlabel(\"K\"); ax.set_ylabel(\"Silhouette (cosine)\")\n",
    "ax.set_title(\"b  Silhouette score\", loc=\"left\")\n",
    "ax.set_xticks(K_LIST); ax.grid(alpha=0.2)\n",
    "\n",
    "# S3A-3: Reconstruction error\n",
    "ax = axes_s3[1, 0]\n",
    "ax.errorbar(df_sweep[\"K\"], df_sweep[\"recon_error_mean\"],\n",
    "            yerr=df_sweep[\"recon_error_std\"], fmt=\"D-\", color=\"#7570b3\",\n",
    "            lw=1.5, capsize=4)\n",
    "ax.set_xlabel(\"K\"); ax.set_ylabel(\"Reconstruction error (Frobenius)\")\n",
    "ax.set_title(\"c  Reconstruction error\", loc=\"left\")\n",
    "ax.set_xticks(K_LIST); ax.grid(alpha=0.2)\n",
    "\n",
    "# S3A-4: External stability\n",
    "ax = axes_s3[1, 1]\n",
    "ax.plot(df_sweep[\"K\"], df_sweep[\"ext_corr_Lavaert_mean\"], \"o-\",\n",
    "        label=\"Lavaert\", color=PALETTE_DUAL[0], lw=1.5)\n",
    "ax.plot(df_sweep[\"K\"], df_sweep[\"ext_corr_Le_mean\"], \"s-\",\n",
    "        label=\"Le\", color=PALETTE_DUAL[1], lw=1.5)\n",
    "ax.set_xlabel(\"K\"); ax.set_ylabel(\"Mean matched correlation\")\n",
    "ax.set_title(\"d  External stability vs K\", loc=\"left\")\n",
    "ax.set_xticks(K_LIST); ax.legend(frameon=False); ax.grid(alpha=0.2)\n",
    "\n",
    "save_fig(fig_s3, \"Fig3A_MES_K_sensitivity\", kind=\"Supplementary\")\n",
    "\n",
    "# SUPPLEMENTARY FIG S4 — NEGCTRL with significance\n",
    "fig_s4, axes_s4 = plt.subplots(1, 2, figsize=(11.5, 4.0),\n",
    "                                gridspec_kw={\"width_ratios\": [1.3, 1]},\n",
    "                                constrained_layout=True)\n",
    "\n",
    "# S4 left: violin plot thymus vs blood per module\n",
    "ax = axes_s4[0]\n",
    "plot_data = []\n",
    "for col in mes_cols:\n",
    "    for val in ts_scores[col].values[:5000]:   # subsample for speed\n",
    "        plot_data.append({\"module\": col, \"score\": val, \"group\": \"Thymus\"})\n",
    "    for val in blood_scores[col].values[:5000]:\n",
    "        plot_data.append({\"module\": col, \"score\": val, \"group\": \"Blood negctrl\"})\n",
    "\n",
    "df_plot = pd.DataFrame(plot_data)\n",
    "sns.violinplot(data=df_plot, x=\"module\", y=\"score\", hue=\"group\",\n",
    "               split=True, inner=\"quart\", palette=PALETTE_DUAL,\n",
    "               linewidth=0.6, ax=ax, density_norm=\"width\", cut=0)\n",
    "ax.set_xlabel(\"\"); ax.set_ylabel(\"MES score\")\n",
    "ax.set_title(\"a  MES specificity: thymus vs peripheral myeloid\", loc=\"left\",\n",
    "             )\n",
    "ax.legend(frameon=False, fontsize=6, loc=\"upper right\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "# Significance stars\n",
    "for i, row in df_negctrl_stat.iterrows():\n",
    "    star = \"\"\n",
    "    if row[\"pval_BH\"] < 0.001:\n",
    "        star = \"***\"\n",
    "    elif row[\"pval_BH\"] < 0.01:\n",
    "        star = \"**\"\n",
    "    elif row[\"pval_BH\"] < 0.05:\n",
    "        star = \"*\"\n",
    "    if star:\n",
    "        ymax = df_plot[df_plot[\"module\"] == row[\"module\"]][\"score\"].quantile(0.98)\n",
    "        ax.text(i, ymax * 1.02, star, ha=\"center\", va=\"bottom\", fontsize=7,\n",
    "                )\n",
    "\n",
    "# S4 right: effect size bar\n",
    "ax = axes_s4[1]\n",
    "colors = [\"#2ca25f\" if d > 0.5 else \"#bdbdbd\" for d in df_negctrl_stat[\"cohens_d\"]]\n",
    "ax.barh(range(K_MAIN), df_negctrl_stat[\"cohens_d\"].values, color=colors,\n",
    "        edgecolor=\"white\", linewidth=0.5)\n",
    "ax.set_yticks(range(K_MAIN))\n",
    "ax.set_yticklabels(mes_cols)\n",
    "ax.set_xlabel(\"Cohen's d (thymus > blood)\")\n",
    "ax.set_title(\"b  Effect sizes\", loc=\"left\")\n",
    "ax.axvline(0.5, ls=\"--\", color=\"grey\", lw=0.8, label=\"d=0.5 (medium)\")\n",
    "ax.axvline(0.8, ls=\":\", color=\"grey\", lw=0.8, label=\"d=0.8 (large)\")\n",
    "ax.legend(frameon=False, fontsize=6)\n",
    "ax.grid(axis=\"x\", alpha=0.2)\n",
    "\n",
    "save_fig(fig_s4, \"FigS4_NEGCTRL_Specificity\", kind=\"Supplementary\")\n",
    "\n",
    "# SUPPLEMENTARY FIG S5 — Compartment enrichment\n",
    "fig_s5 = plt.figure(figsize=(10.0, max(3.5, 0.22 * len(df_comp_ts.index) + 2.0)))\n",
    "ax = plt.gca()\n",
    "\n",
    "# Cluster rows and columns\n",
    "if len(df_comp_ts.index) > 2:\n",
    "    row_link = linkage(df_comp_ts.values, method=\"ward\")\n",
    "    row_order = leaves_list(row_link)\n",
    "else:\n",
    "    row_order = np.arange(len(df_comp_ts.index))\n",
    "\n",
    "if K_MAIN > 2:\n",
    "    col_link = linkage(df_comp_ts.values.T, method=\"ward\")\n",
    "    col_order = leaves_list(col_link)\n",
    "else:\n",
    "    col_order = np.arange(K_MAIN)\n",
    "\n",
    "mat_comp = df_comp_ts.values[np.ix_(row_order, col_order)]\n",
    "row_labels = [df_comp_ts.index[i] for i in row_order]\n",
    "col_labels = [mes_cols[i] for i in col_order]\n",
    "\n",
    "im = ax.imshow(mat_comp, aspect=\"auto\", cmap=CMAP_HEAT)\n",
    "ax.set_yticks(range(len(row_labels)))\n",
    "ax.set_yticklabels(row_labels)\n",
    "ax.set_xticks(range(len(col_labels)))\n",
    "ax.set_xticklabels(col_labels, rotation=45, ha=\"right\")\n",
    "ax.set_title(f\"Thymus compartment enrichment (column: {comp_col}; \"\n",
    "             f\"hierarchically clustered)\")\n",
    "cbar = plt.colorbar(im, ax=ax, fraction=0.02, pad=0.02, shrink=0.85)\n",
    "cbar.set_label(\"Mean MES score\")\n",
    "plt.tight_layout()\n",
    "save_fig(fig_s5, \"FigS5_ThymusCompartment_Enrichment\", kind=\"Supplementary\")\n",
    "\n",
    "# SUPPLEMENTARY FIG S6 — Compartment transfer\n",
    "if not df_transfer.empty:\n",
    "    fig_s6, axes_s6 = plt.subplots(1, 2, figsize=(9.5, 3.8),\n",
    "                                    constrained_layout=True)\n",
    "    # Left: box + strip plot of Spearman r\n",
    "    ax = axes_s6[0]\n",
    "    data_box, labels_box = [], []\n",
    "    for tgt in [\"Lavaert\", \"Le\"]:\n",
    "        vals = df_transfer[df_transfer[\"target\"] == tgt][\"spearman_r\"].dropna().values\n",
    "        if len(vals):\n",
    "            data_box.append(vals)\n",
    "            labels_box.append(tgt)\n",
    "    bp = ax.boxplot(data_box, labels=labels_box, showfliers=False,\n",
    "                    patch_artist=True, widths=0.45)\n",
    "    for patch, col in zip(bp[\"boxes\"], PALETTE_DUAL[:len(labels_box)]):\n",
    "        patch.set_facecolor(col); patch.set_alpha(0.4)\n",
    "    for i, vals in enumerate(data_box):\n",
    "        ax.scatter(np.full_like(vals, i + 1) + np.random.normal(0, 0.04, len(vals)),\n",
    "                   vals, s=18, alpha=0.7, color=PALETTE_DUAL[i], zorder=3,\n",
    "                   edgecolors=\"white\", linewidths=0.3)\n",
    "    ax.set_ylabel(\"Spearman ρ of MES profile\")\n",
    "    ax.set_title(\"a  Compartment-level transfer\", loc=\"left\")\n",
    "    ax.grid(axis=\"y\", alpha=0.2)\n",
    "    ax.axhline(0, ls=\"--\", color=\"grey\", lw=0.6)\n",
    "\n",
    "    # Right: per-compartment bars\n",
    "    ax = axes_s6[1]\n",
    "    for idx_t, tgt in enumerate([\"Lavaert\", \"Le\"]):\n",
    "        sub = df_transfer[df_transfer[\"target\"] == tgt].sort_values(\"spearman_r\",\n",
    "                                                                      ascending=True)\n",
    "        if len(sub):\n",
    "            y_pos = np.arange(len(sub)) + idx_t * 0.35\n",
    "            ax.barh(y_pos, sub[\"spearman_r\"].values, height=0.3,\n",
    "                    color=PALETTE_DUAL[idx_t], alpha=0.75, label=tgt,\n",
    "                    edgecolor=\"white\", linewidth=0.3)\n",
    "            ax.set_yticks(np.arange(len(sub)) + 0.175)\n",
    "            ax.set_yticklabels(sub[\"compartment\"].values, fontsize=5.5)\n",
    "    ax.set_xlabel(\"Spearman ρ\")\n",
    "    ax.set_title(\"b  Per-compartment Spearman ρ\", loc=\"left\")\n",
    "    ax.legend(frameon=False, fontsize=6); ax.grid(axis=\"x\", alpha=0.2)\n",
    "\n",
    "    save_fig(fig_s6, \"FigS6_Compartment_level_transfer_profile_correlation\",\n",
    "             kind=\"Supplementary\")\n",
    "\n",
    "# SUPPLEMENTARY FIG S8 — Enrichment dot plot\n",
    "fig_s7 = plt.figure(figsize=(6.5, 4.5))\n",
    "ax = plt.gca()\n",
    "\n",
    "df_dot = df_enrich_full.copy()\n",
    "df_dot[\"-log10_pBH\"] = -np.log10(df_dot[\"pval_BH\"].clip(lower=1e-20))\n",
    "df_dot[\"module_idx\"] = df_dot[\"module\"].str.extract(r\"(\\d+)\").astype(int) - 1\n",
    "ax_names = sorted(AXIS.keys())\n",
    "df_dot[\"axis_idx\"] = df_dot[\"axis\"].map({a: i for i, a in enumerate(ax_names)})\n",
    "\n",
    "for _, row in df_dot.iterrows():\n",
    "    ax.scatter(row[\"axis_idx\"], row[\"module_idx\"],\n",
    "               s=max(5, row[\"fold_enrichment\"] * 35),\n",
    "               c=row[\"-log10_pBH\"],\n",
    "               cmap=CMAP_VIRIDIS, vmin=0,\n",
    "               vmax=max(3, df_dot[\"-log10_pBH\"].quantile(0.95)),\n",
    "               edgecolors=\"black\", linewidths=0.3)\n",
    "\n",
    "ax.set_xticks(range(len(ax_names)))\n",
    "ax.set_xticklabels([a.replace(\"_\", \"\\n\") for a in ax_names], fontsize=7)\n",
    "ax.set_yticks(range(K_MAIN))\n",
    "ax.set_yticklabels(mes_cols)\n",
    "ax.set_title(\"Module–axis enrichment (size = fold enrichment; colour = −log₁₀ FDR)\",\n",
    "             fontsize=8)\n",
    "sm = plt.cm.ScalarMappable(cmap=CMAP_VIRIDIS,\n",
    "                            norm=plt.Normalize(0, max(3, df_dot[\"-log10_pBH\"].quantile(0.95))))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax, fraction=0.025, pad=0.03)\n",
    "cbar.set_label(\"−log₁₀ FDR\", fontsize=7)\n",
    "plt.tight_layout()\n",
    "save_fig(fig_s7, \"FigS7_Module_Axis_Enrichment_DotPlot\", kind=\"Supplementary\")\n",
    "\n",
    "# SUPPLEMENTARY FIG S9 — Consensus matrix for K=8\n",
    "fig_s8 = plt.figure(figsize=(5.5, 5.0))\n",
    "ax = plt.gca()\n",
    "C_consensus = consensus_results[K_MAIN][\"C_mat\"]\n",
    "# reorder by dominant module for visual clarity\n",
    "dom_labels = np.argmax(consensus_results[K_MAIN][\"W\"], axis=1)\n",
    "reorder = np.argsort(dom_labels)\n",
    "C_sorted = C_consensus[np.ix_(reorder, reorder)]\n",
    "im = ax.imshow(C_sorted, cmap=\"YlOrRd\", vmin=0, vmax=1, aspect=\"equal\")\n",
    "ax.set_title(f\"Consensus matrix K={K_MAIN} ({N_CONSENSUS} runs)\\n\"\n",
    "             f\"Cophenetic = {consensus_results[K_MAIN]['coph']:.4f}\",\n",
    "             fontsize=8)\n",
    "ax.set_xlabel(\"Cells (ordered by dominant module)\")\n",
    "ax.set_ylabel(\"Cells\")\n",
    "# Remove tick labels for large matrices\n",
    "ax.set_xticks([]); ax.set_yticks([])\n",
    "cbar = plt.colorbar(im, ax=ax, fraction=0.03, pad=0.02)\n",
    "cbar.set_label(\"Consensus\", fontsize=7)\n",
    "plt.tight_layout()\n",
    "save_fig(fig_s8, \"FigS8_Consensus_Matrix_K8\", kind=\"Supplementary\")\n",
    "\n",
    "# 15) TABLES\n",
    "print(f\"\\n{'='*72}\")\n",
    "print(\"SAVING TABLES\")\n",
    "print(\"\")\n",
    "\n",
    "# Main Table 1 (same filename)\n",
    "save_excel(\n",
    "    sheets={\n",
    "        \"Module_Summary\": df_module.sort_values(\"module\"),\n",
    "        \"TopGenes\": df_top.sort_values([\"module\", \"rank\"]),\n",
    "        \"GeneWeights\": df_weights,\n",
    "        \"Enrichment_HyperGeom\": df_enrich_full.sort_values([\"module\", \"axis\"]),\n",
    "        \"Stability_within_TS\": df_stab_within,\n",
    "        \"Stability_external_K8\": df_stab8,\n",
    "        \"Stability_ext_summary\": df_stab8_summary,\n",
    "        \"NEGCTRL_stats\": df_negctrl_stat,\n",
    "        \"NEGCTRL_summary\": df_negctrl_summary.sort_values([\"module\", \"dataset\"]),\n",
    "        \"Gene_coverage\": pd.DataFrame([\n",
    "            {\"dataset\": \"Lavaert\",      **info_lav},\n",
    "            {\"dataset\": \"Le\",           **info_le},\n",
    "            {\"dataset\": \"Blood_NEGCTRL\", **info_blood},\n",
    "        ]),\n",
    "        \"Compartment_means\": df_comp_ts.reset_index().rename(\n",
    "            columns={comp_col: \"compartment\"}),\n",
    "        \"Compartment_enrichment\": df_enrichment if len(df_enrichment) else pd.DataFrame(),\n",
    "        \"Transfer_compartment\": df_transfer if len(df_transfer) else pd.DataFrame(),\n",
    "        \"DIAGNOSTIC_gene_overlap\": df_diag,\n",
    "    },\n",
    "    fname=\"Table1\", kind=\"Main\"\n",
    ")\n",
    "\n",
    "# Supplementary Table 3 (same filename)\n",
    "save_excel(\n",
    "    sheets={\n",
    "        \"K_sweep_multi_criteria\": df_sweep.sort_values(\"K\"),\n",
    "        \"K8_matches_detail\": df_stab8.sort_values(\n",
    "            [\"target_dataset\", \"corr\"], ascending=[True, False]),\n",
    "        \"K8_summary_with_CI\": df_stab8_summary,\n",
    "    },\n",
    "    fname=\"Table3\", kind=\"Supplementary\"\n",
    ")\n",
    "\n",
    "# 16) SAVE SCORED ARTIFACTS\n",
    "print(f\"\\n{'='*72}\")\n",
    "print(\"SAVING SCORED ARTIFACTS\")\n",
    "print(\"\")\n",
    "\n",
    "# TS\n",
    "ts_scored = ts.copy()\n",
    "ts_scored.obs[mes_cols] = ts_scores.loc[ts_scored.obs_names, mes_cols].values\n",
    "ts_scored.obs[\"MES_dom\"] = np.array(mes_cols)[\n",
    "    np.argmax(ts_scored.obs[mes_cols].values, axis=1)\n",
    "]\n",
    "ts_scored = sanitize_for_write(ts_scored)\n",
    "out_ts = AIM1_DIR / \"TS_thymus_scored_K8.h5ad\"\n",
    "ts_scored.write_h5ad(out_ts)\n",
    "print(f\"  [SAVED] {out_ts}\")\n",
    "\n",
    "# Lavaert\n",
    "lav_scored = lav.copy()\n",
    "lav_scored.obs[mes_cols] = W_lav\n",
    "lav_scored.obs[\"MES_dom\"] = np.array(mes_cols)[np.argmax(W_lav, axis=1)]\n",
    "lav_scored = sanitize_for_write(lav_scored)\n",
    "out_lav = AIM1_DIR / \"Lavaert_projected_scored_K8.h5ad\"\n",
    "lav_scored.write_h5ad(out_lav)\n",
    "print(f\"  [SAVED] {out_lav}\")\n",
    "\n",
    "# Le\n",
    "le_scored = le.copy()\n",
    "le_scored.obs[mes_cols] = W_le\n",
    "le_scored.obs[\"MES_dom\"] = np.array(mes_cols)[np.argmax(W_le, axis=1)]\n",
    "le_scored = sanitize_for_write(le_scored)\n",
    "out_le = AIM1_DIR / \"Le_projected_scored_K8.h5ad\"\n",
    "le_scored.write_h5ad(out_le)\n",
    "print(f\"  [SAVED] {out_le}\")\n",
    "\n",
    "# Blood NEGCTRL\n",
    "blood_scored = blood.copy()\n",
    "blood_scored.obs[mes_cols] = W_blood\n",
    "blood_scored.obs[\"MES_dom\"] = np.array(mes_cols)[np.argmax(W_blood, axis=1)]\n",
    "blood_scored = sanitize_for_write(blood_scored)\n",
    "out_blood = NEG_DIR / \"Blood_negctrl_projected_scored_K8.h5ad\"\n",
    "blood_scored.write_h5ad(out_blood)\n",
    "print(f\"  [SAVED] {out_blood}\")\n",
    "\n",
    "# FINAL REPORT\n",
    "print(\"\")\n",
    "print(\"NB3 COMPLETED\")\n",
    "print(\"\")\n",
    "print(f\"\"\"\n",
    "STATISTICAL UPGRADES APPLIED:\n",
    "  ✓ Consensus NMF ({N_CONSENSUS} runs) with cophenetic correlation\n",
    "  ✓ Multi-criteria K selection (cophenetic, silhouette, recon error, ext stability)\n",
    "  ✓ Permutation null for external stability (500 perms, p-values)\n",
    "  ✓ Bootstrap 95% CI on matched correlations\n",
    "  ✓ Mann-Whitney U + BH correction for NEGCTRL (one-sided)\n",
    "  ✓ Cohen's d effect sizes for NEGCTRL\n",
    "  ✓ Wilcoxon rank-sum + BH for compartment enrichment (one-vs-rest)\n",
    "  ✓ Hypergeometric enrichment for axis gene sets + BH correction\n",
    "  ✓ Spearman ρ with p-values for compartment transfer\n",
    "\n",
    "FIGURE:\n",
    "  ✓ Separate Main Fig 1A/1B/1C/1D panels\n",
    "  ✓ Hierarchically clustered heatmaps\n",
    "  ✓ Violin + strip plots for NEGCTRL with significance stars\n",
    "  ✓ Effect size bars\n",
    "  ✓ Permutation null histograms (new: Main Fig 1D)\n",
    "  ✓ Enrichment dot plot (new: Fig S7)\n",
    "  ✓ Consensus matrix visualisation (new: Fig S8)\n",
    "  ✓ K-sweep multi-criteria panels (upgraded: Fig S3A)\n",
    "\n",
    "OUTPUTS:\n",
    "  Figures:\n",
    "    - Main_Fig1A.png / Main_Fig1B.png / Main_Fig1C.png\n",
    "    - Main_Fig1D.png  (NEW — permutation null)\n",
    "    - Supplementary_Fig3A_MES_K_sensitivity\n",
    "    - Supplementary_FigS4_NEGCTRL_Specificity\n",
    "    - Supplementary_FigS5_ThymusCompartment_Enrichment\n",
    "    - Supplementary_FigS6_Compartment_level_transfer_profile_correlation\n",
    "    - Supplementary_FigS7_Module_Axis_Enrichment_DotPlot  (NEW)\n",
    "    - Supplementary_FigS8_Consensus_Matrix_K8  (NEW)\n",
    "  Tables:\n",
    "    - Main_Table1.xlsx \n",
    "    - Supplementary_Table3.xlsx  (multi-criteria K-sweep)\n",
    "  Scored artifacts:\n",
    "    - {out_ts}\n",
    "    - {out_lav}\n",
    "    - {out_le}\n",
    "    - {out_blood}\n",
    "\"\"\")"
   ]
  }
 ]
}