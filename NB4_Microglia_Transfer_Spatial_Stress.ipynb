{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB4 — Microglial Transfer, Spatial Validation & Stress-Axis Calibration\n",
    "\n",
    "Projection of thymus-trained MES onto four independent microglial cohorts (SEA-AD, Olah, Tuddenham, MS GSE180759), Visium spatial validation, GR stress-axis calibration (GSE219208), and LPS tolerance model scoring.\n",
    "\n",
    "**Paper:** Zafar SA, Qin W. *Thymus-Derived Myeloid Education Signatures Predict Microglial Tolerance Positioning and Are Modulated by Glucocorticoid Stress-Axis Activity.* Neuroimmunomodulation (2026).\n",
    "\n",
    "> **Note:** Update the path variables in section 0 to match your local directory structure before running. Raw data can be obtained from the public repositories listed in Supplementary Table S1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os, re, warnings, gc, time, traceback\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import scipy.sparse as sp\n",
    "import scipy.stats as stats\n",
    "import scipy.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "sc.settings.verbosity = 2\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set_style(\"ticks\")\n",
    "    HAS_SNS = True\n",
    "except ImportError:\n",
    "    HAS_SNS = False\n",
    "\n",
    "# 0) GLOBAL STYLE\n",
    "matplotlib.rcParams.update({\n",
    "    \"font.family\": \"Arial\",\n",
    "    \"font.size\": 8,\n",
    "    \"axes.labelsize\": 8,\n",
    "    \"axes.titlesize\": 9,\n",
    "    \"xtick.labelsize\": 7,\n",
    "    \"ytick.labelsize\": 7,\n",
    "    \"legend.fontsize\": 7,\n",
    "    \"figure.titlesize\": 9,\n",
    "    \"axes.linewidth\": 0.8,\n",
    "    \"xtick.major.width\": 0.6,\n",
    "    \"ytick.major.width\": 0.6,\n",
    "    \"pdf.fonttype\": 42,\n",
    "    \"ps.fonttype\": 42,\n",
    "    \"figure.dpi\": 150,\n",
    "    \"savefig.dpi\": 1200,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "    \"savefig.pad_inches\": 0.05,\n",
    "})\n",
    "\n",
    "FIG_DPI = 1200\n",
    "\n",
    "# Color system\n",
    "CMAP_CONT = \"cividis\"\n",
    "CMAP_HEAT = \"RdBu_r\"\n",
    "CMAP_DIV  = \"RdBu_r\"\n",
    "\n",
    "C_BAR_MAIN = \"#4A4A4A\"\n",
    "C_BAR_ACC  = \"#D1495B\"\n",
    "C_BAR_ACC2 = \"#2A9D8F\"\n",
    "C_GRID     = \"#B0B0B0\"\n",
    "C_UP  = \"#C0392B\"\n",
    "C_DN  = \"#2E7D32\"\n",
    "C_NEU = \"#7F8C8D\"\n",
    "\n",
    "def _beautify_axes(ax):\n",
    "    ax.grid(axis=\"y\", alpha=0.22, color=C_GRID, linewidth=0.6)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# 0b) STATISTICAL PARAMETERS \n",
    "N_BOOT = 2000\n",
    "N_PERM = 5000\n",
    "SEED   = 42\n",
    "ALPHA  = 0.05\n",
    "\n",
    "# 1) PATHS\n",
    "BASE_DIR = Path(\".\")  # <-- SET TO YOUR PROJECT ROOT\n",
    "RAW_DIR  = BASE_DIR / \"Raw Data\"\n",
    "PROC_DIR = BASE_DIR / \"Process Data\"\n",
    "\n",
    "MANUSCRIPT_DIR = BASE_DIR / \"outputs\" / \"manuscript\"\n",
    "FIG_DIR = MANUSCRIPT_DIR / \"Figures\"\n",
    "TAB_DIR = MANUSCRIPT_DIR / \"Tables\"\n",
    "\n",
    "AIM2_DIR = PROC_DIR / \"aim2_microglia\"\n",
    "AIM3_DIR = PROC_DIR / \"aim3_stress\"\n",
    "NB4_EXPORT_DIR = PROC_DIR / \"nb4_exports\"\n",
    "\n",
    "for d in [FIG_DIR, TAB_DIR, AIM2_DIR, AIM3_DIR, NB4_EXPORT_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert RAW_DIR.exists(), f\"RAW_DIR missing: {RAW_DIR}\"\n",
    "\n",
    "GSE233208_EXPORT = NB4_EXPORT_DIR / \"GSE233208\"\n",
    "GSE233208_VIS_MTX = GSE233208_EXPORT / \"visium_mtx\"\n",
    "GSE233208_SN_MTX  = GSE233208_EXPORT / \"snrna_mtx\"\n",
    "GSE233208_EXPORT.mkdir(exist_ok=True)\n",
    "GSE233208_VIS_MTX.mkdir(exist_ok=True)\n",
    "GSE233208_SN_MTX.mkdir(exist_ok=True)\n",
    "\n",
    "# 2) SAVE HELPERS\n",
    "def save_fig(fig, fname: str, kind: str = \"Supplementary\"):\n",
    "    assert kind in (\"Main\", \"Supplementary\")\n",
    "    out = FIG_DIR / f\"{kind}_{fname}.png\"\n",
    "    fig.savefig(out, dpi=FIG_DPI, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"[SAVED FIG] {out}\")\n",
    "\n",
    "def save_excel(sheets: dict, fname: str, kind: str = \"Supplementary\"):\n",
    "    assert kind in (\"Main\", \"Supplementary\")\n",
    "    out = TAB_DIR / f\"{kind}_{fname}.xlsx\"\n",
    "    with pd.ExcelWriter(out, engine=\"openpyxl\") as w:\n",
    "        for sn, df in sheets.items():\n",
    "            if df is None:\n",
    "                df = pd.DataFrame()\n",
    "            df.to_excel(w, index=False, sheet_name=str(sn)[:31])\n",
    "    print(f\"[SAVED TABLE] {out}\")\n",
    "\n",
    "def sanitize_for_write(adata: ad.AnnData) -> ad.AnnData:\n",
    "    for df_name in [\"obs\", \"var\"]:\n",
    "        df = getattr(adata, df_name)\n",
    "        if df.index.name is not None:\n",
    "            idx_name = df.index.name\n",
    "            if idx_name in df.columns:\n",
    "                if not pd.Series(df.index, index=df.index).equals(df[idx_name]):\n",
    "                    df.rename(columns={idx_name: f\"{idx_name}_col\"}, inplace=True)\n",
    "            df.index.name = None\n",
    "        df.columns = df.columns.astype(str)\n",
    "    adata.obs_names = adata.obs_names.astype(str)\n",
    "    adata.var_names = adata.var_names.astype(str)\n",
    "    return adata\n",
    "\n",
    "def sig_stars(p):\n",
    "    if pd.isna(p) or not np.isfinite(p): return \"ns\"\n",
    "    if p < 0.001: return \"***\"\n",
    "    if p < 0.01:  return \"**\"\n",
    "    if p < 0.05:  return \"*\"\n",
    "    return \"ns\"\n",
    "\n",
    "# 3) CORE HELPERS \n",
    "def ensure_counts_layer(adata):\n",
    "    if \"counts\" not in adata.layers:\n",
    "        adata.layers[\"counts\"] = adata.X.copy()\n",
    "    if not sp.issparse(adata.layers[\"counts\"]):\n",
    "        adata.layers[\"counts\"] = sp.csr_matrix(adata.layers[\"counts\"])\n",
    "\n",
    "def looks_log1p(adata, n=2000):\n",
    "    if adata.n_obs == 0 or adata.n_vars == 0: return False\n",
    "    X = adata.X\n",
    "    if sp.issparse(X):\n",
    "        v = X.data\n",
    "        if v.size == 0: return False\n",
    "        v = v[:min(v.size, n)]\n",
    "    else:\n",
    "        v = np.asarray(X).ravel()[:n]\n",
    "    frac_nonint = np.mean(np.abs(v - np.round(v)) > 1e-6)\n",
    "    return (np.nanmax(v) < 25) and (frac_nonint > 0.2)\n",
    "\n",
    "def prep_for_scoring(adata):\n",
    "    if adata.n_obs == 0 or adata.n_vars == 0: return\n",
    "    ensure_counts_layer(adata)\n",
    "    if looks_log1p(adata): return\n",
    "    adata.X = adata.layers[\"counts\"].copy()\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "def compute_basic_qc(adata):\n",
    "    if \"mt\" not in adata.var.columns:\n",
    "        adata.var[\"mt\"] = adata.var_names.astype(str).str.upper().str.startswith(\"MT-\")\n",
    "    sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\"], percent_top=None, log1p=False, inplace=True)\n",
    "\n",
    "def safe_corr(x, y):\n",
    "    x = np.asarray(x); y = np.asarray(y)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    if m.sum() < 3: return np.nan\n",
    "    return float(np.corrcoef(x[m], y[m])[0, 1])\n",
    "\n",
    "def bh_fdr(pvals):\n",
    "    p = np.asarray(pvals, float)\n",
    "    m = np.isfinite(p)\n",
    "    out = np.full_like(p, np.nan, dtype=float)\n",
    "    if m.sum() == 0: return out\n",
    "    pv = p[m]; n = pv.size\n",
    "    order = np.argsort(pv)\n",
    "    ranked = pv[order]\n",
    "    q = ranked * n / (np.arange(1, n + 1))\n",
    "    q = np.minimum.accumulate(q[::-1])[::-1]\n",
    "    out_m = np.empty_like(pv)\n",
    "    out_m[order] = np.clip(q, 0, 1)\n",
    "    out[m] = out_m\n",
    "    return out\n",
    "\n",
    "def corr_with_ci_p(x, y, n_boot=N_BOOT, n_perm=N_PERM, seed=SEED):\n",
    "    \"\"\"Correlation with bootstrap CI + permutation p-value. UPGRADED: 2000/5000.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    x = np.asarray(x, float); y = np.asarray(y, float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[m]; y = y[m]; n = x.size\n",
    "    if n < 10:\n",
    "        return {\"n\": n, \"r\": np.nan, \"ci_low\": np.nan, \"ci_high\": np.nan, \"p_perm\": np.nan}\n",
    "    r_obs = float(np.corrcoef(x, y)[0, 1])\n",
    "    boot = np.full(n_boot, np.nan)\n",
    "    for i in range(n_boot):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        boot[i] = np.corrcoef(x[idx], y[idx])[0, 1]\n",
    "    fb = boot[np.isfinite(boot)]\n",
    "    ci_low, ci_high = (np.nanpercentile(fb, [2.5, 97.5]) if len(fb) > 10 else (np.nan, np.nan))\n",
    "    perm_count = 0\n",
    "    for _ in range(n_perm):\n",
    "        yp = rng.permutation(y)\n",
    "        if abs(np.corrcoef(x, yp)[0, 1]) >= abs(r_obs):\n",
    "            perm_count += 1\n",
    "    p = float((perm_count + 1) / (n_perm + 1))\n",
    "    return {\"n\": n, \"r\": r_obs, \"ci_low\": float(ci_low), \"ci_high\": float(ci_high), \"p_perm\": p}\n",
    "\n",
    "def cohens_d_with_ci(a, b, n_boot=N_BOOT, seed=SEED):\n",
    "    \"\"\"Cohen's d with bootstrap 95% CI. NEW.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    a = a[np.isfinite(a)]; b = b[np.isfinite(b)]\n",
    "    if len(a) < 2 or len(b) < 2:\n",
    "        return {\"d\": np.nan, \"ci_lo\": np.nan, \"ci_hi\": np.nan, \"n_a\": len(a), \"n_b\": len(b)}\n",
    "\n",
    "    def _d(aa, bb):\n",
    "        va = np.var(aa, ddof=1); vb = np.var(bb, ddof=1)\n",
    "        sp2 = ((len(aa) - 1) * va + (len(bb) - 1) * vb) / max(len(aa) + len(bb) - 2, 1)\n",
    "        if sp2 <= 1e-12: return np.nan\n",
    "        return float((np.mean(aa) - np.mean(bb)) / np.sqrt(sp2))\n",
    "\n",
    "    d_obs = _d(a, b)\n",
    "    boots = np.full(n_boot, np.nan)\n",
    "    for i in range(n_boot):\n",
    "        aa = rng.choice(a, size=len(a), replace=True)\n",
    "        bb = rng.choice(b, size=len(b), replace=True)\n",
    "        boots[i] = _d(aa, bb)\n",
    "    fb = boots[np.isfinite(boots)]\n",
    "    ci_lo, ci_hi = (np.nanpercentile(fb, [2.5, 97.5]) if len(fb) > 10 else (np.nan, np.nan))\n",
    "    return {\"d\": d_obs, \"ci_lo\": float(ci_lo), \"ci_hi\": float(ci_hi), \"n_a\": len(a), \"n_b\": len(b)}\n",
    "\n",
    "def auc_with_ci(y01, scores, n_boot=N_BOOT, seed=SEED):\n",
    "    \"\"\"AUC with bootstrap CI. NEW.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.asarray(y01).astype(int)\n",
    "    s = np.asarray(scores).astype(float)\n",
    "    m = np.isfinite(s)\n",
    "    y = y[m]; s = s[m]\n",
    "    if len(np.unique(y)) < 2 or y.size < 6:\n",
    "        return {\"auc\": np.nan, \"ci_lo\": np.nan, \"ci_hi\": np.nan, \"n\": y.size}\n",
    "\n",
    "    def _auc(yy, ss):\n",
    "        n1 = (yy == 1).sum(); n0 = (yy == 0).sum()\n",
    "        if n1 == 0 or n0 == 0: return np.nan\n",
    "        ranks = stats.rankdata(ss)\n",
    "        return float((ranks[yy == 1].sum() - n1 * (n1 + 1) / 2) / (n1 * n0))\n",
    "\n",
    "    auc_obs = _auc(y, s)\n",
    "    boots = np.full(n_boot, np.nan)\n",
    "    for i in range(n_boot):\n",
    "        idx = rng.integers(0, y.size, y.size)\n",
    "        boots[i] = _auc(y[idx], s[idx])\n",
    "    fb = boots[np.isfinite(boots)]\n",
    "    ci_lo, ci_hi = (np.nanpercentile(fb, [2.5, 97.5]) if len(fb) > 10 else (np.nan, np.nan))\n",
    "    return {\"auc\": auc_obs, \"ci_lo\": float(ci_lo), \"ci_hi\": float(ci_hi), \"n\": y.size}\n",
    "\n",
    "def build_confound_matrix(df, conf_cols):\n",
    "    Xparts = []\n",
    "    for c in conf_cols:\n",
    "        if c not in df.columns: continue\n",
    "        s = df[c]\n",
    "        if pd.api.types.is_numeric_dtype(s):\n",
    "            Xparts.append(pd.DataFrame({c: pd.to_numeric(s, errors=\"coerce\")}))\n",
    "        else:\n",
    "            d = pd.get_dummies(s.astype(str), prefix=c, dummy_na=True)\n",
    "            Xparts.append(d)\n",
    "    if not Xparts: return None\n",
    "    X = pd.concat(Xparts, axis=1).replace([np.inf, -np.inf], np.nan)\n",
    "    keep = [c for c in X.columns if np.isfinite(X[c].values).sum() >= 3 and np.nanstd(X[c].values) > 1e-12]\n",
    "    return X[keep].astype(float) if keep else None\n",
    "\n",
    "def residualize(y, X):\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if X is None or X.shape[1] == 0: return y\n",
    "    Xv = X.values.astype(float)\n",
    "    m = np.isfinite(y) & np.all(np.isfinite(Xv), axis=1)\n",
    "    if m.sum() < 5: return y * np.nan\n",
    "    yy = y[m]\n",
    "    XX = np.column_stack([np.ones((m.sum(), 1)), Xv[m]])\n",
    "    beta, *_ = np.linalg.lstsq(XX, yy, rcond=None)\n",
    "    resid = np.full_like(y, np.nan)\n",
    "    resid[m] = yy - (XX @ beta)\n",
    "    return resid\n",
    "\n",
    "def pick_donor_col(df):\n",
    "    candidates = [\n",
    "        \"donor_id\", \"donor\", \"Donor\", \"subject\", \"Subject\", \"individual\", \"Individual\",\n",
    "        \"patient\", \"Patient\", \"participant\", \"Participant\", \"case_id\", \"Case\",\n",
    "        \"participant_id\", \"donor_id_clean\", \"donorID\", \"DonorID\", \"sample_id\",\n",
    "        \"Sample\", \"sample\", \"Donor ID\", \"orig.ident\"\n",
    "    ]\n",
    "    cols = list(df.columns)\n",
    "    for c in candidates:\n",
    "        if c in cols: return c\n",
    "    low = {c.lower(): c for c in cols}\n",
    "    for key in [\"donor\", \"subject\", \"patient\", \"individual\", \"participant\", \"case\", \"orig.ident\"]:\n",
    "        for lc, orig in low.items():\n",
    "            if key in lc: return orig\n",
    "    return None\n",
    "\n",
    "def donor_aggregate(df_obs, donor_col, cols_needed):\n",
    "    g = df_obs.groupby(donor_col, dropna=False)\n",
    "    out = pd.DataFrame(index=g.size().index)\n",
    "    out[donor_col] = out.index.astype(str)\n",
    "    num_cols = [c for c in cols_needed if c in df_obs.columns and pd.api.types.is_numeric_dtype(df_obs[c])]\n",
    "    if num_cols:\n",
    "        out[num_cols] = g[num_cols].mean(numeric_only=True)\n",
    "    cat_cols = [c for c in cols_needed if c in df_obs.columns and c not in num_cols]\n",
    "    for c in cat_cols:\n",
    "        def _mode(x):\n",
    "            x = x.dropna()\n",
    "            return x.astype(str).value_counts().index[0] if not x.empty else np.nan\n",
    "        out[c] = g[c].apply(_mode)\n",
    "    return out.reset_index(drop=True)\n",
    "\n",
    "# 4) Gene symbol handling\n",
    "MARKER_PROBE = [\"P2RY12\", \"CX3CR1\", \"TMEM119\", \"CSF1R\", \"NR3C1\", \"FKBP5\", \"LGALS3\", \"AIF1\", \"LST1\", \"TYROBP\"]\n",
    "\n",
    "def _upper_map(var_names):\n",
    "    return {str(v).upper(): str(v) for v in var_names}\n",
    "\n",
    "def _overlap_symbols(adata, genes):\n",
    "    m = _upper_map(adata.var_names)\n",
    "    return sum(1 for g in genes if str(g).upper() in m)\n",
    "\n",
    "def ensure_gene_symbols(adata, dataset_name):\n",
    "    ov = _overlap_symbols(adata, MARKER_PROBE)\n",
    "    if ov >= 3: return adata\n",
    "    candidates = [\"gene_symbol\", \"gene_symbols\", \"symbol\", \"symbols\", \"feature_name\",\n",
    "                  \"name\", \"gene\", \"gene_name\", \"hgnc_symbol\"]\n",
    "    found = [c for c in candidates if c in adata.var.columns]\n",
    "    if not found:\n",
    "        print(f\"[WARN] {dataset_name}: low marker overlap ({ov}) and no symbol columns.\")\n",
    "        return adata\n",
    "    best_col, best_score = None, -1\n",
    "    for c in found:\n",
    "        s = adata.var[c].astype(str)\n",
    "        non_ens = (~s.str.upper().str.startswith(\"ENSG\")).mean()\n",
    "        has_letters = s.str.contains(r\"[A-Za-z]\", regex=True).mean()\n",
    "        score = float(non_ens + 0.5 * has_letters)\n",
    "        if score > best_score:\n",
    "            best_score, best_col = score, c\n",
    "    new_names = adata.var[best_col].astype(str).values\n",
    "    new_names = np.where((new_names == \"nan\") | (new_names == \"\") | pd.isna(new_names),\n",
    "                         adata.var_names.values, new_names)\n",
    "    adata.var[\"gene_symbol_used\"] = new_names\n",
    "    adata.var_names = pd.Index(new_names).astype(str)\n",
    "    adata.var_names_make_unique()\n",
    "    ov2 = _overlap_symbols(adata, MARKER_PROBE)\n",
    "    print(f\"[FIX] {dataset_name}: remapped using .var['{best_col}'] | overlap {ov} -> {ov2}\")\n",
    "    return adata\n",
    "\n",
    "def _genes_present_case_insensitive(adata, genes):\n",
    "    m = {g.upper(): g for g in adata.var_names.astype(str)}\n",
    "    seen = set(); out = []\n",
    "    for g in genes:\n",
    "        gg = str(g).upper()\n",
    "        if gg in m and m[gg] not in seen:\n",
    "            out.append(m[gg]); seen.add(m[gg])\n",
    "    return out\n",
    "\n",
    "def score_geneset(adata, genes, score_name, min_genes=3):\n",
    "    if adata.n_obs == 0 or adata.n_vars == 0:\n",
    "        adata.obs[score_name] = np.nan; return\n",
    "    present = _genes_present_case_insensitive(adata, genes)\n",
    "    if len(present) < min_genes:\n",
    "        adata.obs[score_name] = np.nan; return\n",
    "    sc.tl.score_genes(adata, present, score_name=score_name, use_raw=False)\n",
    "\n",
    "def subset_microglia_by_markers(adata, min_hits=2, extra=None):\n",
    "    if adata.n_obs == 0: return adata\n",
    "    markers = [\"P2RY12\", \"CX3CR1\", \"TMEM119\", \"CSF1R\"]\n",
    "    if extra: markers += list(extra)\n",
    "    present = _genes_present_case_insensitive(adata, markers)\n",
    "    if len(present) < 2: return adata\n",
    "    X = adata[:, present].X\n",
    "    if sp.issparse(X): X = X.toarray()\n",
    "    keep = (X > 0).sum(axis=1) >= min_hits\n",
    "    return adata[keep].copy()\n",
    "\n",
    "def add_common_cols(adata, dataset, cohort):\n",
    "    adata.obs[\"dataset\"] = dataset\n",
    "    adata.obs[\"cohort\"] = cohort\n",
    "    adata.obs_names = adata.obs_names.astype(str)\n",
    "    adata.var_names_make_unique()\n",
    "\n",
    "def summarize_dataset_confounds(adata):\n",
    "    compute_basic_qc(adata)\n",
    "    conf = []\n",
    "    for c in [\"total_counts\", \"pct_counts_mt\", \"n_genes_by_counts\"]:\n",
    "        if c in adata.obs.columns: conf.append(c)\n",
    "    for key in [\"batch\", \"Batch\", \"platform\", \"Platform\", \"assay\", \"Assay\", \"region\", \"Region\",\n",
    "                \"brain_region\", \"Brain region\", \"library\", \"Library\", \"Sex\", \"sex\", \"Diagnosis\",\n",
    "                \"diagnosis\", \"Age at Death\", \"age\", \"PMI\", \"pmi\", \"Brain pH\", \"orig.ident\"]:\n",
    "        if key in adata.obs.columns: conf.append(key)\n",
    "    return list(dict.fromkeys(conf))\n",
    "\n",
    "# 5) LOAD MES MODULES (from NB3: Main_Table1.xlsx)\n",
    "main_table1 = TAB_DIR / \"Main_Table1.xlsx\"\n",
    "assert main_table1.exists(), f\"Missing: {main_table1}\"\n",
    "df_weights = pd.read_excel(main_table1, sheet_name=\"GeneWeights\")\n",
    "mes_cols = [c for c in df_weights.columns if str(c).startswith(\"MES\")]\n",
    "assert len(mes_cols) == 8\n",
    "\n",
    "TOP_N_MES = 50\n",
    "mes_gene_sets = {}\n",
    "for mes in mes_cols:\n",
    "    sub = df_weights[[\"gene\", mes]].dropna().sort_values(mes, ascending=False).head(TOP_N_MES)\n",
    "    mes_gene_sets[mes] = sub[\"gene\"].astype(str).tolist()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"NB4: UPGRADE — LOADING MES MODULES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Loaded {len(mes_cols)} MES modules with top {TOP_N_MES} genes each.\")\n",
    "\n",
    "MES_MODULES = mes_gene_sets\n",
    "globals()[\"MES_MODULES\"] = MES_MODULES\n",
    "tab = df_weights.copy()\n",
    "globals()[\"tab\"] = tab\n",
    "\n",
    "# 6) HK SENSITIVITY\n",
    "def is_housekeeping(g):\n",
    "    g = str(g).upper()\n",
    "    if g in {\"MALAT1\"}: return True\n",
    "    if g.startswith(\"MT-\"): return True\n",
    "    if g.startswith(\"RPL\") or g.startswith(\"RPS\"): return True\n",
    "    return False\n",
    "\n",
    "hk_report = []\n",
    "mes_gene_sets_hk_stripped = {}\n",
    "for mes, genes in mes_gene_sets.items():\n",
    "    hk = [g for g in genes if is_housekeeping(g)]\n",
    "    mes_gene_sets_hk_stripped[mes] = [g for g in genes if not is_housekeeping(g)]\n",
    "    hk_report.append({\"MES\": mes, \"topN\": len(genes), \"hk_n\": len(hk),\n",
    "                       \"hk_frac\": len(hk) / max(len(genes), 1),\n",
    "                       \"hk_examples\": \", \".join(hk[:10])})\n",
    "df_hk = pd.DataFrame(hk_report).sort_values(\"hk_frac\", ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.0, 3.0))\n",
    "colors = [\"#D6604D\" if f > 0.1 else \"#FDAE6B\" if f > 0.05 else \"#66C2A5\" for f in df_hk[\"hk_frac\"]]\n",
    "ax.bar(df_hk[\"MES\"], df_hk[\"hk_frac\"], color=colors, edgecolor=\"black\", linewidth=0.3)\n",
    "ax.axhline(0.1, color=\"grey\", linewidth=0.5, linestyle=\":\")\n",
    "ax.set_ylabel(\"Housekeeping fraction (top 50)\")\n",
    "ax.set_title(\"Supplementary Fig 2F  MES housekeeping load check\")\n",
    "_beautify_axes(ax)\n",
    "save_fig(fig, \"Fig2F_HK_Load\", kind=\"Supplementary\")\n",
    "\n",
    "# 7) STRESS-AXIS CALIBRATION (GSE219208)\n",
    "SIG = {\n",
    "    \"microglia_homeostatic\": [\"P2RY12\", \"CX3CR1\", \"TMEM119\", \"GPR34\", \"SALL1\", \"CSF1R\", \"OLFM3\"],\n",
    "    \"microglia_activation\": [\"APOE\", \"SPP1\", \"LPL\", \"TREM2\", \"CST7\", \"CTSD\", \"TYROBP\", \"FCER1G\", \"LGALS3\", \"CD68\"],\n",
    "    \"oxphos\": [\"NDUFA1\", \"NDUFB8\", \"NDUFS1\", \"COX4I1\", \"COX5A\", \"ATP5F1A\", \"ATP5F1B\", \"UQCRC1\", \"UQCRC2\"],\n",
    "    \"glycolysis\": [\"HK1\", \"HK2\", \"PFKM\", \"ALDOA\", \"GAPDH\", \"ENO1\", \"PKM\", \"LDHA\", \"SLC2A1\"],\n",
    "}\n",
    "GR_CORE_CURATED = [\"NR3C1\", \"FKBP5\", \"TSC22D3\", \"DDIT4\", \"KLF9\"]\n",
    "EXPR_G = [\"LGALS3\", \"FNDC5\", \"NR3C1\"]\n",
    "\n",
    "stress_hits = list(RAW_DIR.rglob(\"GSE219208_Non-Normalized_read_counts_combined_lanes_.csv\"))\n",
    "assert len(stress_hits) >= 1, \"Missing GSE219208 counts CSV\"\n",
    "stress_csv = stress_hits[0]\n",
    "df_stress_raw = pd.read_csv(stress_csv, index_col=0)\n",
    "\n",
    "def parse_gse219208_prefix(col):\n",
    "    base = str(col).split(\"_\")[0].lower()\n",
    "    washout = \"wo\" in base\n",
    "    if base.startswith(\"ctl\"):\n",
    "        return {\"sample\": col, \"prefix\": base, \"group\": \"Control\", \"drug\": \"ctl\", \"dose\": None, \"washout\": washout}\n",
    "    if base.startswith(\"cort\"):\n",
    "        dose = \"high\" if base.startswith(\"corth\") else (\"low\" if base.startswith(\"cortl\") else None)\n",
    "        return {\"sample\": col, \"prefix\": base, \"group\": \"Washout\" if washout else \"Treated\", \"drug\": \"cort\", \"dose\": dose, \"washout\": washout}\n",
    "    if base.startswith(\"dex\"):\n",
    "        dose = \"high\" if base.startswith(\"dexh\") else (\"low\" if base.startswith(\"dexl\") else None)\n",
    "        return {\"sample\": col, \"prefix\": base, \"group\": \"Washout\" if washout else \"Treated\", \"drug\": \"dex\", \"dose\": dose, \"washout\": washout}\n",
    "    if base.startswith(\"cv\") or base.startswith(\"dv\"):\n",
    "        return {\"sample\": col, \"prefix\": base, \"group\": \"Control\", \"drug\": base[:2], \"dose\": None, \"washout\": washout}\n",
    "    return {\"sample\": col, \"prefix\": base, \"group\": \"Unknown\", \"drug\": \"unknown\", \"dose\": None, \"washout\": washout}\n",
    "\n",
    "df_meta_stress = pd.DataFrame([parse_gse219208_prefix(c) for c in df_stress_raw.columns])\n",
    "print(\"GSE219208 label breakdown:\", df_meta_stress[\"group\"].value_counts().to_dict())\n",
    "\n",
    "ctrl_cols    = df_meta_stress[df_meta_stress[\"group\"] == \"Control\"][\"sample\"].tolist()\n",
    "treated_cols = df_meta_stress[df_meta_stress[\"group\"] == \"Treated\"][\"sample\"].tolist()\n",
    "washout_cols = df_meta_stress[df_meta_stress[\"group\"] == \"Washout\"][\"sample\"].tolist()\n",
    "assert len(ctrl_cols) >= 2 and len(treated_cols) >= 2\n",
    "\n",
    "# Drug-type breakdown\n",
    "dex_treated = df_meta_stress[(df_meta_stress[\"group\"] == \"Treated\") & (df_meta_stress[\"drug\"] == \"dex\")][\"sample\"].tolist()\n",
    "cort_treated = df_meta_stress[(df_meta_stress[\"group\"] == \"Treated\") & (df_meta_stress[\"drug\"] == \"cort\")][\"sample\"].tolist()\n",
    "\n",
    "gene_sums = df_stress_raw.sum(axis=1)\n",
    "df_filt = df_stress_raw.loc[gene_sums >= 10].copy()\n",
    "df_cpm = df_filt.div(df_filt.sum(axis=0), axis=1) * 1e6\n",
    "df_log = np.log2(df_cpm + 1.0)\n",
    "\n",
    "de_rows = []\n",
    "for gene in df_log.index:\n",
    "    a = df_log.loc[gene, treated_cols].values.astype(float)\n",
    "    b = df_log.loc[gene, ctrl_cols].values.astype(float)\n",
    "    a = a[np.isfinite(a)]; b = b[np.isfinite(b)]\n",
    "    if len(a) < 2 or len(b) < 2: continue\n",
    "    log2fc = float(np.mean(a) - np.mean(b))\n",
    "    try:\n",
    "        _, p = stats.ttest_ind(a, b, equal_var=False)\n",
    "        p = float(p)\n",
    "    except:\n",
    "        p = 1.0\n",
    "    de_rows.append({\"gene\": gene, \"log2FC\": log2fc, \"pval\": p})\n",
    "\n",
    "df_de = pd.DataFrame(de_rows).sort_values(\"pval\")\n",
    "df_de[\"padj\"] = bh_fdr(df_de[\"pval\"].values)\n",
    "\n",
    "LOG2FC_T = 0.5\n",
    "PADJ_T = 0.05 \n",
    "sig_up = df_de[(df_de[\"log2FC\"] > LOG2FC_T) & (df_de[\"padj\"] < PADJ_T)].sort_values(\"log2FC\", ascending=False)\n",
    "sig_dn = df_de[(df_de[\"log2FC\"] < -LOG2FC_T) & (df_de[\"padj\"] < PADJ_T)].sort_values(\"log2FC\", ascending=True)\n",
    "if len(sig_up) < 10:\n",
    "    sig_up = df_de[df_de[\"log2FC\"] > 0.3].sort_values(\"log2FC\", ascending=False)\n",
    "if len(sig_dn) < 10:\n",
    "    sig_dn = df_de[df_de[\"log2FC\"] < -0.3].sort_values(\"log2FC\", ascending=True)\n",
    "\n",
    "TOP_N_SIG = 50\n",
    "GR_UP = sig_up[\"gene\"].head(TOP_N_SIG).astype(str).tolist()\n",
    "GR_DN = sig_dn[\"gene\"].head(TOP_N_SIG).astype(str).tolist()\n",
    "if len(GR_UP) < 5:\n",
    "    GR_UP = GR_CORE_CURATED.copy(); GR_DN = []\n",
    "\n",
    "def sample_score_from_log(df_log_gxS, up_genes, dn_genes):\n",
    "    up = [g for g in up_genes if g in df_log_gxS.index]\n",
    "    dn = [g for g in dn_genes if g in df_log_gxS.index]\n",
    "    if len(up) < 3: return pd.Series(index=df_log_gxS.columns, data=np.nan)\n",
    "    s_up = df_log_gxS.loc[up].mean(axis=0)\n",
    "    s_dn = df_log_gxS.loc[dn].mean(axis=0) if len(dn) >= 3 else 0.0\n",
    "    return (s_up - s_dn).astype(float)\n",
    "\n",
    "stress_score = sample_score_from_log(df_log, GR_UP, GR_DN)\n",
    "df_meta_stress[\"GR_score\"] = df_meta_stress[\"sample\"].map(stress_score.to_dict())\n",
    "df184 = df_meta_stress\n",
    "globals()[\"df184\"] = df184\n",
    "\n",
    "# AUC + Cohen's d with CIs\n",
    "y_auc = np.array([0] * len(ctrl_cols) + [1] * len(treated_cols))\n",
    "s_auc = np.array(list(stress_score[ctrl_cols].values) + list(stress_score[treated_cols].values))\n",
    "auc_res = auc_with_ci(y_auc, s_auc, n_boot=N_BOOT, seed=SEED)\n",
    "auc_ct = auc_res[\"auc\"]\n",
    "\n",
    "d_res = cohens_d_with_ci(stress_score[treated_cols].values, stress_score[ctrl_cols].values,\n",
    "                         n_boot=N_BOOT, seed=SEED)\n",
    "d_treat_vs_ctrl = d_res[\"d\"]\n",
    "\n",
    "# Drug-type specific AUCs\n",
    "drug_breakdown = []\n",
    "for drug_name, drug_cols in [(\"dex\", dex_treated), (\"cort\", cort_treated)]:\n",
    "    if len(drug_cols) >= 2:\n",
    "        ya = np.array([0] * len(ctrl_cols) + [1] * len(drug_cols))\n",
    "        sa = np.array(list(stress_score[ctrl_cols].values) + list(stress_score[drug_cols].values))\n",
    "        ar = auc_with_ci(ya, sa, n_boot=min(N_BOOT, 500), seed=SEED + 10)\n",
    "        dr = cohens_d_with_ci(stress_score[drug_cols].values, stress_score[ctrl_cols].values,\n",
    "                              n_boot=min(N_BOOT, 500), seed=SEED + 10)\n",
    "        drug_breakdown.append({\"drug\": drug_name, \"n_treated\": len(drug_cols), \"n_ctrl\": len(ctrl_cols),\n",
    "                               \"auc\": ar[\"auc\"], \"auc_ci_lo\": ar[\"ci_lo\"], \"auc_ci_hi\": ar[\"ci_hi\"],\n",
    "                               \"d\": dr[\"d\"], \"d_ci_lo\": dr[\"ci_lo\"], \"d_ci_hi\": dr[\"ci_hi\"]})\n",
    "df_drug_bd = pd.DataFrame(drug_breakdown)\n",
    "\n",
    "# GR signature sensitivity: top 30/50/100\n",
    "gr_sens_rows = []\n",
    "for topN in [30, 50, 100]:\n",
    "    up_n = sig_up[\"gene\"].head(topN).astype(str).tolist()\n",
    "    dn_n = sig_dn[\"gene\"].head(topN).astype(str).tolist()\n",
    "    if len(up_n) < 5: continue\n",
    "    ss = sample_score_from_log(df_log, up_n, dn_n)\n",
    "    ya = np.array([0] * len(ctrl_cols) + [1] * len(treated_cols))\n",
    "    sa = np.array(list(ss[ctrl_cols].values) + list(ss[treated_cols].values))\n",
    "    ar = auc_with_ci(ya, sa, n_boot=min(N_BOOT, 500), seed=SEED + topN)\n",
    "    gr_sens_rows.append({\"topN\": topN, \"n_up\": len(up_n), \"n_dn\": len(dn_n),\n",
    "                         \"auc\": ar[\"auc\"], \"auc_ci_lo\": ar[\"ci_lo\"], \"auc_ci_hi\": ar[\"ci_hi\"]})\n",
    "df_gr_sens = pd.DataFrame(gr_sens_rows)\n",
    "\n",
    "print(f\"\\n=== GR SIGNATURE SUMMARY ===\")\n",
    "print(f\"UP={len(GR_UP)} DN={len(GR_DN)} | AUC={auc_ct:.3f} [{auc_res['ci_lo']:.3f},{auc_res['ci_hi']:.3f}] | d={d_treat_vs_ctrl:.2f} [{d_res['ci_lo']:.2f},{d_res['ci_hi']:.2f}]\")\n",
    "\n",
    "# Main Fig 4A: volcano with key gene labels\n",
    "df_plot = df_de.copy()\n",
    "df_plot[\"-log10(padj)\"] = -np.log10(df_plot[\"padj\"].clip(lower=1e-50))\n",
    "fig, ax = plt.subplots(figsize=(6.0, 5.0))\n",
    "colors = np.array([C_NEU] * len(df_plot), dtype=object)\n",
    "colors[(df_plot[\"padj\"] < 0.05) & (df_plot[\"log2FC\"] > 0.5)] = C_UP\n",
    "colors[(df_plot[\"padj\"] < 0.05) & (df_plot[\"log2FC\"] < -0.5)] = C_DN\n",
    "ax.scatter(df_plot[\"log2FC\"], df_plot[\"-log10(padj)\"], c=colors, s=8, alpha=0.65, linewidths=0)\n",
    "ax.axhline(-np.log10(0.05), color=\"#333333\", linestyle=\"--\", linewidth=0.8, alpha=0.6)\n",
    "ax.axvline(0.5, color=\"#333333\", linestyle=\"--\", linewidth=0.8, alpha=0.6)\n",
    "ax.axvline(-0.5, color=\"#333333\", linestyle=\"--\", linewidth=0.8, alpha=0.6)\n",
    "\n",
    "# Label key GR genes (NEW)\n",
    "label_genes = set(GR_CORE_CURATED) | {\"FKBP5\", \"NR3C1\", \"TSC22D3\", \"DDIT4\", \"KLF9\", \"PER1\", \"GILZ\", \"SGK1\"}\n",
    "for _, row in df_plot.iterrows():\n",
    "    if str(row[\"gene\"]).upper() in {g.upper() for g in label_genes}:\n",
    "        if np.isfinite(row[\"-log10(padj)\"]) and row[\"-log10(padj)\"] > 1:\n",
    "            ax.annotate(row[\"gene\"], (row[\"log2FC\"], row[\"-log10(padj)\"]),\n",
    "                       fontsize=6, fontweight=\"bold\", alpha=0.9,\n",
    "                       xytext=(4, 4), textcoords=\"offset points\")\n",
    "# Also label top 5 by significance\n",
    "for _, row in df_plot.nlargest(5, \"-log10(padj)\").iterrows():\n",
    "    if str(row[\"gene\"]).upper() not in {g.upper() for g in label_genes}:\n",
    "        ax.annotate(row[\"gene\"], (row[\"log2FC\"], row[\"-log10(padj)\"]),\n",
    "                   fontsize=5, alpha=0.7, xytext=(3, 3), textcoords=\"offset points\")\n",
    "\n",
    "ax.set_xlabel(\"log₂ Fold Change (Treated vs Control)\")\n",
    "ax.set_ylabel(\"-log₁₀(padj)\")\n",
    "ax.set_title(f\"Main Fig 4A  GSE219208 perturbation DE (padj<0.05)\")\n",
    "_beautify_axes(ax)\n",
    "save_fig(fig, \"Fig4A\", kind=\"Main\")\n",
    "\n",
    "# Main Fig 4B heatmap (z-scored) \n",
    "hm_genes = (GR_UP[:15] + GR_DN[:15]) if len(GR_DN) else GR_UP[:25]\n",
    "hm_genes = [g for g in hm_genes if g in df_log.index]\n",
    "if len(hm_genes) >= 6:\n",
    "    df_hm = df_log.loc[hm_genes, ctrl_cols + treated_cols].copy()\n",
    "    df_hm = df_hm.sub(df_hm.mean(axis=1), axis=0).div(df_hm.std(axis=1) + 1e-8, axis=0)\n",
    "    fig, ax = plt.subplots(figsize=(8.0, 6.0))\n",
    "    if HAS_SNS:\n",
    "        sns.heatmap(df_hm, ax=ax, cmap=CMAP_HEAT, vmin=-2, vmax=2, linewidths=0.3,\n",
    "                    cbar_kws={\"label\": \"Z-score (log₂CPM)\", \"shrink\": 0.8},\n",
    "                    xticklabels=True, yticklabels=True)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=5)\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), fontsize=6)\n",
    "    else:\n",
    "        im = ax.imshow(df_hm.values, aspect=\"auto\", cmap=CMAP_HEAT, vmin=-2, vmax=2)\n",
    "        ax.set_yticks(range(len(df_hm.index))); ax.set_yticklabels(df_hm.index, fontsize=6)\n",
    "        ax.set_xticks(range(len(df_hm.columns))); ax.set_xticklabels(df_hm.columns, rotation=90, fontsize=5)\n",
    "        plt.colorbar(im, ax=ax, fraction=0.03, pad=0.02, label=\"Z-score\")\n",
    "    ax.set_title(\"Main Fig 4B  Perturbation-derived GR signature\")\n",
    "    save_fig(fig, \"Fig4B\", kind=\"Main\")\n",
    "\n",
    "# Main Fig 4C boxplot with significance annotations\n",
    "fig, ax = plt.subplots(figsize=(6.4, 3.5))\n",
    "order = [\"Control\", \"Treated\", \"Washout\"]\n",
    "data = [df_meta_stress.loc[df_meta_stress[\"group\"] == g, \"GR_score\"].dropna().values for g in order]\n",
    "bp = ax.boxplot(data, labels=order, showfliers=False, patch_artist=True,\n",
    "                boxprops=dict(edgecolor=\"#333333\", linewidth=0.9),\n",
    "                medianprops=dict(color=\"#111111\", linewidth=1.0),\n",
    "                whiskerprops=dict(color=\"#333333\", linewidth=0.9),\n",
    "                capprops=dict(color=\"#333333\", linewidth=0.9))\n",
    "fill_cols = [C_BAR_MAIN, C_BAR_ACC, C_BAR_ACC2]\n",
    "for patch, col in zip(bp[\"boxes\"], fill_cols):\n",
    "    patch.set_facecolor(col); patch.set_alpha(0.35)\n",
    "# Significance annotations (NEW)\n",
    "if len(data[0]) >= 2 and len(data[1]) >= 2:\n",
    "    _, p_ct = stats.mannwhitneyu(data[0], data[1], alternative=\"two-sided\")\n",
    "    s = sig_stars(p_ct)\n",
    "    y_max = max(np.max(data[0]), np.max(data[1]))\n",
    "    ax.plot([1, 2], [y_max + 0.05, y_max + 0.05], color=\"black\", linewidth=0.8)\n",
    "    ax.text(1.5, y_max + 0.06, f\"{s} p={p_ct:.2e}\", ha=\"center\", fontsize=6)\n",
    "if len(data[1]) >= 2 and len(data[2]) >= 2:\n",
    "    _, p_tw = stats.mannwhitneyu(data[1], data[2], alternative=\"two-sided\")\n",
    "    s = sig_stars(p_tw)\n",
    "    y_max2 = max(np.max(data[1]), np.max(data[2])) + 0.15\n",
    "    ax.plot([2, 3], [y_max2, y_max2], color=\"black\", linewidth=0.8)\n",
    "    ax.text(2.5, y_max2 + 0.01, f\"{s} p={p_tw:.2e}\", ha=\"center\", fontsize=6)\n",
    "\n",
    "ax.set_ylabel(\"GR calibration score\")\n",
    "ax.set_title(f\"Main Fig 4C  AUC={auc_ct:.2f} [{auc_res['ci_lo']:.2f},{auc_res['ci_hi']:.2f}]  d={d_treat_vs_ctrl:.2f} [{d_res['ci_lo']:.2f},{d_res['ci_hi']:.2f}]\")\n",
    "_beautify_axes(ax)\n",
    "save_fig(fig, \"Fig4C\", kind=\"Main\")\n",
    "\n",
    "save_excel({\n",
    "    \"Calibration_summary\": pd.DataFrame([{\n",
    "        \"stress_file\": str(stress_csv), \"n_control\": len(ctrl_cols),\n",
    "        \"n_treated\": len(treated_cols), \"n_washout\": len(washout_cols),\n",
    "        \"auc\": auc_ct, \"auc_ci_lo\": auc_res[\"ci_lo\"], \"auc_ci_hi\": auc_res[\"ci_hi\"],\n",
    "        \"cohens_d\": d_treat_vs_ctrl, \"d_ci_lo\": d_res[\"ci_lo\"], \"d_ci_hi\": d_res[\"ci_hi\"],\n",
    "        \"log2fc_threshold\": LOG2FC_T, \"padj_threshold\": PADJ_T,\n",
    "    }]),\n",
    "    \"Drug_breakdown\": df_drug_bd,\n",
    "    \"GR_size_sensitivity\": df_gr_sens,\n",
    "    \"Sample_metadata\": df_meta_stress,\n",
    "    \"GR_UP_signature\": pd.DataFrame({\"rank\": range(1, len(GR_UP) + 1), \"gene\": GR_UP}),\n",
    "    \"GR_DOWN_signature\": pd.DataFrame({\"rank\": range(1, len(GR_DN) + 1), \"gene\": GR_DN}) if len(GR_DN) else pd.DataFrame(),\n",
    "    \"DE_top500\": df_de.sort_values(\"padj\").head(500)\n",
    "}, fname=\"Table3_StressCalibration\", kind=\"Supplementary\")\n",
    "\n",
    "# 8) LOAD MICROGLIA COHORTS\n",
    "micro_adatas = []\n",
    "\n",
    "# SEA-AD\n",
    "seaad_path = RAW_DIR / \"Brain\" / \"SEA-AD (AllenBrainMap)\" / \"SEA-AD_Microglia-and-Immune_multi-regional_final-nuclei_AAIC-pre-release.2025-07-24.h5ad\"\n",
    "assert seaad_path.exists()\n",
    "adata_seaad = ensure_gene_symbols(sc.read_h5ad(seaad_path), \"SEA-AD\")\n",
    "add_common_cols(adata_seaad, \"SEA-AD\", \"microglia\")\n",
    "prep_for_scoring(adata_seaad)\n",
    "ct_cols_s = [c for c in adata_seaad.obs.columns if (\"cell\" in c.lower() and \"type\" in c.lower())]\n",
    "if ct_cols_s:\n",
    "    vals = adata_seaad.obs[ct_cols_s[0]].astype(str).str.lower()\n",
    "    keep = vals.str.contains(\"microglia|myeloid\")\n",
    "    adata_seaad = adata_seaad[keep].copy() if keep.any() else subset_microglia_by_markers(adata_seaad, 2, [\"AIF1\", \"LST1\", \"TYROBP\"])\n",
    "else:\n",
    "    adata_seaad = subset_microglia_by_markers(adata_seaad, 2, [\"AIF1\", \"LST1\", \"TYROBP\"])\n",
    "micro_adatas.append(adata_seaad)\n",
    "print(f\"SEA-AD: {adata_seaad.n_obs:,} cells\")\n",
    "\n",
    "# Olah\n",
    "olah_path = RAW_DIR / \"Brain\" / \"Olah et al. live human microglia (CELLxGENE Census artifact; AnnData).h5ad\"\n",
    "assert olah_path.exists()\n",
    "adata_olah = ensure_gene_symbols(sc.read_h5ad(olah_path), \"Olah\")\n",
    "add_common_cols(adata_olah, \"Olah\", \"microglia\")\n",
    "prep_for_scoring(adata_olah)\n",
    "adata_olah = subset_microglia_by_markers(adata_olah, 2, [\"AIF1\", \"LST1\", \"TYROBP\"])\n",
    "micro_adatas.append(adata_olah)\n",
    "print(f\"Olah: {adata_olah.n_obs:,} cells\")\n",
    "\n",
    "# Tuddenham\n",
    "tud_dir = RAW_DIR / \"Cross-disease living human microglia (Tuddenham  De Jager lab)\"\n",
    "assert tud_dir.exists()\n",
    "h5s = sorted(tud_dir.rglob(\"*.h5\"))[:20]\n",
    "tud_adatas = []\n",
    "for h5 in h5s:\n",
    "    try:\n",
    "        a = sc.read_10x_h5(h5)\n",
    "        a = ensure_gene_symbols(a, \"Tuddenham_GSE204702\")\n",
    "        add_common_cols(a, \"Tuddenham_GSE204702\", \"microglia\")\n",
    "        a.obs[\"sample_id\"] = h5.stem\n",
    "        prep_for_scoring(a)\n",
    "        a = subset_microglia_by_markers(a, 1, [\"AIF1\", \"LST1\", \"TYROBP\"])\n",
    "        if a.n_obs > 0: tud_adatas.append(a)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Tuddenham: {h5.name} ({type(e).__name__})\")\n",
    "if tud_adatas:\n",
    "    adata_tud = ad.concat(tud_adatas, join=\"outer\", merge=\"same\")\n",
    "    micro_adatas.append(adata_tud)\n",
    "    print(f\"Tuddenham: {adata_tud.n_obs:,} cells\")\n",
    "\n",
    "# MS (GSE180759)\n",
    "ms_root = RAW_DIR / \"MS lesion snRNA\" / \"Absinta et al. progressive MS lesion edge snRNA (GEO GSE180759)\"\n",
    "ms_counts = ms_root / \"GSE180759_expression_matrix.csv\"\n",
    "ms_anno = ms_root / \"GSE180759_annotation.txt\"\n",
    "assert ms_counts.exists() and ms_anno.exists()\n",
    "\n",
    "df_ms_anno = pd.read_csv(ms_anno, sep=\"\\t\")\n",
    "def guess_col(cols, contains_any):\n",
    "    for c in cols:\n",
    "        if any(k in c.lower() for k in contains_any): return c\n",
    "    return None\n",
    "bc_col = guess_col(df_ms_anno.columns, [\"nucleus_barcode\", \"barcode\", \"cell_id\", \"cellid\", \"cell\"]) or df_ms_anno.columns[0]\n",
    "df_ms_anno[bc_col] = df_ms_anno[bc_col].astype(str)\n",
    "ct_col = None\n",
    "for key in [\"cell_type\", \"celltype\", \"annotation\", \"class\", \"cell_class\"]:\n",
    "    if key in df_ms_anno.columns: ct_col = key; break\n",
    "if ct_col is None:\n",
    "    low = {c.lower(): c for c in df_ms_anno.columns}\n",
    "    for key in [\"cell_type\", \"celltype\", \"annotation\", \"class\", \"cell_class\"]:\n",
    "        if key in low: ct_col = low[key]; break\n",
    "\n",
    "with ms_counts.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "    header_line = f.readline().strip()\n",
    "hdr = [h.strip() for h in header_line.split(\",\")]\n",
    "def looks_like_barcode(x): return \"-\" in str(x) and len(str(x)) >= 10\n",
    "header_barcodes = hdr[:] if looks_like_barcode(hdr[0]) else hdr[1:]\n",
    "header_set = set(header_barcodes)\n",
    "\n",
    "if ct_col is not None:\n",
    "    ct = df_ms_anno[ct_col].astype(str).str.lower()\n",
    "    keep_bcs_anno = df_ms_anno.loc[ct.str.contains(\"immune|lymphocytes\", regex=True, na=False), bc_col].tolist()\n",
    "    if not keep_bcs_anno: keep_bcs_anno = df_ms_anno[bc_col].astype(str).tolist()\n",
    "else:\n",
    "    keep_bcs_anno = df_ms_anno[bc_col].astype(str).tolist()\n",
    "keep_bcs_anno = list(dict.fromkeys([b for b in keep_bcs_anno if pd.notna(b) and str(b).strip()]))\n",
    "keep_bcs_mapped = [b for b in keep_bcs_anno if b in header_set]\n",
    "\n",
    "MS_MARKERS = [\"P2RY12\", \"CX3CR1\", \"TMEM119\", \"CSF1R\", \"AIF1\", \"TYROBP\", \"LST1\", \"SPI1\", \"FCER1G\"]\n",
    "REQ = set(GR_CORE_CURATED) | set(GR_UP) | set(GR_DN)\n",
    "for v in SIG.values(): REQ |= set(v)\n",
    "for mes in mes_cols: REQ |= set(mes_gene_sets[mes])\n",
    "REQ |= set(EXPR_G) | set(MS_MARKERS)\n",
    "REQ_UP = {g.upper() for g in REQ}\n",
    "\n",
    "def stream_ms_required_to_sparse(ms_counts_path, header_barcodes, selected_barcodes, required_genes_upper, chunksize=2000):\n",
    "    pos = {b: i for i, b in enumerate(header_barcodes)}\n",
    "    sel = [b for b in selected_barcodes if b in pos]\n",
    "    if len(sel) < 200: return None\n",
    "    usecols = [0] + [1 + pos[b] for b in sel]\n",
    "    data = []; rows = []; cols = []; kept_genes = []; row_idx = 0\n",
    "    for chunk in pd.read_csv(ms_counts_path, sep=\",\", header=None, skiprows=1, usecols=usecols,\n",
    "                              chunksize=chunksize, dtype={0: str}, keep_default_na=False):\n",
    "        genes = chunk.iloc[:, 0].astype(str).str.strip().values\n",
    "        X = chunk.iloc[:, 1:].apply(pd.to_numeric, errors=\"coerce\").fillna(0.0).values.astype(np.float32)\n",
    "        sums = X.sum(axis=1)\n",
    "        keep = (sums > 0) | np.isin(np.char.upper(genes.astype(str)), list(required_genes_upper))\n",
    "        if not np.any(keep): continue\n",
    "        gk = genes[keep]; Xk = X[keep]\n",
    "        nzr, nzc = np.nonzero(Xk)\n",
    "        if nzr.size:\n",
    "            data.append(Xk[nzr, nzc]); rows.append(nzr + row_idx); cols.append(nzc)\n",
    "        kept_genes.extend(gk.tolist()); row_idx += Xk.shape[0]\n",
    "    if row_idx == 0: return None\n",
    "    data = np.concatenate(data) if data else np.array([], dtype=np.float32)\n",
    "    rows = np.concatenate(rows) if rows else np.array([], dtype=np.int64)\n",
    "    cols = np.concatenate(cols) if cols else np.array([], dtype=np.int64)\n",
    "    return kept_genes, sel, sp.coo_matrix((data, (rows, cols)), shape=(row_idx, len(sel))).tocsr()\n",
    "\n",
    "selected_bcs = keep_bcs_mapped if len(keep_bcs_mapped) >= 200 else header_barcodes[:20000]\n",
    "res = stream_ms_required_to_sparse(ms_counts, header_barcodes, selected_bcs, REQ_UP, 2000)\n",
    "assert res is not None\n",
    "genes_kept, sel_bcs, X_gxC = res\n",
    "\n",
    "adata_ms = ad.AnnData(X=X_gxC.T.tocsr(), obs=pd.DataFrame(index=pd.Index(sel_bcs).astype(str)),\n",
    "                       var=pd.DataFrame(index=pd.Index(genes_kept).astype(str)))\n",
    "adata_ms.var_names_make_unique()\n",
    "adata_ms = ensure_gene_symbols(adata_ms, \"MS_GSE180759\")\n",
    "add_common_cols(adata_ms, \"MS_GSE180759\", \"microglia\")\n",
    "prep_for_scoring(adata_ms)\n",
    "adata_ms = subset_microglia_by_markers(adata_ms, 1, [\"AIF1\", \"LST1\", \"TYROBP\", \"FCER1G\"])\n",
    "assert adata_ms.n_obs > 500\n",
    "micro_adatas.append(adata_ms)\n",
    "print(f\"MS: {adata_ms.n_obs:,} cells\")\n",
    "\n",
    "# 9) SCORE COHORTS\n",
    "MAX_CELL_STATS = 50_000\n",
    "\n",
    "all_results = []\n",
    "qc_rows = []\n",
    "expr_rows = []\n",
    "stress_interaction_rows = []\n",
    "hk_sens_rows = []\n",
    "lgals3_rows = []\n",
    "fndc5_rows = []\n",
    "\n",
    "for a in micro_adatas:\n",
    "    ds = str(a.obs[\"dataset\"].iloc[0])\n",
    "    print(f\"\\n--- Scoring: {ds} ---\")\n",
    "    prep_for_scoring(a); compute_basic_qc(a)\n",
    "\n",
    "    score_geneset(a, SIG[\"microglia_homeostatic\"], \"score_homeostatic\")\n",
    "    score_geneset(a, SIG[\"microglia_activation\"], \"score_activation\")\n",
    "    score_geneset(a, SIG[\"oxphos\"], \"score_oxphos\")\n",
    "    score_geneset(a, SIG[\"glycolysis\"], \"score_glycolysis\")\n",
    "    a.obs[\"tolerance_positioning\"] = a.obs[\"score_homeostatic\"] - a.obs[\"score_activation\"]\n",
    "\n",
    "    for mes, genes in mes_gene_sets.items():\n",
    "        score_geneset(a, genes, f\"{mes}_score\")\n",
    "    for mes, genes in mes_gene_sets_hk_stripped.items():\n",
    "        score_geneset(a, genes, f\"{mes}_score_hkstrip\", min_genes=3)\n",
    "\n",
    "    score_geneset(a, GR_UP, \"GR_UP\", min_genes=3)\n",
    "    score_geneset(a, GR_DN, \"GR_DN\", min_genes=3)\n",
    "    upv = a.obs[\"GR_UP\"].values; dnv = a.obs[\"GR_DN\"].values\n",
    "    if np.isfinite(upv).sum() > 100 and np.isfinite(dnv).sum() > 100:\n",
    "        a.obs[\"GR_composite\"] = upv - dnv\n",
    "    elif np.isfinite(upv).sum() > 100:\n",
    "        a.obs[\"GR_composite\"] = upv\n",
    "    else:\n",
    "        score_geneset(a, GR_CORE_CURATED, \"GR_composite\", min_genes=2)\n",
    "\n",
    "    v = a.obs[\"GR_composite\"].values; vfin = v[np.isfinite(v)]\n",
    "    if vfin.size >= 200:\n",
    "        a.obs[\"stress_high\"] = (a.obs[\"GR_composite\"] >= float(np.median(vfin))).astype(int)\n",
    "    else:\n",
    "        a.obs[\"stress_high\"] = np.nan\n",
    "\n",
    "    for g in EXPR_G:\n",
    "        present = _genes_present_case_insensitive(a, [g])\n",
    "        if present:\n",
    "            x = a[:, present[0]].X\n",
    "            if sp.issparse(x): x = x.toarray()\n",
    "            a.obs[f\"expr_{g}\"] = np.asarray(x).reshape(-1)\n",
    "        else:\n",
    "            a.obs[f\"expr_{g}\"] = np.nan\n",
    "\n",
    "    conf_cols = summarize_dataset_confounds(a)\n",
    "    donor_col = pick_donor_col(a.obs)\n",
    "\n",
    "    qc_rows.append({\"dataset\": ds, \"n_cells\": int(a.n_obs), \"n_genes\": int(a.n_vars),\n",
    "                     \"donor_col\": donor_col or \"(none)\",\n",
    "                     \"confounds\": \", \".join(conf_cols) if conf_cols else \"(none)\"})\n",
    "\n",
    "    df_obs = a.obs.copy()\n",
    "    needed_cols = list(dict.fromkeys(\n",
    "        conf_cols + [\"tolerance_positioning\", \"GR_composite\", \"stress_high\"] +\n",
    "        [f\"{m}_score\" for m in mes_cols] + [f\"{m}_score_hkstrip\" for m in mes_cols] +\n",
    "        [f\"expr_{g}\" for g in EXPR_G]))\n",
    "\n",
    "    if donor_col and donor_col in df_obs.columns:\n",
    "        df_unit = donor_aggregate(df_obs, donor_col, needed_cols)\n",
    "        level = \"donor\"; sample_note = \"donor\"\n",
    "    else:\n",
    "        df_unit = df_obs[needed_cols].copy()\n",
    "        level = \"cell\"; sample_note = \"cell-full\"\n",
    "        if df_unit.shape[0] > MAX_CELL_STATS:\n",
    "            idx = np.random.default_rng(SEED).choice(df_unit.index.values, size=MAX_CELL_STATS, replace=False)\n",
    "            df_unit = df_unit.loc[idx].copy()\n",
    "            sample_note = f\"cell-sub={MAX_CELL_STATS}\"\n",
    "\n",
    "    X_conf = build_confound_matrix(df_unit, conf_cols)\n",
    "    y = df_unit[\"tolerance_positioning\"].values\n",
    "    y_adj = residualize(y, X_conf) if X_conf is not None else y\n",
    "\n",
    "    for mes in mes_cols:\n",
    "        x = df_unit.get(f\"{mes}_score\", pd.Series(np.nan, index=df_unit.index)).values\n",
    "        x_adj = residualize(x, X_conf) if X_conf is not None else x\n",
    "        s_adj = corr_with_ci_p(x_adj, y_adj, n_boot=N_BOOT, n_perm=N_PERM, seed=SEED + 7)\n",
    "\n",
    "        x2 = df_unit.get(f\"{mes}_score_hkstrip\", pd.Series(np.nan, index=df_unit.index)).values\n",
    "        x2_adj = residualize(x2, X_conf) if X_conf is not None else x2\n",
    "        s2_adj = corr_with_ci_p(x2_adj, y_adj, n_boot=min(N_BOOT, 500), n_perm=min(N_PERM, 500), seed=SEED + 17)\n",
    "\n",
    "        all_results.append({\n",
    "            \"dataset\": ds, \"level\": level, \"N\": int(s_adj[\"n\"]), \"sample_note\": sample_note,\n",
    "            \"MES\": mes,\n",
    "            \"r_adj\": s_adj[\"r\"], \"ci_adj_low\": s_adj[\"ci_low\"], \"ci_adj_high\": s_adj[\"ci_high\"],\n",
    "            \"p_adj_perm\": s_adj[\"p_perm\"],\n",
    "            \"confounds\": \", \".join(conf_cols) if conf_cols else \"(none)\"})\n",
    "        hk_sens_rows.append({\n",
    "            \"dataset\": ds, \"level\": level, \"N\": int(s_adj[\"n\"]), \"MES\": mes,\n",
    "            \"r_adj_original\": s_adj[\"r\"], \"r_adj_hkstrip\": s2_adj[\"r\"],\n",
    "            \"delta\": (s2_adj[\"r\"] - s_adj[\"r\"]) if (np.isfinite(s2_adj[\"r\"]) and np.isfinite(s_adj[\"r\"])) else np.nan})\n",
    "\n",
    "    for gname, rows_store in [(\"LGALS3\", lgals3_rows), (\"FNDC5\", fndc5_rows)]:\n",
    "        if f\"expr_{gname}\" in df_unit.columns:\n",
    "            x = df_unit[f\"expr_{gname}\"].values\n",
    "            x_adj = residualize(x, X_conf) if X_conf is not None else x\n",
    "            s = corr_with_ci_p(x_adj, y_adj, n_boot=N_BOOT, n_perm=N_PERM, seed=SEED + 123)\n",
    "            rows_store.append({\"dataset\": ds, \"level\": level, \"N\": int(s[\"n\"]),\n",
    "                               \"r_adj\": s[\"r\"], \"ci_low\": s[\"ci_low\"], \"ci_high\": s[\"ci_high\"],\n",
    "                               \"p_perm\": s[\"p_perm\"]})\n",
    "\n",
    "    expr_rows.append({\n",
    "        \"dataset\": ds, \"level\": level, \"N\": int(df_unit.shape[0]),\n",
    "        \"corr_LGALS3_vs_tolerance\": safe_corr(df_unit.get(\"expr_LGALS3\", np.nan), y),\n",
    "        \"corr_FNDC5_vs_tolerance\": safe_corr(df_unit.get(\"expr_FNDC5\", np.nan), y),\n",
    "        \"sample_note\": sample_note})\n",
    "\n",
    "    if \"stress_high\" in df_unit.columns and np.isfinite(df_unit[\"stress_high\"].values).sum() >= 30:\n",
    "        suball = df_unit[np.isfinite(df_unit[\"stress_high\"].values)].copy()\n",
    "\n",
    "        def mean_mes_corr(df_sub):\n",
    "            yy = df_sub[\"tolerance_positioning\"].values\n",
    "            Xc = build_confound_matrix(df_sub, conf_cols)\n",
    "            yy_adj = residualize(yy, Xc) if Xc is not None else yy\n",
    "            rs = []\n",
    "            for mes in mes_cols:\n",
    "                xx = df_sub.get(f\"{mes}_score\", pd.Series(np.nan, index=df_sub.index)).values\n",
    "                xx_adj = residualize(xx, Xc) if Xc is not None else xx\n",
    "                rs.append(safe_corr(xx_adj, yy_adj))\n",
    "            return float(np.nanmean(rs))\n",
    "\n",
    "        low = suball[suball[\"stress_high\"] == 0]\n",
    "        high = suball[suball[\"stress_high\"] == 1]\n",
    "        obs_low = mean_mes_corr(low) if low.shape[0] >= 10 else np.nan\n",
    "        obs_high = mean_mes_corr(high) if high.shape[0] >= 10 else np.nan\n",
    "        obs_diff = (obs_high - obs_low) if (np.isfinite(obs_high) and np.isfinite(obs_low)) else np.nan\n",
    "\n",
    "        p_diff = np.nan\n",
    "        if low.shape[0] >= 10 and high.shape[0] >= 10:\n",
    "            rng = np.random.default_rng(SEED + 99)\n",
    "            labels = suball[\"stress_high\"].values.astype(int)\n",
    "            diffs = []\n",
    "            for _ in range(N_PERM):\n",
    "                lp = rng.permutation(labels)\n",
    "                tmp = suball.copy(); tmp[\"stress_high_perm\"] = lp\n",
    "                lo = tmp[tmp[\"stress_high_perm\"] == 0]; hi = tmp[tmp[\"stress_high_perm\"] == 1]\n",
    "                if lo.shape[0] < 10 or hi.shape[0] < 10: continue\n",
    "                diffs.append(mean_mes_corr(hi) - mean_mes_corr(lo))\n",
    "            diffs = np.asarray(diffs, float)\n",
    "            if diffs.size:\n",
    "                p_diff = float((np.sum(np.abs(diffs) >= abs(obs_diff)) + 1) / (diffs.size + 1))\n",
    "\n",
    "        stress_interaction_rows.append({\n",
    "            \"dataset\": ds, \"level\": level, \"N\": int(suball.shape[0]),\n",
    "            \"mean_r_low_stress\": obs_low, \"mean_r_high_stress\": obs_high,\n",
    "            \"diff_high_minus_low\": obs_diff, \"p_perm\": p_diff,\n",
    "            \"sample_note\": sample_note})\n",
    "\n",
    "df_res = pd.DataFrame(all_results)\n",
    "df_qc = pd.DataFrame(qc_rows)\n",
    "df_expr = pd.DataFrame(expr_rows)\n",
    "df_hk_sens = pd.DataFrame(hk_sens_rows)\n",
    "df_stress = pd.DataFrame(stress_interaction_rows)\n",
    "\n",
    "# Global BH-FDR across ALL correlation tests\n",
    "if len(df_res) and \"p_adj_perm\" in df_res.columns:\n",
    "    df_res[\"q_global_BH\"] = bh_fdr(df_res[\"p_adj_perm\"].values)\n",
    "    df_res[\"q_dataset_BH\"] = df_res.groupby(\"dataset\")[\"p_adj_perm\"].transform(bh_fdr)\n",
    "\n",
    "save_excel({\n",
    "    \"MES_vs_Tolerance_main\": df_res.sort_values([\"dataset\", \"MES\"]),\n",
    "    \"Dataset_QC\": df_qc,\n",
    "    \"Expression_checks\": df_expr\n",
    "}, fname=\"Table2\", kind=\"Main\")\n",
    "\n",
    "sig_def = [{\"signature\": k, \"genes\": \", \".join(v)} for k, v in SIG.items()]\n",
    "sig_def += [\n",
    "    {\"signature\": \"GR_UP derived\", \"genes\": \", \".join(GR_UP[:25]) + (\"...\" if len(GR_UP) > 25 else \"\")},\n",
    "    {\"signature\": \"GR_DOWN derived\", \"genes\": \", \".join(GR_DN[:25]) + (\"...\" if len(GR_DN) > 25 else \"\")},\n",
    "    {\"signature\": \"GR_CORE curated\", \"genes\": \", \".join(GR_CORE_CURATED)}]\n",
    "sig_def += [{\"signature\": mes, \"genes\": \", \".join(mes_gene_sets[mes][:25]) + \"...\"} for mes in mes_cols]\n",
    "\n",
    "save_excel({\n",
    "    \"Signature_Definitions\": pd.DataFrame(sig_def),\n",
    "    \"MES_vs_Tolerance_full\": df_res.sort_values([\"dataset\", \"level\", \"MES\"])\n",
    "}, fname=\"Table4\", kind=\"Supplementary\")\n",
    "\n",
    "save_excel({\"Stress_interaction\": df_stress}, fname=\"Table6\", kind=\"Supplementary\")\n",
    "save_excel({\"HK_load_by_module\": df_hk, \"HK_strip_sensitivity\": df_hk_sens}, fname=\"Table9_HK_Sensitivity\", kind=\"Supplementary\")\n",
    "\n",
    "# FIGURES 2A-2D \n",
    "MAX_EMB_TOTAL = 120000\n",
    "rng = np.random.default_rng(SEED)\n",
    "micro_for_emb = []\n",
    "for a in micro_adatas:\n",
    "    take = min(a.n_obs, max(8000, int(MAX_EMB_TOTAL / max(len(micro_adatas), 1))))\n",
    "    idx = rng.choice(a.n_obs, size=take, replace=False) if a.n_obs > take else np.arange(a.n_obs)\n",
    "    micro_for_emb.append(a[idx].copy())\n",
    "micro = ad.concat(micro_for_emb, join=\"outer\", merge=\"same\")\n",
    "micro = sanitize_for_write(micro)\n",
    "ensure_counts_layer(micro)\n",
    "micro.X = micro.layers[\"counts\"].copy()\n",
    "if not looks_log1p(micro):\n",
    "    sc.pp.normalize_total(micro, target_sum=1e4); sc.pp.log1p(micro)\n",
    "sc.pp.highly_variable_genes(micro, n_top_genes=2000, flavor=\"seurat_v3\")\n",
    "micro2 = micro[:, micro.var_names[micro.var[\"highly_variable\"]]].copy()\n",
    "sc.tl.pca(micro2, n_comps=50, svd_solver=\"arpack\")\n",
    "sc.pp.neighbors(micro2, n_neighbors=15, n_pcs=30)\n",
    "sc.tl.umap(micro2)\n",
    "\n",
    "# Main Fig 2A\n",
    "fig, ax = plt.subplots(figsize=(6.6, 5.2))\n",
    "xy = micro2.obsm[\"X_umap\"]\n",
    "val = micro2.obs.get(\"tolerance_positioning\", pd.Series(np.nan, index=micro2.obs_names)).values\n",
    "sca = ax.scatter(xy[:, 0], xy[:, 1], c=val, s=2, alpha=0.75, linewidths=0, cmap=CMAP_CONT)\n",
    "ax.set_xlabel(\"UMAP1\"); ax.set_ylabel(\"UMAP2\")\n",
    "ax.set_title(\"Main Fig 2A  Microglia tolerance positioning\")\n",
    "_beautify_axes(ax)\n",
    "plt.colorbar(sca, ax=ax, fraction=0.03, pad=0.02, label=\"Homeostatic − Activation\")\n",
    "save_fig(fig, \"Fig2A\", kind=\"Main\")\n",
    "\n",
    "# Main Fig 2B: bar + error bars (CI range)\n",
    "mat_adj = df_res.pivot_table(index=\"dataset\", columns=\"MES\", values=\"r_adj\")\n",
    "mat_ci_lo = df_res.pivot_table(index=\"dataset\", columns=\"MES\", values=\"ci_adj_low\")\n",
    "mat_ci_hi = df_res.pivot_table(index=\"dataset\", columns=\"MES\", values=\"ci_adj_high\")\n",
    "df_bar = pd.DataFrame({\n",
    "    \"dataset\": mat_adj.index,\n",
    "    \"mean_r_adj\": np.nanmean(mat_adj.values, axis=1),\n",
    "    \"mean_ci_lo\": np.nanmean(mat_ci_lo.values, axis=1),\n",
    "    \"mean_ci_hi\": np.nanmean(mat_ci_hi.values, axis=1)\n",
    "}).sort_values(\"mean_r_adj\", ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.6, 3.4))\n",
    "yerr_lo = df_bar[\"mean_r_adj\"] - df_bar[\"mean_ci_lo\"]\n",
    "yerr_hi = df_bar[\"mean_ci_hi\"] - df_bar[\"mean_r_adj\"]\n",
    "ax.bar(df_bar[\"dataset\"], df_bar[\"mean_r_adj\"], color=C_BAR_MAIN,\n",
    "       yerr=[yerr_lo.values, yerr_hi.values], capsize=3, error_kw={\"linewidth\": 0.8})\n",
    "ax.set_ylabel(\"Mean adjusted ρ (95% CI)\")\n",
    "ax.set_title(\"Main Fig 2B  Average MES–tolerance correlation (adjusted)\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "_beautify_axes(ax)\n",
    "save_fig(fig, \"Fig2B\", kind=\"Main\")\n",
    "\n",
    "# Main Fig 2C: annotated seaborn heatmap\n",
    "fig, ax = plt.subplots(figsize=(8.5, 3.5))\n",
    "if HAS_SNS:\n",
    "    # Build significance matrix\n",
    "    mat_q = df_res.pivot_table(index=\"dataset\", columns=\"MES\", values=\"q_global_BH\") if \"q_global_BH\" in df_res.columns else None\n",
    "    annot_text = mat_adj.copy()\n",
    "    for ds in mat_adj.index:\n",
    "        for mes in mat_adj.columns:\n",
    "            r_val = mat_adj.loc[ds, mes]\n",
    "            q_val = mat_q.loc[ds, mes] if mat_q is not None and ds in mat_q.index and mes in mat_q.columns else np.nan\n",
    "            s = sig_stars(q_val)\n",
    "            annot_text.loc[ds, mes] = f\"{r_val:.2f}\\n{s}\" if np.isfinite(r_val) else \"\"\n",
    "\n",
    "    sns.heatmap(mat_adj, ax=ax, cmap=CMAP_DIV, vmin=-0.5, vmax=0.5, linewidths=0.5,\n",
    "                linecolor=\"white\", annot=annot_text, fmt=\"\", annot_kws={\"fontsize\": 6},\n",
    "                cbar_kws={\"label\": \"Adjusted ρ\", \"shrink\": 0.8})\n",
    "else:\n",
    "    im = ax.imshow(mat_adj.values, aspect=\"auto\", vmin=-0.5, vmax=0.5, cmap=CMAP_DIV)\n",
    "    ax.set_yticks(range(mat_adj.shape[0])); ax.set_yticklabels(mat_adj.index)\n",
    "    ax.set_xticks(range(mat_adj.shape[1])); ax.set_xticklabels(mat_adj.columns, rotation=90)\n",
    "    plt.colorbar(im, ax=ax, fraction=0.03, pad=0.02, label=\"Adjusted ρ\")\n",
    "ax.set_title(\"Main Fig 2C  MES–tolerance correlations (covariate-adjusted, FDR-annotated)\")\n",
    "save_fig(fig, \"Fig2C\", kind=\"Main\")\n",
    "\n",
    "# Main Fig 2D: LGALS3 with CIs\n",
    "df_lg = pd.DataFrame(lgals3_rows).dropna(subset=[\"r_adj\"])\n",
    "fig, ax = plt.subplots(figsize=(6.6, 3.2))\n",
    "if len(df_lg):\n",
    "    yerr_lo = df_lg[\"r_adj\"] - df_lg[\"ci_low\"]\n",
    "    yerr_hi = df_lg[\"ci_high\"] - df_lg[\"r_adj\"]\n",
    "    ax.bar(df_lg[\"dataset\"], df_lg[\"r_adj\"], color=C_BAR_ACC2,\n",
    "           yerr=[yerr_lo.values, yerr_hi.values], capsize=3, error_kw={\"linewidth\": 0.8},\n",
    "           edgecolor=\"black\", linewidth=0.3)\n",
    "    for i, (_, row) in enumerate(df_lg.iterrows()):\n",
    "        s = sig_stars(row.get(\"p_perm\"))\n",
    "        if s != \"ns\":\n",
    "            ax.text(i, row[\"ci_high\"] + 0.01, s, ha=\"center\", fontsize=7, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Adjusted ρ (95% CI)\")\n",
    "ax.set_title(\"Main Fig 2D  LGALS3 vs tolerance (adjusted)\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "_beautify_axes(ax)\n",
    "save_fig(fig, \"Fig2D\", kind=\"Main\")\n",
    "\n",
    "# Supp Fig 2E: FNDC5 with CIs\n",
    "df_fn = pd.DataFrame(fndc5_rows).dropna(subset=[\"r_adj\"])\n",
    "if len(df_fn):\n",
    "    fig, ax = plt.subplots(figsize=(6.6, 3.2))\n",
    "    yerr_lo = df_fn[\"r_adj\"] - df_fn[\"ci_low\"]\n",
    "    yerr_hi = df_fn[\"ci_high\"] - df_fn[\"r_adj\"]\n",
    "    ax.bar(df_fn[\"dataset\"], df_fn[\"r_adj\"], color=C_BAR_ACC,\n",
    "           yerr=[yerr_lo.values, yerr_hi.values], capsize=3, error_kw={\"linewidth\": 0.8},\n",
    "           edgecolor=\"black\", linewidth=0.3)\n",
    "    for i, (_, row) in enumerate(df_fn.iterrows()):\n",
    "        s = sig_stars(row.get(\"p_perm\"))\n",
    "        if s != \"ns\":\n",
    "            ax.text(i, row[\"ci_high\"] + 0.01, s, ha=\"center\", fontsize=7, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Adjusted ρ (95% CI)\")\n",
    "    ax.set_title(\"Supplementary Fig 2E  FNDC5 vs tolerance (exploratory)\")\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "    _beautify_axes(ax)\n",
    "    save_fig(fig, \"Fig2E_FNDC5\", kind=\"Supplementary\")\n",
    "\n",
    "# Supp Fig 2G: HK robustness\n",
    "fig, ax = plt.subplots(figsize=(7.2, 3.0))\n",
    "tmp = df_hk_sens.copy(); tmp[\"abs_delta\"] = tmp[\"delta\"].abs()\n",
    "summ = tmp.groupby(\"dataset\")[\"abs_delta\"].agg([\"mean\", \"std\"]).sort_values(\"mean\", ascending=False)\n",
    "ax.bar(summ.index, summ[\"mean\"], color=C_BAR_MAIN, yerr=summ[\"std\"], capsize=3,\n",
    "       error_kw={\"linewidth\": 0.8}, edgecolor=\"black\", linewidth=0.3)\n",
    "ax.set_ylabel(\"Mean |Δρ| ± SD\")\n",
    "ax.set_title(\"Supplementary Fig 2G  MES robustness to housekeeping removal\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "_beautify_axes(ax)\n",
    "save_fig(fig, \"Fig2G_HK_Robustness\", kind=\"Supplementary\")\n",
    "\n",
    "\n",
    "# 10) SPATIAL VALIDATION\n",
    "vis_hits = list(RAW_DIR.rglob(\"GSE220442\"))\n",
    "assert len(vis_hits) >= 1\n",
    "vis_root = None\n",
    "for p in vis_hits:\n",
    "    cand = p / \"counts_and_images\"\n",
    "    if cand.exists(): vis_root = cand; break\n",
    "assert vis_root is not None\n",
    "\n",
    "samples = sorted([d for d in vis_root.iterdir() if d.is_dir()])\n",
    "rep_sample = samples[0].name if samples else None\n",
    "\n",
    "spatial_rows = []\n",
    "for sdir in samples:\n",
    "    h5 = sdir / \"filtered_feature_bc_matrix.h5\"\n",
    "    if not h5.exists(): continue\n",
    "    a = sc.read_10x_h5(h5)\n",
    "    a = ensure_gene_symbols(a, f\"Visium_{sdir.name}\")\n",
    "    a.var_names_make_unique()\n",
    "    a.layers[\"counts\"] = a.X.copy()\n",
    "    sc.pp.normalize_total(a, target_sum=1e4); sc.pp.log1p(a)\n",
    "\n",
    "    score_geneset(a, SIG[\"microglia_homeostatic\"], \"score_homeostatic\")\n",
    "    score_geneset(a, SIG[\"microglia_activation\"], \"score_activation\")\n",
    "    a.obs[\"tolerance_positioning\"] = a.obs[\"score_homeostatic\"] - a.obs[\"score_activation\"]\n",
    "    for mes, genes in mes_gene_sets.items():\n",
    "        score_geneset(a, genes, f\"{mes}_score\")\n",
    "\n",
    "    # ALL 8 MES correlations per sample\n",
    "    for mes in mes_cols:\n",
    "        st = corr_with_ci_p(a.obs[f\"{mes}_score\"].values, a.obs[\"tolerance_positioning\"].values,\n",
    "                            n_boot=min(N_BOOT, 500), n_perm=min(N_PERM, 500), seed=SEED + 77)\n",
    "        spatial_rows.append({\n",
    "            \"dataset\": \"GSE220442\", \"sample_id\": sdir.name, \"MES\": mes,\n",
    "            \"n_spots\": int(st[\"n\"]), \"r\": float(st[\"r\"]),\n",
    "            \"ci_low\": float(st[\"ci_low\"]), \"ci_high\": float(st[\"ci_high\"]),\n",
    "            \"p_perm\": float(st[\"p_perm\"])})\n",
    "\n",
    "    if sdir.name == rep_sample:\n",
    "        fig, ax = plt.subplots(figsize=(6.0, 3.2))\n",
    "        vv = a.obs[\"tolerance_positioning\"].values\n",
    "        vv = vv[np.isfinite(vv)]\n",
    "        ax.hist(vv, bins=50, color=C_BAR_MAIN, alpha=0.85, edgecolor=\"black\", linewidth=0.3)\n",
    "        ax.set_title(f\"Main Fig 3A  {sdir.name} tolerance distribution (n={len(vv)})\")\n",
    "        ax.set_xlabel(\"Tolerance positioning\"); ax.set_ylabel(\"Spots\")\n",
    "        _beautify_axes(ax)\n",
    "        save_fig(fig, \"Fig3A\", kind=\"Main\")\n",
    "\n",
    "df_spatial = pd.DataFrame(spatial_rows)\n",
    "if len(df_spatial):\n",
    "    df_spatial[\"q_BH\"] = bh_fdr(df_spatial[\"p_perm\"].values)\n",
    "\n",
    "# Main Fig 3B: heatmap per sample × MES\n",
    "if len(df_spatial):\n",
    "    fig, ax = plt.subplots(figsize=(8, max(3, 0.4 * df_spatial[\"sample_id\"].nunique())))\n",
    "    piv = df_spatial.pivot_table(index=\"sample_id\", columns=\"MES\", values=\"r\", aggfunc=\"mean\")\n",
    "    ordered = [f\"MES0{i}\" for i in range(1, 9)]\n",
    "    cols = [c for c in ordered if c in piv.columns]\n",
    "    piv = piv[cols]\n",
    "\n",
    "    if HAS_SNS:\n",
    "        piv_q = df_spatial.pivot_table(index=\"sample_id\", columns=\"MES\", values=\"q_BH\", aggfunc=\"mean\")\n",
    "        annot = piv.copy()\n",
    "        for ds in piv.index:\n",
    "            for mes in piv.columns:\n",
    "                r = piv.loc[ds, mes]\n",
    "                q = piv_q.loc[ds, mes] if ds in piv_q.index and mes in piv_q.columns else np.nan\n",
    "                annot.loc[ds, mes] = f\"{r:.2f}{sig_stars(q)}\" if np.isfinite(r) else \"\"\n",
    "        sns.heatmap(piv, ax=ax, cmap=CMAP_DIV, vmin=-0.5, vmax=0.5, linewidths=0.5,\n",
    "                    annot=annot, fmt=\"\", annot_kws={\"fontsize\": 5},\n",
    "                    cbar_kws={\"label\": \"ρ\", \"shrink\": 0.8})\n",
    "    else:\n",
    "        im = ax.imshow(piv.values, aspect=\"auto\", cmap=CMAP_DIV, vmin=-0.5, vmax=0.5)\n",
    "        ax.set_xticks(range(piv.shape[1])); ax.set_xticklabels(piv.columns, rotation=45)\n",
    "        ax.set_yticks(range(piv.shape[0])); ax.set_yticklabels(piv.index)\n",
    "        plt.colorbar(im, ax=ax, label=\"ρ\", shrink=0.8)\n",
    "    ax.set_title(\"Main Fig 3B  Visium spatial: all MES × sample (FDR-annotated)\")\n",
    "    save_fig(fig, \"Fig3B\", kind=\"Main\")\n",
    "\n",
    "# 11) CROSS-MODAL GSE233208\n",
    "def load_mtx_export(mtx_dir, label):\n",
    "    mtx = mtx_dir / \"counts.mtx\"; feats = mtx_dir / \"features.tsv.gz\"\n",
    "    bcs = mtx_dir / \"barcodes.tsv.gz\"; meta = mtx_dir / \"meta.csv.gz\"\n",
    "    if not all(p.exists() for p in [mtx, feats, bcs, meta]):\n",
    "        raise FileNotFoundError(f\"{label} missing files\")\n",
    "    X = scipy.io.mmread(str(mtx)).tocsr()\n",
    "    feats_df = pd.read_csv(feats, sep=\"\\t\", header=None, compression=\"gzip\")\n",
    "    bcs_df = pd.read_csv(bcs, sep=\"\\t\", header=None, compression=\"gzip\")\n",
    "    meta_df = pd.read_csv(meta, compression=\"gzip\", index_col=0).reindex(bcs_df[0].astype(str).values)\n",
    "    adata = ad.AnnData(X=X.T.tocsr(), obs=meta_df.copy(),\n",
    "                        var=pd.DataFrame(index=feats_df[1].astype(str).values if feats_df.shape[1] > 1 else feats_df[0].astype(str).values))\n",
    "    adata.obs_names = bcs_df[0].astype(str).values; adata.var_names_make_unique()\n",
    "    return adata\n",
    "\n",
    "crossmodal_ran = False; df_concord = pd.DataFrame(); pair_key_used = \"(not run)\"\n",
    "try:\n",
    "    if all((GSE233208_VIS_MTX / \"counts.mtx\").exists() for _ in [1]) and (GSE233208_SN_MTX / \"counts.mtx\").exists():\n",
    "        ad_vis = load_mtx_export(GSE233208_VIS_MTX, \"GSE233208_visium\")\n",
    "        ad_sn = load_mtx_export(GSE233208_SN_MTX, \"GSE233208_snrna\")\n",
    "        crossmodal_ran = True\n",
    "        ad_vis = ensure_gene_symbols(ad_vis, \"GSE233208_Visium\")\n",
    "        ensure_counts_layer(ad_vis); ad_vis.X = ad_vis.layers[\"counts\"].copy()\n",
    "        if not looks_log1p(ad_vis): sc.pp.normalize_total(ad_vis, target_sum=1e4); sc.pp.log1p(ad_vis)\n",
    "        score_geneset(ad_vis, SIG[\"microglia_homeostatic\"], \"score_homeostatic\", 3)\n",
    "        score_geneset(ad_vis, SIG[\"microglia_activation\"], \"score_activation\", 3)\n",
    "        ad_vis.obs[\"tolerance_positioning\"] = ad_vis.obs[\"score_homeostatic\"] - ad_vis.obs[\"score_activation\"]\n",
    "        for mes, genes in mes_gene_sets.items(): score_geneset(ad_vis, genes, f\"{mes}_score\", 3)\n",
    "        v = ad_vis.obs[\"score_homeostatic\"].values\n",
    "        thr = np.nanquantile(v[np.isfinite(v)], 0.70) if np.isfinite(v).sum() > 50 else np.nan\n",
    "        ad_vis.obs[\"microglia_enriched_spot\"] = (ad_vis.obs[\"score_homeostatic\"] >= thr).astype(int) if np.isfinite(thr) else 1\n",
    "        ad_sn = ensure_gene_symbols(ad_sn, \"GSE233208_snRNA\"); prep_for_scoring(ad_sn)\n",
    "        ct_c = [c for c in ad_sn.obs.columns if (\"cell\" in c.lower() and \"type\" in c.lower()) or \"annotation\" in c.lower()]\n",
    "        if ct_c:\n",
    "            vals = ad_sn.obs[ct_c[0]].astype(str).str.lower()\n",
    "            keep = vals.str.contains(\"microglia|myeloid\")\n",
    "            ad_sn = ad_sn[keep].copy() if keep.any() else subset_microglia_by_markers(ad_sn, 2, [\"AIF1\",\"LST1\",\"TYROBP\"])\n",
    "        else:\n",
    "            ad_sn = subset_microglia_by_markers(ad_sn, 2, [\"AIF1\",\"LST1\",\"TYROBP\"])\n",
    "        prep_for_scoring(ad_sn)\n",
    "        score_geneset(ad_sn, SIG[\"microglia_homeostatic\"], \"score_homeostatic\", 3)\n",
    "        score_geneset(ad_sn, SIG[\"microglia_activation\"], \"score_activation\", 3)\n",
    "        ad_sn.obs[\"tolerance_positioning\"] = ad_sn.obs[\"score_homeostatic\"] - ad_sn.obs[\"score_activation\"]\n",
    "        for mes, genes in mes_gene_sets.items(): score_geneset(ad_sn, genes, f\"{mes}_score\", 3)\n",
    "\n",
    "        def find_pair_key(dfA, dfB):\n",
    "            for k in [\"sample_id\",\"sample\",\"donor_id\",\"donor\",\"subject\",\"patient\",\"case_id\",\"region\",\"library_id\",\"orig.ident\"]:\n",
    "                if k in dfA.columns and k in dfB.columns: return k\n",
    "            return None\n",
    "        pair_key = find_pair_key(ad_vis.obs, ad_sn.obs) or \"__global__\"\n",
    "        if pair_key == \"__global__\": ad_vis.obs[pair_key] = \"all\"; ad_sn.obs[pair_key] = \"all\"\n",
    "        pair_key_used = pair_key\n",
    "        cols_scores = [\"tolerance_positioning\"] + [f\"{m}_score\" for m in mes_cols]\n",
    "        dfv = ad_vis.obs[ad_vis.obs[\"microglia_enriched_spot\"].astype(int) == 1].groupby(pair_key)[cols_scores].mean().reset_index()\n",
    "        dfn = ad_sn.obs.groupby(pair_key)[cols_scores].mean().reset_index()\n",
    "        df_merge = pd.merge(dfv, dfn, on=pair_key, suffixes=(\"_visium\", \"_snrna\"))\n",
    "        concord = []\n",
    "        for c in cols_scores:\n",
    "            cv = f\"{c}_visium\"; cn = f\"{c}_snrna\"\n",
    "            if cv in df_merge.columns and cn in df_merge.columns:\n",
    "                concord.append({\"score\": c, \"n_groups\": int(df_merge.shape[0]),\n",
    "                                \"pearson_r\": safe_corr(df_merge[cv].values, df_merge[cn].values)})\n",
    "        df_concord = pd.DataFrame(concord)\n",
    "        save_excel({\"Concordance\": df_concord, \"Paired\": df_merge,\n",
    "                    \"pair_key\": pd.DataFrame([{\"pair_key\": pair_key_used}])},\n",
    "                   fname=\"Table8_CrossModal_GSE233208\", kind=\"Supplementary\")\n",
    "\n",
    "        fig = plt.figure(figsize=(6.8, 3.2))\n",
    "        gs = fig.add_gridspec(1, 2, wspace=0.35)\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        if \"tolerance_positioning_visium\" in df_merge.columns:\n",
    "            x = df_merge[\"tolerance_positioning_visium\"].values; y2 = df_merge[\"tolerance_positioning_snrna\"].values\n",
    "            ax1.scatter(x, y2, s=18, alpha=0.85, color=C_BAR_ACC2)\n",
    "            ax1.set_xlabel(\"Visium tolerance\"); ax1.set_ylabel(\"snRNA tolerance\")\n",
    "            ax1.set_title(f\"r = {safe_corr(x, y2):.2f}\")\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        dfm = df_concord[df_concord[\"score\"].str.startswith(\"MES\")]\n",
    "        if len(dfm): ax2.bar(dfm[\"score\"], dfm[\"pearson_r\"], color=C_BAR_MAIN)\n",
    "        ax2.tick_params(axis=\"x\", rotation=90); ax2.set_ylabel(\"Pearson r\")\n",
    "        ax2.set_title(\"MES concordance\"); _beautify_axes(ax2)\n",
    "        save_fig(fig, \"Fig3C_CrossModal_GSE233208\", kind=\"Supplementary\")\n",
    "except Exception as e:\n",
    "    crossmodal_ran = False\n",
    "    print(f\"[INFO] Cross-modal not run: {type(e).__name__}: {e}\")\n",
    "\n",
    "# 12) FIGURES 4D + 4E\n",
    "fig, ax = plt.subplots(figsize=(6.8, 3.6))\n",
    "if len(df_stress):\n",
    "    diff = df_stress.set_index(\"dataset\")\n",
    "    ax.bar(diff.index, diff[\"diff_high_minus_low\"], color=C_BAR_ACC, edgecolor=\"black\", linewidth=0.3)\n",
    "    for i, (ds, row) in enumerate(diff.iterrows()):\n",
    "        s = sig_stars(row.get(\"p_perm\"))\n",
    "        if s != \"ns\":\n",
    "            y_pos = row[\"diff_high_minus_low\"] + (0.01 if row[\"diff_high_minus_low\"] >= 0 else -0.02)\n",
    "            ax.text(i, y_pos, f\"{s}\\np={row['p_perm']:.3f}\", ha=\"center\", fontsize=6, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Δ mean adjusted ρ (high − low GR)\")\n",
    "ax.set_title(\"Main Fig 4D  GR moderation of MES–tolerance link\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "_beautify_axes(ax)\n",
    "save_fig(fig, \"Fig4D\", kind=\"Main\")\n",
    "\n",
    "data_gr = []; labels_gr = []\n",
    "for a in micro_adatas:\n",
    "    vv = a.obs.get(\"GR_composite\", pd.Series([], dtype=float)).values\n",
    "    vv = vv[np.isfinite(vv)]\n",
    "    if vv.size >= 200: data_gr.append(vv); labels_gr.append(str(a.obs[\"dataset\"].iloc[0]))\n",
    "fig, ax = plt.subplots(figsize=(6.8, 3.6))\n",
    "bp = ax.boxplot(data_gr, labels=labels_gr, showfliers=False, patch_artist=True,\n",
    "                boxprops=dict(edgecolor=\"#333333\", linewidth=0.9),\n",
    "                medianprops=dict(color=\"#111111\", linewidth=1.0),\n",
    "                whiskerprops=dict(color=\"#333333\", linewidth=0.9),\n",
    "                capprops=dict(color=\"#333333\", linewidth=0.9))\n",
    "for patch in bp[\"boxes\"]: patch.set_facecolor(C_BAR_MAIN); patch.set_alpha(0.30)\n",
    "ax.set_ylabel(\"GR composite score\")\n",
    "ax.set_title(\"Supplementary Fig 4E  GR program across cohorts\")\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "_beautify_axes(ax)\n",
    "save_fig(fig, \"Fig4E_GR_AcrossCohorts\", kind=\"Supplementary\")\n",
    "\n",
    "# 13) INNATE MEMORY (GSE184241)\n",
    "def read_gse184241_counts(path):\n",
    "    path = Path(path)\n",
    "    compression = \"gzip\" if str(path).endswith(\".gz\") else None\n",
    "    df = pd.read_csv(path, sep=r\"\\s+\", engine=\"python\", compression=compression, index_col=0)\n",
    "    df.index = df.index.astype(str).str.replace('\"', '').str.strip()\n",
    "    df.columns = df.columns.astype(str).str.replace('\"', '').str.strip()\n",
    "    idx_sample = df.index[:100].astype(str)\n",
    "    hgnc_like = idx_sample.str.match(r\"^[A-Za-z][A-Za-z0-9\\-\\.\\+]*$\").mean()\n",
    "    numeric_like = idx_sample.str.fullmatch(r\"\\d+\").mean()\n",
    "    if hgnc_like >= 0.6 and numeric_like < 0.2:\n",
    "        df = df.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
    "        return df.groupby(df.index, sort=False).sum(min_count=1)\n",
    "    df2 = pd.read_csv(path, sep=r\"\\s+\", engine=\"python\", compression=compression)\n",
    "    df2.columns = df2.columns.astype(str).str.replace('\"', '').str.strip()\n",
    "    gene_col = df2.columns[0]\n",
    "    df2[gene_col] = df2[gene_col].astype(str).str.replace('\"', '').str.strip()\n",
    "    df2 = df2.set_index(gene_col)\n",
    "    df2 = df2.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
    "    return df2.groupby(df2.index, sort=False).sum(min_count=1)\n",
    "\n",
    "def infer_condition_fixed(sample_name):\n",
    "    s_up = str(sample_name).upper()\n",
    "    if \"_LPS_\" in s_up: return \"LPS\"\n",
    "    if \"_RPMI_\" in s_up: return \"RPMI\"\n",
    "    if \"LPS\" in s_up: return \"LPS\"\n",
    "    if \"RPMI\" in s_up: return \"RPMI\"\n",
    "    if \"CTRL\" in s_up or \"CONTROL\" in s_up: return \"Control\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "gse184_hits = list(RAW_DIR.rglob(\"GSE184241_combined_raw_counts.txt.gz\")) + list(RAW_DIR.rglob(\"GSE184241_combined_raw_counts.txt\"))\n",
    "df_innate_scores = pd.DataFrame()\n",
    "innate_stats_rows = []\n",
    "\n",
    "if gse184_hits:\n",
    "    gse184_file = gse184_hits[0]\n",
    "    expr184 = read_gse184241_counts(gse184_file)\n",
    "    MES_GENES = sorted({g for genes in mes_gene_sets.values() for g in genes})\n",
    "    overlap = sorted(set(MES_GENES) & set(expr184.index))\n",
    "    print(f\"[GSE184241] MES overlap: {len(overlap)}/{len(MES_GENES)}\")\n",
    "    assert len(overlap) > 0\n",
    "\n",
    "    lib = expr184.sum(axis=0).replace(0, np.nan)\n",
    "    df_logm = np.log2(expr184.div(lib, axis=1) * 1e6 + 1.0)\n",
    "\n",
    "    def sample_score(df_log_gxS, genes_up, genes_dn=None):\n",
    "        up = [g for g in genes_up if g in df_log_gxS.index]\n",
    "        dn = [g for g in (genes_dn or []) if g in df_log_gxS.index]\n",
    "        if len(up) < 3: return pd.Series(index=df_log_gxS.columns, data=np.nan)\n",
    "        s_up = df_log_gxS.loc[up].mean(axis=0)\n",
    "        s_dn = df_log_gxS.loc[dn].mean(axis=0) if len(dn) >= 3 else 0.0\n",
    "        return (s_up - s_dn).astype(float)\n",
    "\n",
    "    out = pd.DataFrame(index=df_logm.columns)\n",
    "    out[\"sample\"] = out.index.astype(str)\n",
    "    out[\"condition\"] = out[\"sample\"].apply(infer_condition_fixed)\n",
    "    out[\"homeostatic\"] = sample_score(df_logm, SIG[\"microglia_homeostatic\"])\n",
    "    out[\"activation\"] = sample_score(df_logm, SIG[\"microglia_activation\"])\n",
    "    out[\"tolerance_like\"] = out[\"homeostatic\"] - out[\"activation\"]\n",
    "    out[\"GR_score\"] = sample_score(df_logm, GR_UP, GR_DN)\n",
    "    for mes in mes_cols:\n",
    "        out[f\"{mes}_score\"] = sample_score(df_logm, mes_gene_sets[mes])\n",
    "\n",
    "    df_innate_scores = out.reset_index(drop=True)\n",
    "    print(\"GSE184241 conditions:\", df_innate_scores[\"condition\"].value_counts().to_dict())\n",
    "\n",
    "    # FORMAL LPS vs RPMI STATISTICAL TESTS (NEW)\n",
    "    lps = df_innate_scores[df_innate_scores[\"condition\"] == \"LPS\"]\n",
    "    rpmi = df_innate_scores[df_innate_scores[\"condition\"] == \"RPMI\"]\n",
    "    if len(lps) >= 3 and len(rpmi) >= 3:\n",
    "        for sc_col in [\"tolerance_like\", \"GR_score\"] + [f\"{m}_score\" for m in mes_cols]:\n",
    "            a_vals = lps[sc_col].dropna().values\n",
    "            b_vals = rpmi[sc_col].dropna().values\n",
    "            if len(a_vals) >= 3 and len(b_vals) >= 3:\n",
    "                _, p_mw = stats.mannwhitneyu(a_vals, b_vals, alternative=\"two-sided\")\n",
    "                dr = cohens_d_with_ci(a_vals, b_vals, n_boot=min(N_BOOT, 500), seed=SEED + 200)\n",
    "                innate_stats_rows.append({\n",
    "                    \"score\": sc_col, \"n_LPS\": len(a_vals), \"n_RPMI\": len(b_vals),\n",
    "                    \"mean_LPS\": float(np.mean(a_vals)), \"mean_RPMI\": float(np.mean(b_vals)),\n",
    "                    \"cohens_d\": dr[\"d\"], \"d_ci_lo\": dr[\"ci_lo\"], \"d_ci_hi\": dr[\"ci_hi\"],\n",
    "                    \"p_MW\": float(p_mw)})\n",
    "        df_innate_stats = pd.DataFrame(innate_stats_rows)\n",
    "        df_innate_stats[\"q_BH\"] = bh_fdr(df_innate_stats[\"p_MW\"].values)\n",
    "    else:\n",
    "        df_innate_stats = pd.DataFrame()\n",
    "\n",
    "    save_excel({\n",
    "        \"GSE184241_sample_scores\": df_innate_scores,\n",
    "        \"LPS_vs_RPMI_stats\": df_innate_stats if len(innate_stats_rows) else pd.DataFrame(),\n",
    "        \"note\": pd.DataFrame([{\"file\": str(gse184_file),\n",
    "                                \"note\": \"Sample-level scoring + formal LPS vs RPMI comparison (MW + Cohen's d + BH-FDR)\"}])\n",
    "    }, fname=\"Table7_InnateMemory_GSE184241\", kind=\"Supplementary\")\n",
    "\n",
    "    # Supp Fig 4F: heatmap\n",
    "    mes_score_cols = [f\"{m}_score\" for m in mes_cols]\n",
    "    hm = df_innate_scores.set_index(\"sample\")[mes_score_cols].copy()\n",
    "    hmz = (hm - hm.mean(axis=0)) / (hm.std(axis=0) + 1e-8)\n",
    "    cond = df_innate_scores.set_index(\"sample\")[\"condition\"].reindex(hmz.index).astype(str)\n",
    "    order = np.argsort(cond.values, kind=\"stable\")\n",
    "    hmz_ord = hmz.iloc[order]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.2, 4.8))\n",
    "    if HAS_SNS:\n",
    "        row_colors = cond.iloc[order].map({\"LPS\": \"#D6604D\", \"RPMI\": \"#4393C3\", \"Control\": \"#66C2A5\", \"Unknown\": \"#999999\"})\n",
    "        sns.heatmap(hmz_ord, ax=ax, cmap=CMAP_HEAT, vmin=-2, vmax=2, linewidths=0,\n",
    "                    cbar_kws={\"label\": \"Z-score\", \"shrink\": 0.7},\n",
    "                    xticklabels=True, yticklabels=False)\n",
    "    else:\n",
    "        im = ax.imshow(hmz_ord.values, aspect=\"auto\", cmap=CMAP_HEAT, vmin=-2, vmax=2, interpolation=\"nearest\")\n",
    "        ax.set_xticks(range(hmz_ord.shape[1])); ax.set_xticklabels(hmz_ord.columns, rotation=90)\n",
    "        plt.colorbar(im, ax=ax, label=\"Z-score\", shrink=0.7)\n",
    "    ax.set_title(\"Supplementary Fig 4F  GSE184241 innate memory MES profiles\")\n",
    "    ax.set_ylabel(\"Samples (ordered by condition)\")\n",
    "    save_fig(fig, \"Fig4F_InnateMemory_MES_Profiles\", kind=\"Supplementary\")\n",
    "else:\n",
    "    print(\"[INFO] GSE184241 not found; skipping.\")\n",
    "\n",
    "# 14) SAVE SCORED h5ad\n",
    "for a in micro_adatas:\n",
    "    ds = str(a.obs[\"dataset\"].iloc[0])\n",
    "    out = AIM2_DIR / f\"{ds}__microglia_scored.h5ad\"\n",
    "    sanitize_for_write(a).write_h5ad(out)\n",
    "    print(f\"[SAVED] {out}\")\n",
    "\n",
    "# 15) SUPPLEMENTARY TABLE 5 \n",
    "df_crossmodal_summary = pd.DataFrame()\n",
    "if crossmodal_ran and len(df_concord):\n",
    "    df_crossmodal_summary = df_concord.copy()\n",
    "    df_crossmodal_summary[\"dataset\"] = \"GSE233208\"\n",
    "    df_crossmodal_summary[\"pair_key\"] = pair_key_used\n",
    "\n",
    "save_excel({\n",
    "    \"GSE220442_spatial_allMES\": df_spatial,\n",
    "    \"GSE233208_crossmodal\": df_crossmodal_summary,\n",
    "    \"crossmodal_status\": pd.DataFrame([{\n",
    "        \"ran\": bool(crossmodal_ran),\n",
    "        \"folder\": str(GSE233208_EXPORT),\n",
    "        \"note\": \"Cross-modal runs only if MTX exports exist.\"}])\n",
    "}, fname=\"Table5\", kind=\"Supplementary\")\n",
    "\n",
    "# 16) SUPPLEMENTARY TABLE INDEX \n",
    "index_rows = [\n",
    "    {\"label\": \"Main Table 2\", \"file\": \"Main_Table2.xlsx\", \"content\": \"MES–tolerance correlations + QC + global FDR\"},\n",
    "    {\"label\": \"Supp Table 3\", \"file\": \"Supplementary_Table3_StressCalibration.xlsx\",\n",
    "     \"content\": \"GSE219208 calibration + GR signatures + drug breakdown + sensitivity\"},\n",
    "    {\"label\": \"Supp Table 4\", \"file\": \"Supplementary_Table4.xlsx\", \"content\": \"Signature definitions + full results\"},\n",
    "    {\"label\": \"Supp Table 5\", \"file\": \"Supplementary_Table5.xlsx\", \"content\": \"Spatial (all 8 MES) + cross-modal\"},\n",
    "    {\"label\": \"Supp Table 6\", \"file\": \"Supplementary_Table6.xlsx\", \"content\": \"Stress moderation (permutation)\"},\n",
    "    {\"label\": \"Supp Table 7\", \"file\": \"Supplementary_Table7_InnateMemory_GSE184241.xlsx\",\n",
    "     \"content\": \"Innate memory scores + LPS vs RPMI formal stats\"},\n",
    "    {\"label\": \"Supp Table 9\", \"file\": \"Supplementary_Table9_HK_Sensitivity.xlsx\", \"content\": \"HK load + sensitivity\"},\n",
    "]\n",
    "if crossmodal_ran:\n",
    "    index_rows.append({\"label\": \"Supp Table 8\", \"file\": \"Supplementary_Table8_CrossModal_GSE233208.xlsx\",\n",
    "                        \"content\": \"Visium+snRNA concordance\"})\n",
    "\n",
    "save_excel({\"Index\": pd.DataFrame(index_rows)}, fname=\"Table_Index\", kind=\"Supplementary\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"NB4 COMPLETE ✅\")\n",
    "print(\"=\" * 70)\n",
    "print(\"  ✓ Bootstrap 400→2000, permutation 400→5000\")\n",
    "print(\"  ✓ Cohen's d + AUC with bootstrap 95% CIs\")\n",
    "print(\"  ✓ Key gene labels on volcano (FKBP5, NR3C1, TSC22D3...)\")\n",
    "print(\"  ✓ Seaborn heatmaps with r-values + significance stars\")\n",
    "print(\"  ✓ All bar plots with error bars / CIs\")\n",
    "print(\"  ✓ Boxplot with MW significance annotations\")\n",
    "print(\"  ✓ Drug-type breakdown (dex vs cort)\")\n",
    "print(\"  ✓ GR signature size sensitivity (top 30/50/100)\")\n",
    "print(\"  ✓ Spatial: all 8 MES per sample (not just best)\")\n",
    "print(\"  ✓ Innate memory: formal LPS vs RPMI stats (MW + d + FDR)\")\n",
    "print(\"  ✓ Global BH-FDR across all tests\")\n",
    "print(\"  ✓ padj threshold 0.05 (was 0.1)\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ]
}